From Daniel at deeper.co.za  Tue Aug  3 04:22:56 2004
From: Daniel at deeper.co.za (Daniel)
Date: Tue, 3 Aug 2004 09:22:56 +0100 (BST)
Subject: [OWASP-TESTING] content for new portal
Message-ID: <55887.194.203.201.168.1091521376.squirrel@194.203.201.168>

Hi all,

As you may be aware, the new portal has gone live.
I'm busy adding content to the testing section and would love any feedback
on what everyone thinks should be up there.

cheers

Daniel




From ferruh at mavituna.com  Tue Aug  3 05:50:21 2004
From: ferruh at mavituna.com (Ferruh Mavituna)
Date: Tue, 3 Aug 2004 12:50:21 +0300
Subject: [OWASP-TESTING] content for new portal
In-Reply-To: <55887.194.203.201.168.1091521376.squirrel@194.203.201.168>
Message-ID: <E1Brvvr-0001J9-3A@sc8-sf-mx1.sourceforge.net>

Hi,

First of all it looks nice,

I have some small notes & improvement ideas;

- It's better to add small icons to top menu which can tell visitor to "this
is a fly-out menu" (important for usability), Also fly-out menus should be
different than "Home" link because "Home" is not fly-out. 

Icon: An arrow which is pointing to bottom.


- In "Documentation > Top Ten" menu people who have smaller screen than
1280*1024 and who views site in a smaller window can not see all menus. So
padding would be smaller. (Same in: Local Chapters and Documentation >
Testing)


- Link colors would be default (blue) or some other color because of
usability issues. Also hover color would be nice I think (maybe orange -
red).


- Search box could be "disabled" until it'll be active. A search label would
be good for a better visibility.


- Top-Left OWASP logo can be linked to homepage.


- In http://www.owasp.org/software/webscarab.html page list very close to
"Quick Links". (Just in Mozilla Firefox 0.9.2, IE 6 is fine)


Best Regards;

Ferruh Mavituna
http://ferruh.mavituna.com
PGP Key: http://ferruh.mavituna.com/pgpkey.asc 

> -----Original Message-----
> From: owasp-testing-admin at lists.sourceforge.net [mailto:owasp-testing-
> admin at lists.sourceforge.net] On Behalf Of Daniel
> Sent: 03 A?ustos 2004 Sal? 11:23
> To: owasp
> Subject: [OWASP-TESTING] content for new portal
> 
> Hi all,
> 
> As you may be aware, the new portal has gone live.
> I'm busy adding content to the testing section and would love any feedback
> on what everyone thinks should be up there.
> 
> cheers
> 
> Daniel
> 
> 
> 
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing




From Daniel at deeper.co.za  Tue Aug  3 04:54:47 2004
From: Daniel at deeper.co.za (Daniel)
Date: Tue, 3 Aug 2004 09:54:47 +0100 (BST)
Subject: [OWASP-TESTING] content for new portal
Message-ID: <56966.194.203.201.168.1091523287.squirrel@194.203.201.168>

Whilst the comments are useful (and i've cc'd Jeff in this mail) i was
only really asking about content people in the testing team wanted up
there.

:0)

> Hi,
>
> First of all it looks nice,
>
> I have some small notes & improvement ideas;
>
> - It's better to add small icons to top menu which can tell visitor to
> "this
> is a fly-out menu" (important for usability), Also fly-out menus should be
> different than "Home" link because "Home" is not fly-out.
>
> Icon: An arrow which is pointing to bottom.
>
>
> - In "Documentation > Top Ten" menu people who have smaller screen than
> 1280*1024 and who views site in a smaller window can not see all menus. So
> padding would be smaller. (Same in: Local Chapters and Documentation >
> Testing)
>
>
> - Link colors would be default (blue) or some other color because of
> usability issues. Also hover color would be nice I think (maybe orange -
> red).
>
>
> - Search box could be "disabled" until it'll be active. A search label
> would
> be good for a better visibility.
>
>
> - Top-Left OWASP logo can be linked to homepage.
>
>
> - In http://www.owasp.org/software/webscarab.html page list very close to
> "Quick Links". (Just in Mozilla Firefox 0.9.2, IE 6 is fine)
>
>
> Best Regards;
>
> Ferruh Mavituna
> http://ferruh.mavituna.com
> PGP Key: http://ferruh.mavituna.com/pgpkey.asc
>
>> -----Original Message-----
>> From: owasp-testing-admin at lists.sourceforge.net [mailto:owasp-testing-
>> admin at lists.sourceforge.net] On Behalf Of Daniel
>> Sent: 03 A?ustos 2004 Sal? 11:23
>> To: owasp
>> Subject: [OWASP-TESTING] content for new portal
>>
>> Hi all,
>>
>> As you may be aware, the new portal has gone live.
>> I'm busy adding content to the testing section and would love any
>> feedback
>> on what everyone thinks should be up there.
>>
>> cheers
>>
>> Daniel
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
>> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
>> one more big change to announce. We are now OSTG- Open Source Technology
>> Group. Come see the changes on the new OSTG site. www.ostg.com
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>
>





From mark at curphey.com  Tue Aug  3 05:56:35 2004
From: mark at curphey.com (Mark Curphey)
Date: Tue, 03 Aug 2004 05:56:35 -0400 (EDT)
Subject: [OWASP-TESTING] content for new portal
In-Reply-To: <E1Brvvr-0001J9-3A@sc8-sf-mx1.sourceforge.net>
Message-ID: <200408030956.FAA06057@arkroyal.cnchost.com>

Ferruh

Thanks for the comments. I will set you up with CVS so you can make these change. If you forward me your Sourceforge ID we can do that.

Thanks

Mark
---- Ferruh Mavituna <ferruh at mavituna.com> wrote:
>
> Hi,
> 
> First of all it looks nice,
> 
> I have some small notes & improvement ideas;
> 
> - It's better to add small icons to top menu which can tell visitor to "this
> is a fly-out menu" (important for usability), Also fly-out menus should be
> different than "Home" link because "Home" is not fly-out. 
> 
> Icon: An arrow which is pointing to bottom.
> 
> 
> - In "Documentation > Top Ten" menu people who have smaller screen than
> 1280*1024 and who views site in a smaller window can not see all menus. So
> padding would be smaller. (Same in: Local Chapters and Documentation >
> Testing)
> 
> 
> - Link colors would be default (blue) or some other color because of
> usability issues. Also hover color would be nice I think (maybe orange -
> red).
> 
> 
> - Search box could be "disabled" until it'll be active. A search label would
> be good for a better visibility.
> 
> 
> - Top-Left OWASP logo can be linked to homepage.
> 
> 
> - In http://www.owasp.org/software/webscarab.html page list very close to
> "Quick Links". (Just in Mozilla Firefox 0.9.2, IE 6 is fine)
> 
> 
> Best Regards;
> 
> Ferruh Mavituna
> http://ferruh.mavituna.com
> PGP Key: http://ferruh.mavituna.com/pgpkey.asc 
> 
> > -----Original Message-----
> > From: owasp-testing-admin at lists.sourceforge.net [mailto:owasp-testing-
> > admin at lists.sourceforge.net] On Behalf Of Daniel
> > Sent: 03 A?ustos 2004 Sal? 11:23
> > To: owasp
> > Subject: [OWASP-TESTING] content for new portal
> > 
> > Hi all,
> > 
> > As you may be aware, the new portal has gone live.
> > I'm busy adding content to the testing section and would love any feedback
> > on what everyone thinks should be up there.
> > 
> > cheers
> > 
> > Daniel
> > 
> > 
> > 
> > -------------------------------------------------------
> > This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> > Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> > one more big change to announce. We are now OSTG- Open Source Technology
> > Group. Come see the changes on the new OSTG site. www.ostg.com
> > _______________________________________________
> > owasp-testing mailing list
> > owasp-testing at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 
> 
> 
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 
> 



From llmora at sentryware.com  Tue Aug  3 21:03:04 2004
From: llmora at sentryware.com (Lluis Mora)
Date: Wed, 04 Aug 2004 03:03:04 +0200
Subject: [OWASP-TESTING] Phase II, outline
In-Reply-To: <200407291322.JAA26353@dreadnought.cnchost.com>
References: <200407291322.JAA26353@dreadnought.cnchost.com>
Message-ID: <411035C8.8040902@sentryware.com>

Hi there,

I like the idea of the new proposed outline, it looks easier to mantain 
and we can start writing some sections while we continue to discuss what 
parts we want on the appendixes.

About J2EE or other languages, I would try to stay away from any 
particular language whilst doing the testing description for 
vulnerabilities that can be "implemented" in any language, even if we 
are tempted to give out an example it should be pseudocode, without 
limiting ourselves to a particular language.

Having said that I would allow for language specific sections such as 
"Testing for vulnerabilities in applications written in XXX" and "... 
applications running on such and such platforms (e.g. J2EE, .NET...)"

Can we decide on a basic outline so that we can start working on some 
contents? I have some spare time on August and would like to put some 
work into it.

Cheers,

Lluis
.

Mark Curphey wrote:
> Dan,
> 
> A couple of ideas that might be worth thinking about are;
> 
> 1. Provide generic methodologies for code review, pen testing , manual
> review etc as outlined in the Part 1 (Nish and Hari started this with their
> sections). These would basically outline "here is how to do a web app pen
> test- first profile site, then look for potential issues, then exploit them
> etc...obviously much more detailed and just a pseudo example). We already
> have a good start with this in Nish, Hari and other work that can be
> re-purposed.
> 2. Organize the actual implementation of these methodologies around the SDLC
> tasks we proposed in Part 1.  This ensures we cover how to test requirements
> and design and don't just produce a pen test methodology and low level guide
> for pen testing. I that that would be fine but we should call it out as that
> as an compliment to the pen test check list if that is what we really want
> to do ?
> 3. Merging Part 1 into Part 2 to get one big testing guide. At that point
> Part 1 would no longer be stand-alone.
> 
> One of the things we found in the OWASP Guide 2.0 re-write was it became
> much easier to call out the language specific stuff such as J2EE and C# into
> an appendix.
> 
> Maybe we could do that here, ie Appendix A - Finding Specific Vulns by Code
> Review, Appendix B - Finding Specific Vulns by Pen testing, Finding Specifi
> Vulns by Design Review
> 
> The advantage of this is an appendix doesn't have to be complete and judging
> by the length of time it took to get to Part 1, it would be far easier to
> get the core of the doc (the methodologies themselves) completed and then
> update Apendixes frequently. By gut estimate is the size of Part 2 will b 20
> times the size of part 1, or 56 years ;-)
> 
> The overall structure would look like
> 
> Introduction
> Principles of Testing
> Testing Techniques Explained (overview)
> OWASP Testing Framework
> Methodologies
> 	Manual Inspections
> 	Penetration Testing
> 	Code Review
> 	Threat Modeling
> 
> Appendix A - Finding Specific Issues using Manual Inspection
> 	Design Reviews
> 	Policy Reviews
> 	Threat Modeling
> 	Requirements Analysis
> 
> Appendix B - Finding Specific Vulnerabilities using Penetration Testing
> 	SQL Injection
> 	XSS
> 	Buffer Overflows
> 	Weak Passwords
> 	Session Management
> Appendix C - Finding Specific Vulnerabilities using Source Code Review
> 	SQL Injection
> 	Weak Key Generation
> 	
> Apendix D - Testing Tools
> Appendix X etc
> 
> Some how this needs to be tied to using these techniques at the right stages
> of the SDLC so people stop pen testing before deployment. Maybe the
> framework itself is OK for that.
> 
> Thoughts ? 
> 
> -----Original Message-----
> From: owasp-testing-admin at lists.sourceforge.net
> [mailto:owasp-testing-admin at lists.sourceforge.net] On Behalf Of Daniel
> Sent: Thursday, July 29, 2004 6:50 AM
> To: owasp 
> Subject: [OWASP-TESTING] Phase II, outline
> 
> Attached is the outline so far, can we all start looking at the structure
> and deciding the direction?
> 
> I think we need to concentrate on making sure the various languages are
> covered. I had a good chat with a friend over at another large investment
> bank and he wanted to know what we were doing with J2EE stuff, hence this
> has now been added.
> 
> Once everyone is happy with what is in the outline, i'll draw up a better
> format and then we can start assigning sections for people to get on with.
> 
> There are a large amount of people on this list now and yet only a few
> regulars still seem to offer comments. I will be removing the inactive ones
> in the next couple of weeks (hey it's only fair to contribute and not use it
> as a private guide before the rest of the world get it..)
> 
> 
> Thanks to everyone who has contributed so far
> 
> Daniel
> 
> 
> 
> -------------------------------------------------------
> This SF.Net email is sponsored by BEA Weblogic Workshop
> FREE Java Enterprise J2EE developer tools!
> Get your free copy of BEA WebLogic Workshop 8.1 today.
> http://ads.osdn.com/?ad_id=4721&alloc_id=10040&op=click
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 




From Daniel at deeper.co.za  Wed Aug  4 03:19:18 2004
From: Daniel at deeper.co.za (Daniel)
Date: Wed, 4 Aug 2004 08:19:18 +0100 (BST)
Subject: [OWASP-TESTING] Phase II, outline
In-Reply-To: <411035C8.8040902@sentryware.com>
References: <200407291322.JAA26353@dreadnought.cnchost.com>
    <411035C8.8040902@sentryware.com>
Message-ID: <42168.194.203.201.168.1091603958.squirrel@194.203.201.168>

Exactly my thoughts!

I am working on getting out a revised outline by this weekend. Sorry for
the delay but the real world job has a load of deadlines i need to get
done (or ill have a load of free time on my hands *wink)



> Hi there,
>
> I like the idea of the new proposed outline, it looks easier to mantain
> and we can start writing some sections while we continue to discuss what
> parts we want on the appendixes.
>
> About J2EE or other languages, I would try to stay away from any
> particular language whilst doing the testing description for
> vulnerabilities that can be "implemented" in any language, even if we
> are tempted to give out an example it should be pseudocode, without
> limiting ourselves to a particular language.
>
> Having said that I would allow for language specific sections such as
> "Testing for vulnerabilities in applications written in XXX" and "...
> applications running on such and such platforms (e.g. J2EE, .NET...)"
>
> Can we decide on a basic outline so that we can start working on some
> contents? I have some spare time on August and would like to put some
> work into it.
>
> Cheers,
>
> Lluis
> .
>
> Mark Curphey wrote:
>> Dan,
>>
>> A couple of ideas that might be worth thinking about are;
>>
>> 1. Provide generic methodologies for code review, pen testing , manual
>> review etc as outlined in the Part 1 (Nish and Hari started this with
>> their
>> sections). These would basically outline "here is how to do a web app
>> pen
>> test- first profile site, then look for potential issues, then exploit
>> them
>> etc...obviously much more detailed and just a pseudo example). We
>> already
>> have a good start with this in Nish, Hari and other work that can be
>> re-purposed.
>> 2. Organize the actual implementation of these methodologies around the
>> SDLC
>> tasks we proposed in Part 1.  This ensures we cover how to test
>> requirements
>> and design and don't just produce a pen test methodology and low level
>> guide
>> for pen testing. I that that would be fine but we should call it out as
>> that
>> as an compliment to the pen test check list if that is what we really
>> want
>> to do ?
>> 3. Merging Part 1 into Part 2 to get one big testing guide. At that
>> point
>> Part 1 would no longer be stand-alone.
>>
>> One of the things we found in the OWASP Guide 2.0 re-write was it became
>> much easier to call out the language specific stuff such as J2EE and C#
>> into
>> an appendix.
>>
>> Maybe we could do that here, ie Appendix A - Finding Specific Vulns by
>> Code
>> Review, Appendix B - Finding Specific Vulns by Pen testing, Finding
>> Specifi
>> Vulns by Design Review
>>
>> The advantage of this is an appendix doesn't have to be complete and
>> judging
>> by the length of time it took to get to Part 1, it would be far easier
>> to
>> get the core of the doc (the methodologies themselves) completed and
>> then
>> update Apendixes frequently. By gut estimate is the size of Part 2 will
>> b 20
>> times the size of part 1, or 56 years ;-)
>>
>> The overall structure would look like
>>
>> Introduction
>> Principles of Testing
>> Testing Techniques Explained (overview)
>> OWASP Testing Framework
>> Methodologies
>> 	Manual Inspections
>> 	Penetration Testing
>> 	Code Review
>> 	Threat Modeling
>>
>> Appendix A - Finding Specific Issues using Manual Inspection
>> 	Design Reviews
>> 	Policy Reviews
>> 	Threat Modeling
>> 	Requirements Analysis
>>
>> Appendix B - Finding Specific Vulnerabilities using Penetration Testing
>> 	SQL Injection
>> 	XSS
>> 	Buffer Overflows
>> 	Weak Passwords
>> 	Session Management
>> Appendix C - Finding Specific Vulnerabilities using Source Code Review
>> 	SQL Injection
>> 	Weak Key Generation
>>
>> Apendix D - Testing Tools
>> Appendix X etc
>>
>> Some how this needs to be tied to using these techniques at the right
>> stages
>> of the SDLC so people stop pen testing before deployment. Maybe the
>> framework itself is OK for that.
>>
>> Thoughts ?
>>
>> -----Original Message-----
>> From: owasp-testing-admin at lists.sourceforge.net
>> [mailto:owasp-testing-admin at lists.sourceforge.net] On Behalf Of Daniel
>> Sent: Thursday, July 29, 2004 6:50 AM
>> To: owasp
>> Subject: [OWASP-TESTING] Phase II, outline
>>
>> Attached is the outline so far, can we all start looking at the
>> structure
>> and deciding the direction?
>>
>> I think we need to concentrate on making sure the various languages are
>> covered. I had a good chat with a friend over at another large
>> investment
>> bank and he wanted to know what we were doing with J2EE stuff, hence
>> this
>> has now been added.
>>
>> Once everyone is happy with what is in the outline, i'll draw up a
>> better
>> format and then we can start assigning sections for people to get on
>> with.
>>
>> There are a large amount of people on this list now and yet only a few
>> regulars still seem to offer comments. I will be removing the inactive
>> ones
>> in the next couple of weeks (hey it's only fair to contribute and not
>> use it
>> as a private guide before the rest of the world get it..)
>>
>>
>> Thanks to everyone who has contributed so far
>>
>> Daniel
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by BEA Weblogic Workshop
>> FREE Java Enterprise J2EE developer tools!
>> Get your free copy of BEA WebLogic Workshop 8.1 today.
>> http://ads.osdn.com/?ad_id=4721&alloc_id=10040&op=click
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>
>
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>





From SyedMA at microland.net  Wed Aug  4 04:44:03 2004
From: SyedMA at microland.net (Syed Mohamed A)
Date: Wed, 4 Aug 2004 14:14:03 +0530 
Subject: [OWASP-TESTING] Phase II, outline
Message-ID: <226C58401C8BD41195E700B0D022182F02DEF10C@mlcor00103>

Isn't reporting missing in the outline??? 
Regards
Syed Mohamed A

-----Original Message-----
From: Daniel [mailto:Daniel at deeper.co.za] 
Sent: Wednesday, August 04, 2004 12:19 AM
To: owasp 
Subject: Re: [OWASP-TESTING] Phase II, outline

Exactly my thoughts!

I am working on getting out a revised outline by this weekend. Sorry for
the delay but the real world job has a load of deadlines i need to get
done (or ill have a load of free time on my hands *wink)



> Hi there,
>
> I like the idea of the new proposed outline, it looks easier to mantain
> and we can start writing some sections while we continue to discuss what
> parts we want on the appendixes.
>
> About J2EE or other languages, I would try to stay away from any
> particular language whilst doing the testing description for
> vulnerabilities that can be "implemented" in any language, even if we
> are tempted to give out an example it should be pseudocode, without
> limiting ourselves to a particular language.
>
> Having said that I would allow for language specific sections such as
> "Testing for vulnerabilities in applications written in XXX" and "...
> applications running on such and such platforms (e.g. J2EE, .NET...)"
>
> Can we decide on a basic outline so that we can start working on some
> contents? I have some spare time on August and would like to put some
> work into it.
>
> Cheers,
>
> Lluis
> .
>
> Mark Curphey wrote:
>> Dan,
>>
>> A couple of ideas that might be worth thinking about are;
>>
>> 1. Provide generic methodologies for code review, pen testing , manual
>> review etc as outlined in the Part 1 (Nish and Hari started this with
>> their
>> sections). These would basically outline "here is how to do a web app
>> pen
>> test- first profile site, then look for potential issues, then exploit
>> them
>> etc...obviously much more detailed and just a pseudo example). We
>> already
>> have a good start with this in Nish, Hari and other work that can be
>> re-purposed.
>> 2. Organize the actual implementation of these methodologies around the
>> SDLC
>> tasks we proposed in Part 1.  This ensures we cover how to test
>> requirements
>> and design and don't just produce a pen test methodology and low level
>> guide
>> for pen testing. I that that would be fine but we should call it out as
>> that
>> as an compliment to the pen test check list if that is what we really
>> want
>> to do ?
>> 3. Merging Part 1 into Part 2 to get one big testing guide. At that
>> point
>> Part 1 would no longer be stand-alone.
>>
>> One of the things we found in the OWASP Guide 2.0 re-write was it became
>> much easier to call out the language specific stuff such as J2EE and C#
>> into
>> an appendix.
>>
>> Maybe we could do that here, ie Appendix A - Finding Specific Vulns by
>> Code
>> Review, Appendix B - Finding Specific Vulns by Pen testing, Finding
>> Specifi
>> Vulns by Design Review
>>
>> The advantage of this is an appendix doesn't have to be complete and
>> judging
>> by the length of time it took to get to Part 1, it would be far easier
>> to
>> get the core of the doc (the methodologies themselves) completed and
>> then
>> update Apendixes frequently. By gut estimate is the size of Part 2 will
>> b 20
>> times the size of part 1, or 56 years ;-)
>>
>> The overall structure would look like
>>
>> Introduction
>> Principles of Testing
>> Testing Techniques Explained (overview)
>> OWASP Testing Framework
>> Methodologies
>> 	Manual Inspections
>> 	Penetration Testing
>> 	Code Review
>> 	Threat Modeling
>>
>> Appendix A - Finding Specific Issues using Manual Inspection
>> 	Design Reviews
>> 	Policy Reviews
>> 	Threat Modeling
>> 	Requirements Analysis
>>
>> Appendix B - Finding Specific Vulnerabilities using Penetration Testing
>> 	SQL Injection
>> 	XSS
>> 	Buffer Overflows
>> 	Weak Passwords
>> 	Session Management
>> Appendix C - Finding Specific Vulnerabilities using Source Code Review
>> 	SQL Injection
>> 	Weak Key Generation
>>
>> Apendix D - Testing Tools
>> Appendix X etc
>>
>> Some how this needs to be tied to using these techniques at the right
>> stages
>> of the SDLC so people stop pen testing before deployment. Maybe the
>> framework itself is OK for that.
>>
>> Thoughts ?
>>
>> -----Original Message-----
>> From: owasp-testing-admin at lists.sourceforge.net
>> [mailto:owasp-testing-admin at lists.sourceforge.net] On Behalf Of Daniel
>> Sent: Thursday, July 29, 2004 6:50 AM
>> To: owasp
>> Subject: [OWASP-TESTING] Phase II, outline
>>
>> Attached is the outline so far, can we all start looking at the
>> structure
>> and deciding the direction?
>>
>> I think we need to concentrate on making sure the various languages are
>> covered. I had a good chat with a friend over at another large
>> investment
>> bank and he wanted to know what we were doing with J2EE stuff, hence
>> this
>> has now been added.
>>
>> Once everyone is happy with what is in the outline, i'll draw up a
>> better
>> format and then we can start assigning sections for people to get on
>> with.
>>
>> There are a large amount of people on this list now and yet only a few
>> regulars still seem to offer comments. I will be removing the inactive
>> ones
>> in the next couple of weeks (hey it's only fair to contribute and not
>> use it
>> as a private guide before the rest of the world get it..)
>>
>>
>> Thanks to everyone who has contributed so far
>>
>> Daniel
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by BEA Weblogic Workshop
>> FREE Java Enterprise J2EE developer tools!
>> Get your free copy of BEA WebLogic Workshop 8.1 today.
>> http://ads.osdn.com/?ad_id=4721&alloc_id=10040&op=click
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>
>
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>




-------------------------------------------------------
This SF.Net email is sponsored by OSTG. Have you noticed the changes on
Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
one more big change to announce. We are now OSTG- Open Source Technology
Group. Come see the changes on the new OSTG site. www.ostg.com
_______________________________________________
owasp-testing mailing list
owasp-testing at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/owasp-testing



From orac at uncon.org  Wed Aug  4 04:48:44 2004
From: orac at uncon.org (orac)
Date: Wed, 4 Aug 2004 09:48:44 +0100
Subject: [OWASP-TESTING] Comment on testing guide and contrib for part 2
In-Reply-To: <20040730152754.50322.qmail@web54106.mail.yahoo.com>
Message-ID: <002301c479ff$ef5edf10$aee59ed4@Pegasus>

Hi Mauro,

I have a similar issue in when I can get at the SDLC for testing. The
end-user organisation I am working in at the moment officially "does not
do in-house development". All the line of business applications (And
there are many) are sourced from external vendors and the closest we get
to a SDLC is the system design stage where off-the-shelf components are
glued together. 

There is a certain amount of completed system penetration testing but I
am finding the value of that to be fairly low as the vendors either
cannot fix the bugs at that late stage or want so much money to do it
that the business decides to take the risk.

I am seeing some value in component level tests during the design phase.
The result being that we may not be able to alter the source of a COTS
component but if we spot the problems early enough we can architect
around them in the glue code. 

Due to the fact that these are limited in scope and custom to the
component and it's role in the architecture they tend to be tested
in-house as it is barely worth it for a 3rd party testing company to get
involved. 

Given the time and cost of code reviews we just don't get to do them
unless serious problems are thrown up by any testing that is performed.
It is a frustrating position sometimes that could be helped by having
automated scanning tools for glue-code languages like (in my experience
here) ASP, JSP, T-SQL and PL-SQL. Being able to at least run an
automated scanner over code that is unlikely to be manually reviewed can
at least identify vendors who have code quality issues that can then be
used as justification for more detailed work.

Anyway just throwing in the perspective from the end users.

Regards

Orac

<snip>
 
> Concerning SQL Injection, actually those
> vulnerabilities were
> found and exploited during pen tests (all of them).
> In my experience, clients are not very keen in having 
> grey/white box assessments, not to mention let you snoop 
> through their code. I'm not saying they don't do this, but 
> usually when we were called in it was for pen test or 
> application assessments black-box style. People dealing with 
> security - the guys who called us
> - usually managed deployed applications;
> intervening in the SDLC is somehow harder for an
> external organization,
> partly because one tends to "wash dirty laundry at
> home", as an
> italian saying puts it.
> Maybe others have different experiences...
> 
> Mauro
> 
<snip>





From Daniel at deeper.co.za  Wed Aug  4 03:53:17 2004
From: Daniel at deeper.co.za (Daniel)
Date: Wed, 4 Aug 2004 08:53:17 +0100 (BST)
Subject: [OWASP-TESTING] Phase II, outline
In-Reply-To: <226C58401C8BD41195E700B0D022182F02DEF10C@mlcor00103>
References: <226C58401C8BD41195E700B0D022182F02DEF10C@mlcor00103>
Message-ID: <42906.194.203.201.168.1091605997.squirrel@194.203.201.168>

you know, this is a section i'm still unsure about.
Originally we had reporting in Phase III (or maybe im wrong..) and i still
think that in Phase III there needs to be a section on determining the
risk rating with vulns found and also how to do the report.

Phase II is more of the technical "howto", but im open to comments if
anyone thinks we need reporting in here



> Isn't reporting missing in the outline???
> Regards
> Syed Mohamed A
>
> -----Original Message-----
> From: Daniel [mailto:Daniel at deeper.co.za]
> Sent: Wednesday, August 04, 2004 12:19 AM
> To: owasp
> Subject: Re: [OWASP-TESTING] Phase II, outline
>
> Exactly my thoughts!
>
> I am working on getting out a revised outline by this weekend. Sorry for
> the delay but the real world job has a load of deadlines i need to get
> done (or ill have a load of free time on my hands *wink)
>
>
>
>> Hi there,
>>
>> I like the idea of the new proposed outline, it looks easier to mantain
>> and we can start writing some sections while we continue to discuss what
>> parts we want on the appendixes.
>>
>> About J2EE or other languages, I would try to stay away from any
>> particular language whilst doing the testing description for
>> vulnerabilities that can be "implemented" in any language, even if we
>> are tempted to give out an example it should be pseudocode, without
>> limiting ourselves to a particular language.
>>
>> Having said that I would allow for language specific sections such as
>> "Testing for vulnerabilities in applications written in XXX" and "...
>> applications running on such and such platforms (e.g. J2EE, .NET...)"
>>
>> Can we decide on a basic outline so that we can start working on some
>> contents? I have some spare time on August and would like to put some
>> work into it.
>>
>> Cheers,
>>
>> Lluis
>> .
>>
>> Mark Curphey wrote:
>>> Dan,
>>>
>>> A couple of ideas that might be worth thinking about are;
>>>
>>> 1. Provide generic methodologies for code review, pen testing , manual
>>> review etc as outlined in the Part 1 (Nish and Hari started this with
>>> their
>>> sections). These would basically outline "here is how to do a web app
>>> pen
>>> test- first profile site, then look for potential issues, then exploit
>>> them
>>> etc...obviously much more detailed and just a pseudo example). We
>>> already
>>> have a good start with this in Nish, Hari and other work that can be
>>> re-purposed.
>>> 2. Organize the actual implementation of these methodologies around the
>>> SDLC
>>> tasks we proposed in Part 1.  This ensures we cover how to test
>>> requirements
>>> and design and don't just produce a pen test methodology and low level
>>> guide
>>> for pen testing. I that that would be fine but we should call it out as
>>> that
>>> as an compliment to the pen test check list if that is what we really
>>> want
>>> to do ?
>>> 3. Merging Part 1 into Part 2 to get one big testing guide. At that
>>> point
>>> Part 1 would no longer be stand-alone.
>>>
>>> One of the things we found in the OWASP Guide 2.0 re-write was it
>>> became
>>> much easier to call out the language specific stuff such as J2EE and C#
>>> into
>>> an appendix.
>>>
>>> Maybe we could do that here, ie Appendix A - Finding Specific Vulns by
>>> Code
>>> Review, Appendix B - Finding Specific Vulns by Pen testing, Finding
>>> Specifi
>>> Vulns by Design Review
>>>
>>> The advantage of this is an appendix doesn't have to be complete and
>>> judging
>>> by the length of time it took to get to Part 1, it would be far easier
>>> to
>>> get the core of the doc (the methodologies themselves) completed and
>>> then
>>> update Apendixes frequently. By gut estimate is the size of Part 2 will
>>> b 20
>>> times the size of part 1, or 56 years ;-)
>>>
>>> The overall structure would look like
>>>
>>> Introduction
>>> Principles of Testing
>>> Testing Techniques Explained (overview)
>>> OWASP Testing Framework
>>> Methodologies
>>> 	Manual Inspections
>>> 	Penetration Testing
>>> 	Code Review
>>> 	Threat Modeling
>>>
>>> Appendix A - Finding Specific Issues using Manual Inspection
>>> 	Design Reviews
>>> 	Policy Reviews
>>> 	Threat Modeling
>>> 	Requirements Analysis
>>>
>>> Appendix B - Finding Specific Vulnerabilities using Penetration Testing
>>> 	SQL Injection
>>> 	XSS
>>> 	Buffer Overflows
>>> 	Weak Passwords
>>> 	Session Management
>>> Appendix C - Finding Specific Vulnerabilities using Source Code Review
>>> 	SQL Injection
>>> 	Weak Key Generation
>>>
>>> Apendix D - Testing Tools
>>> Appendix X etc
>>>
>>> Some how this needs to be tied to using these techniques at the right
>>> stages
>>> of the SDLC so people stop pen testing before deployment. Maybe the
>>> framework itself is OK for that.
>>>
>>> Thoughts ?
>>>
>>> -----Original Message-----
>>> From: owasp-testing-admin at lists.sourceforge.net
>>> [mailto:owasp-testing-admin at lists.sourceforge.net] On Behalf Of Daniel
>>> Sent: Thursday, July 29, 2004 6:50 AM
>>> To: owasp
>>> Subject: [OWASP-TESTING] Phase II, outline
>>>
>>> Attached is the outline so far, can we all start looking at the
>>> structure
>>> and deciding the direction?
>>>
>>> I think we need to concentrate on making sure the various languages are
>>> covered. I had a good chat with a friend over at another large
>>> investment
>>> bank and he wanted to know what we were doing with J2EE stuff, hence
>>> this
>>> has now been added.
>>>
>>> Once everyone is happy with what is in the outline, i'll draw up a
>>> better
>>> format and then we can start assigning sections for people to get on
>>> with.
>>>
>>> There are a large amount of people on this list now and yet only a few
>>> regulars still seem to offer comments. I will be removing the inactive
>>> ones
>>> in the next couple of weeks (hey it's only fair to contribute and not
>>> use it
>>> as a private guide before the rest of the world get it..)
>>>
>>>
>>> Thanks to everyone who has contributed so far
>>>
>>> Daniel
>>>
>>>
>>>
>>> -------------------------------------------------------
>>> This SF.Net email is sponsored by BEA Weblogic Workshop
>>> FREE Java Enterprise J2EE developer tools!
>>> Get your free copy of BEA WebLogic Workshop 8.1 today.
>>> http://ads.osdn.com/?ad_id=4721&alloc_id=10040&op=click
>>> _______________________________________________
>>> owasp-testing mailing list
>>> owasp-testing at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>>
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
>> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
>> one more big change to announce. We are now OSTG- Open Source Technology
>> Group. Come see the changes on the new OSTG site. www.ostg.com
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>
>
>
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>





From syedma at microland.net  Mon Aug 16 18:11:02 2004
From: syedma at microland.net (Syed Mohamed A)
Date: Mon, 16 Aug 2004 15:11:02 -0700
Subject: [OWASP-TESTING] Phase II, outline
In-Reply-To: <42906.194.203.201.168.1091605997.squirrel@194.203.201.168>
Message-ID: <BIELKCPEOCIAHFBOPPGAKEBCCAAA.syedma@microland.net>

Keeping reporting in phase III sounds good. :-)
Regards
Syed

-----Original Message-----
From: owasp-testing-admin at lists.sourceforge.net
[mailto:owasp-testing-admin at lists.sourceforge.net]On Behalf Of Daniel
Sent: Wednesday, August 04, 2004 12:53 AM
To: owasp 
Subject: RE: [OWASP-TESTING] Phase II, outline


you know, this is a section i'm still unsure about.
Originally we had reporting in Phase III (or maybe im wrong..) and i still
think that in Phase III there needs to be a section on determining the
risk rating with vulns found and also how to do the report.

Phase II is more of the technical "howto", but im open to comments if
anyone thinks we need reporting in here



> Isn't reporting missing in the outline???
> Regards
> Syed Mohamed A
>
> -----Original Message-----
> From: Daniel [mailto:Daniel at deeper.co.za]
> Sent: Wednesday, August 04, 2004 12:19 AM
> To: owasp
> Subject: Re: [OWASP-TESTING] Phase II, outline
>
> Exactly my thoughts!
>
> I am working on getting out a revised outline by this weekend. Sorry for
> the delay but the real world job has a load of deadlines i need to get
> done (or ill have a load of free time on my hands *wink)
>
>
>
>> Hi there,
>>
>> I like the idea of the new proposed outline, it looks easier to mantain
>> and we can start writing some sections while we continue to discuss what
>> parts we want on the appendixes.
>>
>> About J2EE or other languages, I would try to stay away from any
>> particular language whilst doing the testing description for
>> vulnerabilities that can be "implemented" in any language, even if we
>> are tempted to give out an example it should be pseudocode, without
>> limiting ourselves to a particular language.
>>
>> Having said that I would allow for language specific sections such as
>> "Testing for vulnerabilities in applications written in XXX" and "...
>> applications running on such and such platforms (e.g. J2EE, .NET...)"
>>
>> Can we decide on a basic outline so that we can start working on some
>> contents? I have some spare time on August and would like to put some
>> work into it.
>>
>> Cheers,
>>
>> Lluis
>> .
>>
>> Mark Curphey wrote:
>>> Dan,
>>>
>>> A couple of ideas that might be worth thinking about are;
>>>
>>> 1. Provide generic methodologies for code review, pen testing , manual
>>> review etc as outlined in the Part 1 (Nish and Hari started this with
>>> their
>>> sections). These would basically outline "here is how to do a web app
>>> pen
>>> test- first profile site, then look for potential issues, then exploit
>>> them
>>> etc...obviously much more detailed and just a pseudo example). We
>>> already
>>> have a good start with this in Nish, Hari and other work that can be
>>> re-purposed.
>>> 2. Organize the actual implementation of these methodologies around the
>>> SDLC
>>> tasks we proposed in Part 1.  This ensures we cover how to test
>>> requirements
>>> and design and don't just produce a pen test methodology and low level
>>> guide
>>> for pen testing. I that that would be fine but we should call it out as
>>> that
>>> as an compliment to the pen test check list if that is what we really
>>> want
>>> to do ?
>>> 3. Merging Part 1 into Part 2 to get one big testing guide. At that
>>> point
>>> Part 1 would no longer be stand-alone.
>>>
>>> One of the things we found in the OWASP Guide 2.0 re-write was it
>>> became
>>> much easier to call out the language specific stuff such as J2EE and C#
>>> into
>>> an appendix.
>>>
>>> Maybe we could do that here, ie Appendix A - Finding Specific Vulns by
>>> Code
>>> Review, Appendix B - Finding Specific Vulns by Pen testing, Finding
>>> Specifi
>>> Vulns by Design Review
>>>
>>> The advantage of this is an appendix doesn't have to be complete and
>>> judging
>>> by the length of time it took to get to Part 1, it would be far easier
>>> to
>>> get the core of the doc (the methodologies themselves) completed and
>>> then
>>> update Apendixes frequently. By gut estimate is the size of Part 2 will
>>> b 20
>>> times the size of part 1, or 56 years ;-)
>>>
>>> The overall structure would look like
>>>
>>> Introduction
>>> Principles of Testing
>>> Testing Techniques Explained (overview)
>>> OWASP Testing Framework
>>> Methodologies
>>> 	Manual Inspections
>>> 	Penetration Testing
>>> 	Code Review
>>> 	Threat Modeling
>>>
>>> Appendix A - Finding Specific Issues using Manual Inspection
>>> 	Design Reviews
>>> 	Policy Reviews
>>> 	Threat Modeling
>>> 	Requirements Analysis
>>>
>>> Appendix B - Finding Specific Vulnerabilities using Penetration Testing
>>> 	SQL Injection
>>> 	XSS
>>> 	Buffer Overflows
>>> 	Weak Passwords
>>> 	Session Management
>>> Appendix C - Finding Specific Vulnerabilities using Source Code Review
>>> 	SQL Injection
>>> 	Weak Key Generation
>>>
>>> Apendix D - Testing Tools
>>> Appendix X etc
>>>
>>> Some how this needs to be tied to using these techniques at the right
>>> stages
>>> of the SDLC so people stop pen testing before deployment. Maybe the
>>> framework itself is OK for that.
>>>
>>> Thoughts ?
>>>
>>> -----Original Message-----
>>> From: owasp-testing-admin at lists.sourceforge.net
>>> [mailto:owasp-testing-admin at lists.sourceforge.net] On Behalf Of Daniel
>>> Sent: Thursday, July 29, 2004 6:50 AM
>>> To: owasp
>>> Subject: [OWASP-TESTING] Phase II, outline
>>>
>>> Attached is the outline so far, can we all start looking at the
>>> structure
>>> and deciding the direction?
>>>
>>> I think we need to concentrate on making sure the various languages are
>>> covered. I had a good chat with a friend over at another large
>>> investment
>>> bank and he wanted to know what we were doing with J2EE stuff, hence
>>> this
>>> has now been added.
>>>
>>> Once everyone is happy with what is in the outline, i'll draw up a
>>> better
>>> format and then we can start assigning sections for people to get on
>>> with.
>>>
>>> There are a large amount of people on this list now and yet only a few
>>> regulars still seem to offer comments. I will be removing the inactive
>>> ones
>>> in the next couple of weeks (hey it's only fair to contribute and not
>>> use it
>>> as a private guide before the rest of the world get it..)
>>>
>>>
>>> Thanks to everyone who has contributed so far
>>>
>>> Daniel
>>>
>>>
>>>
>>> -------------------------------------------------------
>>> This SF.Net email is sponsored by BEA Weblogic Workshop
>>> FREE Java Enterprise J2EE developer tools!
>>> Get your free copy of BEA WebLogic Workshop 8.1 today.
>>> http://ads.osdn.com/?ad_id=4721&alloc_id=10040&op=click
>>> _______________________________________________
>>> owasp-testing mailing list
>>> owasp-testing at lists.sourceforge.net
>>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>>
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
>> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
>> one more big change to announce. We are now OSTG- Open Source Technology
>> Group. Come see the changes on the new OSTG site. www.ostg.com
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>
>
>
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>
>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>




-------------------------------------------------------
This SF.Net email is sponsored by OSTG. Have you noticed the changes on
Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
one more big change to announce. We are now OSTG- Open Source Technology
Group. Come see the changes on the new OSTG site. www.ostg.com
_______________________________________________
owasp-testing mailing list
owasp-testing at lists.sourceforge.net
https://lists.sourceforge.net/lists/listinfo/owasp-testing



From Daniel at deeper.co.za  Wed Aug  4 04:59:27 2004
From: Daniel at deeper.co.za (Daniel)
Date: Wed, 4 Aug 2004 09:59:27 +0100 (BST)
Subject: [OWASP-TESTING] SPI Dynamics toolset
Message-ID: <44035.194.203.201.168.1091609967.squirrel@194.203.201.168>

Thought this may interest a few peeps on this list.

SPI have recently announced a pentesters toolkit for performing web app
pentests.

http://www.spidynamics.com/products/Comp_Audit/toolkit/index.html

I've been told that it retails for around the 2k dollar mark, and im
currently playing with them to see how they go (1st impressions seem to be
a commercial offering of the tools already out there for free)






From mark at curphey.com  Wed Aug  4 06:20:18 2004
From: mark at curphey.com (Mark Curphey)
Date: Wed, 04 Aug 2004 06:20:18 -0400 (EDT)
Subject: [OWASP-TESTING] SPI Dynamics toolset
In-Reply-To: <44035.194.203.201.168.1091609967.squirrel@194.203.201.168>
Message-ID: <200408041020.GAA05051@courageux.cnchost.com>

The proxy is very good. 

I foegot to tell people about SSLDigger

I didn't send it to webappsec as US Law requires we capture peoples addresses for the crypto laws ;-(

www.foundstone.com/s3i

We have a cookie analyzer which will be released in about a month that does phases state analsysis on cookie randomness !



---- Daniel <Daniel at deeper.co.za> wrote:
>
> Thought this may interest a few peeps on this list.
> 
> SPI have recently announced a pentesters toolkit for performing web app
> pentests.
> 
> http://www.spidynamics.com/products/Comp_Audit/toolkit/index.html
> 
> I've been told that it retails for around the 2k dollar mark, and im
> currently playing with them to see how they go (1st impressions seem to be
> a commercial offering of the tools already out there for free)
> 
> 
> 
> 
> 
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 
> 



From Daniel at deeper.co.za  Wed Aug  4 05:22:00 2004
From: Daniel at deeper.co.za (Daniel)
Date: Wed, 4 Aug 2004 10:22:00 +0100 (BST)
Subject: [OWASP-TESTING] SPI Dynamics toolset
In-Reply-To: <200408041020.GAA05051@courageux.cnchost.com>
References: <44035.194.203.201.168.1091609967.squirrel@194.203.201.168>
    <200408041020.GAA05051@courageux.cnchost.com>
Message-ID: <44335.194.203.201.168.1091611320.squirrel@194.203.201.168>

yeah i like SSLDigger alot, although i wish it had individual proxy
support *wink

i think another section that needs to be in phase II is the paper i did on
tools for web app testing, although this time there will be a actual use
for it and it will be released ;0)



> The proxy is very good.
>
> I foegot to tell people about SSLDigger
>
> I didn't send it to webappsec as US Law requires we capture peoples
> addresses for the crypto laws ;-(
>
> www.foundstone.com/s3i
>
> We have a cookie analyzer which will be released in about a month that
> does phases state analsysis on cookie randomness !
>
>
>
> ---- Daniel <Daniel at deeper.co.za> wrote:
>>
>> Thought this may interest a few peeps on this list.
>>
>> SPI have recently announced a pentesters toolkit for performing web app
>> pentests.
>>
>> http://www.spidynamics.com/products/Comp_Audit/toolkit/index.html
>>
>> I've been told that it retails for around the 2k dollar mark, and im
>> currently playing with them to see how they go (1st impressions seem to
>> be
>> a commercial offering of the tools already out there for free)
>>
>>
>>
>>
>>
>> -------------------------------------------------------
>> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
>> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
>> one more big change to announce. We are now OSTG- Open Source Technology
>> Group. Come see the changes on the new OSTG site. www.ostg.com
>> _______________________________________________
>> owasp-testing mailing list
>> owasp-testing at lists.sourceforge.net
>> https://lists.sourceforge.net/lists/listinfo/owasp-testing
>>
>>
>





From mark at curphey.com  Wed Aug  4 06:49:05 2004
From: mark at curphey.com (Mark Curphey)
Date: Wed, 04 Aug 2004 06:49:05 -0400 (EDT)
Subject: [OWASP-TESTING] Comment on testing guide and contrib for part 2
In-Reply-To: <002301c479ff$ef5edf10$aee59ed4@Pegasus>
Message-ID: <200408041049.GAA24493@courageux.cnchost.com>

I think there are a couple of things that might be worth considering. 

1. Consider testing to be split (down the road) for 3rd party reviews and 1st party reviews. 

The original intent of this project was from a 1st party perspective ie I wor for bank x and want tobuild a testing program for my own company.

I guess we have mainly people who do third party reviews on the list.

2. Gary McGraw says it best;

"If you fail a penetration test you know you have a problem. If you pass a penetration test you have no idea that you dont have a bad problem."

I am working on building some tools that benchmark the automated scanners. You know they typically find less than 10% of vulns in a standard site right ?

---- orac <orac at uncon.org> wrote:
>
> Hi Mauro,
> 
> I have a similar issue in when I can get at the SDLC for testing. The
> end-user organisation I am working in at the moment officially "does not
> do in-house development". All the line of business applications (And
> there are many) are sourced from external vendors and the closest we get
> to a SDLC is the system design stage where off-the-shelf components are
> glued together. 
> 
> There is a certain amount of completed system penetration testing but I
> am finding the value of that to be fairly low as the vendors either
> cannot fix the bugs at that late stage or want so much money to do it
> that the business decides to take the risk.
> 
> I am seeing some value in component level tests during the design phase.
> The result being that we may not be able to alter the source of a COTS
> component but if we spot the problems early enough we can architect
> around them in the glue code. 
> 
> Due to the fact that these are limited in scope and custom to the
> component and it's role in the architecture they tend to be tested
> in-house as it is barely worth it for a 3rd party testing company to get
> involved. 
> 
> Given the time and cost of code reviews we just don't get to do them
> unless serious problems are thrown up by any testing that is performed.
> It is a frustrating position sometimes that could be helped by having
> automated scanning tools for glue-code languages like (in my experience
> here) ASP, JSP, T-SQL and PL-SQL. Being able to at least run an
> automated scanner over code that is unlikely to be manually reviewed can
> at least identify vendors who have code quality issues that can then be
> used as justification for more detailed work.
> 
> Anyway just throwing in the perspective from the end users.
> 
> Regards
> 
> Orac
> 
> <snip>
>  
> > Concerning SQL Injection, actually those
> > vulnerabilities were
> > found and exploited during pen tests (all of them).
> > In my experience, clients are not very keen in having 
> > grey/white box assessments, not to mention let you snoop 
> > through their code. I'm not saying they don't do this, but 
> > usually when we were called in it was for pen test or 
> > application assessments black-box style. People dealing with 
> > security - the guys who called us
> > - usually managed deployed applications;
> > intervening in the SDLC is somehow harder for an
> > external organization,
> > partly because one tends to "wash dirty laundry at
> > home", as an
> > italian saying puts it.
> > Maybe others have different experiences...
> > 
> > Mauro
> > 
> <snip>
> 
> 
> 
> 
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 
> 



From orac at uncon.org  Wed Aug  4 07:16:01 2004
From: orac at uncon.org (Orac)
Date: Wed, 4 Aug 2004 12:16:01 +0100
Subject: [OWASP-TESTING] Comment on testing guide and contrib for part 2
In-Reply-To: <200408041049.GAA24493@courageux.cnchost.com>
References: <200408041049.GAA24493@courageux.cnchost.com>
Message-ID: <AAFD92E4-E607-11D8-9D9D-000393A5ED54@uncon.org>

I know the automated scanners are not good practice from a complete 
security solution and wouldn't rely on them as anything more than 
preliminary reconnaissance in a code review.

The benefit is that for the investment of 30 minutes I can get a 
(admittedly very partial) view on the quality of some code that would 
never get reviewed otherwise, perhaps because the project is too small 
financially to pay for the work or because the Business Impact of a 
compromise of the system is too low. Unfortunately we need very much to 
prioritise the time taken over security as there are many systems and 
budgets are limited.

 From previous experience I have been able to grade suppliers based on 
previous code reviews / pen tests in such a way that I know when I have 
to fight to get involved because I don't think the supplier 'gets it'. 
Being able to automatically scan across all code would also give me 
another good measure to identify suppliers who I should worry about. It 
doesn't act as a test of security, passing an automated scan would 
still require further work on high Business Impact systems but it does 
allow me to to do more with less on the smaller ones that slip through 
the gaps :)

I am in the very early stages of looking at a parser for ASP (classic 
at the moment as many of our suppliers have yet to move to .Net) which 
can hopefully be used to search for previously identified bugs or flaws 
so that it can get better over time. I have to date done this with 
regexes but due to differences in coding styles these tend to be 
supplier specific. If it ever gets useful I will share it but it's a 
long way from that at the moment.

In any case a 3rd party (or at least End User) review test process 
would be fantastic. We have implemented security in to various levels 
of our vaguely ITIL compliant custom IT project process so I can't 
really punt that out but am willing to pitch in with advice on a 
standard approach.

Regards

Orac



On 4 Aug 2004, at 11:49, Mark Curphey wrote:

> I think there are a couple of things that might be worth considering.
>
> 1. Consider testing to be split (down the road) for 3rd party reviews 
> and 1st party reviews.
>
> The original intent of this project was from a 1st party perspective 
> ie I wor for bank x and want tobuild a testing program for my own 
> company.
>
> I guess we have mainly people who do third party reviews on the list.
>
> 2. Gary McGraw says it best;
>
> "If you fail a penetration test you know you have a problem. If you 
> pass a penetration test you have no idea that you dont have a bad 
> problem."
>
> I am working on building some tools that benchmark the automated 
> scanners. You know they typically find less than 10% of vulns in a 
> standard site right ?
>
> ---- orac <orac at uncon.org> wrote:
>> <snip>

>> Given the time and cost of code reviews we just don't get to do them
>> unless serious problems are thrown up by any testing that is 
>> performed.
>> It is a frustrating position sometimes that could be helped by having
>> automated scanning tools for glue-code languages like (in my 
>> experience
>> here) ASP, JSP, T-SQL and PL-SQL. Being able to at least run an
>> automated scanner over code that is unlikely to be manually reviewed 
>> can
>> at least identify vendors who have code quality issues that can then 
>> be
>> used as justification for more detailed work.
>>
>> Anyway just throwing in the perspective from the end users.
>>
>> Regards
>>
>> Orac
>>
>> <snip>
> -------------------------------------------------------
> This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> one more big change to announce. We are now OSTG- Open Source 
> Technology
> Group. Come see the changes on the new OSTG site. www.ostg.com
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing




From mark at curphey.com  Wed Aug  4 07:29:24 2004
From: mark at curphey.com (Mark Curphey)
Date: Wed, 04 Aug 2004 07:29:24 -0400 (EDT)
Subject: [OWASP-TESTING] Comment on testing guide and contrib for part 2
In-Reply-To: <200408041049.GAA24493@courageux.cnchost.com>
Message-ID: <200408041129.HAA09918@arkroyal.cnchost.com>

I hear what you are saying but running a web app scanner on a web app is like testing a cars safety by front impact testing only. What happens to side impacts? Rear impacts ? What happens to roll safety? Is it flame proof? Do the seats give off cyanide when set alight? Do the seat belts work? I am not saying they dont have place; you articulate some reasons why they may be appropriate but they are very very limited and very very innacurate. 

We have to be careful to set the pace and say what SHOULD be done rather than WHAT is done today. OWASP has the ability to lead the market into doing the right thing. Thats part of the beauty of it and part of our duty in my opinion.

As I can't type as fast as my stomach wants me to move to the breakfast room, how about a teleconference next week to debate this whole issue ?BTW 

I have an ASP.NET C# parser I wrote that is shaping up. The major code review players (Fortify, Ounce and Coverity) are all working on Java and ASP.NET modules for their platforms. 

---- Orac <orac at uncon.org> wrote:
>
> I know the automated scanners are not good practice from a complete 
> security solution and wouldn't rely on them as anything more than 
> preliminary reconnaissance in a code review.
> 
> The benefit is that for the investment of 30 minutes I can get a 
> (admittedly very partial) view on the quality of some code that would 
> never get reviewed otherwise, perhaps because the project is too small 
> financially to pay for the work or because the Business Impact of a 
> compromise of the system is too low. Unfortunately we need very much to 
> prioritise the time taken over security as there are many systems and 
> budgets are limited.
> 
>  From previous experience I have been able to grade suppliers based on 
> previous code reviews / pen tests in such a way that I know when I have 
> to fight to get involved because I don't think the supplier 'gets it'. 
> Being able to automatically scan across all code would also give me 
> another good measure to identify suppliers who I should worry about. It 
> doesn't act as a test of security, passing an automated scan would 
> still require further work on high Business Impact systems but it does 
> allow me to to do more with less on the smaller ones that slip through 
> the gaps :)
> 
> I am in the very early stages of looking at a parser for ASP (classic 
> at the moment as many of our suppliers have yet to move to .Net) which 
> can hopefully be used to search for previously identified bugs or flaws 
> so that it can get better over time. I have to date done this with 
> regexes but due to differences in coding styles these tend to be 
> supplier specific. If it ever gets useful I will share it but it's a 
> long way from that at the moment.
> 
> In any case a 3rd party (or at least End User) review test process 
> would be fantastic. We have implemented security in to various levels 
> of our vaguely ITIL compliant custom IT project process so I can't 
> really punt that out but am willing to pitch in with advice on a 
> standard approach.
> 
> Regards
> 
> Orac
> 
> 
> 
> On 4 Aug 2004, at 11:49, Mark Curphey wrote:
> 
> > I think there are a couple of things that might be worth considering.
> >
> > 1. Consider testing to be split (down the road) for 3rd party reviews 
> > and 1st party reviews.
> >
> > The original intent of this project was from a 1st party perspective 
> > ie I wor for bank x and want tobuild a testing program for my own 
> > company.
> >
> > I guess we have mainly people who do third party reviews on the list.
> >
> > 2. Gary McGraw says it best;
> >
> > "If you fail a penetration test you know you have a problem. If you 
> > pass a penetration test you have no idea that you dont have a bad 
> > problem."
> >
> > I am working on building some tools that benchmark the automated 
> > scanners. You know they typically find less than 10% of vulns in a 
> > standard site right ?
> >
> > ---- orac <orac at uncon.org> wrote:
> >> <snip>
> 
> >> Given the time and cost of code reviews we just don't get to do them
> >> unless serious problems are thrown up by any testing that is 
> >> performed.
> >> It is a frustrating position sometimes that could be helped by having
> >> automated scanning tools for glue-code languages like (in my 
> >> experience
> >> here) ASP, JSP, T-SQL and PL-SQL. Being able to at least run an
> >> automated scanner over code that is unlikely to be manually reviewed 
> >> can
> >> at least identify vendors who have code quality issues that can then 
> >> be
> >> used as justification for more detailed work.
> >>
> >> Anyway just throwing in the perspective from the end users.
> >>
> >> Regards
> >>
> >> Orac
> >>
> >> <snip>
> > -------------------------------------------------------
> > This SF.Net email is sponsored by OSTG. Have you noticed the changes on
> > Linux.com, ITManagersJournal and NewsForge in the past few weeks? Now,
> > one more big change to announce. We are now OSTG- Open Source 
> > Technology
> > Group. Come see the changes on the new OSTG site. www.ostg.com
> > _______________________________________________
> > owasp-testing mailing list
> > owasp-testing at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/owasp-testing
> 
> 
> 



From orac at uncon.org  Wed Aug  4 07:59:45 2004
From: orac at uncon.org (Orac)
Date: Wed, 4 Aug 2004 12:59:45 +0100
Subject: [OWASP-TESTING] Comment on testing guide and contrib for part 2
In-Reply-To: <200408041129.HAA09918@arkroyal.cnchost.com>
References: <200408041129.HAA09918@arkroyal.cnchost.com>
Message-ID: <C7338372-E60D-11D8-9D9D-000393A5ED54@uncon.org>

I agree OWASP is definitely leading the charge on web application 
security and that has proved to be a good thing.

There's always a but.... but, a lot of the leading stuff that OWASP 
provides is going to take years to filter down through the 3rd party 
software vendors to the end user organisations (Especially if they 
don't do much development in-house).  We are doing our bit by making 
sure that our suppliers are aware of the OWASP guide and by publishing 
our own standard requirements to them (including informally training 
their developers in way too many cases) but for many vendors and many 
applications (especially line-of-business applications behind the 
perimeter) there is a perception that security isn't an important part 
of the sale which will change but will take longer.

We're not in the financial sector which I know from previous experience 
is a lot further along in their externally-facing applications but 
generally not much better on their internal applications.

The OWASP guide is useful to me in my role as a vendor independent 
standard with which I can explain to the business why they need these 
arcane things like input validation and the rest.

I suggest it would be useful to provide a certain level of guidance 
over the level and types of testing of 3rd party apps from the end user 
point of view. That becomes a strong supporting case for convincing the 
business that these things should be done.

It's kind of like pushing at both ends of the system development scale, 
currently OWASP does a good and important job of pushing developer 
understanding and SDLC best practice whereas we are pushing vendors for 
secure code to be delivered to us post SDLC. Hopefully we meet in the 
middle at some point.

A teleconference sounds good, I am on UK time so no 2am calls please :)

Regards

Orac


On 4 Aug 2004, at 12:29, Mark Curphey wrote:

> I hear what you are saying but running a web app scanner on a web app 
> is like testing a cars safety by front impact testing only. What 
> happens to side impacts? Rear impacts ? What happens to roll safety? 
> Is it flame proof? Do the seats give off cyanide when set alight? Do 
> the seat belts work? I am not saying they dont have place; you 
> articulate some reasons why they may be appropriate but they are very 
> very limited and very very innacurate.
>
> We have to be careful to set the pace and say what SHOULD be done 
> rather than WHAT is done today. OWASP has the ability to lead the 
> market into doing the right thing. Thats part of the beauty of it and 
> part of our duty in my opinion.
>
> As I can't type as fast as my stomach wants me to move to the 
> breakfast room, how about a teleconference next week to debate this 
> whole issue ?BTW
>
> I have an ASP.NET C# parser I wrote that is shaping up. The major code 
> review players (Fortify, Ounce and Coverity) are all working on Java 
> and ASP.NET modules for their platforms.




From mark.curphey at foundstone.com  Tue Aug 10 15:43:15 2004
From: mark.curphey at foundstone.com (Mark Curphey)
Date: Tue, 10 Aug 2004 15:43:15 -0400
Subject: [OWASP-TESTING] Testing 1
Message-ID: <7274FE6068F1DE49B8AA0258E92C5A3C01D381A0@shasta.foundstone.com>

I have taken Thursday off for the final completion of Testing 1. Sorry
things always come up and this time it was a big Tsunami ;-)

I am also writing a feature for Software Magazine on testing Software
and the project. 



From Daniel at deeper.co.za  Wed Aug 11 03:19:56 2004
From: Daniel at deeper.co.za (Daniel)
Date: Wed, 11 Aug 2004 08:19:56 +0100 (BST)
Subject: [OWASP-TESTING] wikto
Message-ID: <45100.194.203.201.168.1092208796.squirrel@194.203.201.168>

hey all,

i thought this lovely tool should have a use in your toolboxes when doing
app tests

http://www.sensepost.com/research/wikto/

its pretty cool, ive been working with Roelof on testing it, and im impressed

Daniel




From jeff.williams at aspectsecurity.com  Wed Aug 11 15:28:47 2004
From: jeff.williams at aspectsecurity.com (Jeff Williams)
Date: Wed, 11 Aug 2004 15:28:47 -0400
Subject: [OWASP-TESTING] wikto
References: <45100.194.203.201.168.1092208796.squirrel@194.203.201.168>
Message-ID: <00f401c47fd9$6c2d37b0$0464a8c0@intranet.aspectsecurity.com>

Looks interesting. Can you clarify the license it is offered under? All I
could find in the docs is that it is NOT offered with source.  I'd be
interested to know if it is free, can be used commercially, etc...  Is it
under the GPL since Nikto is GPL?

Thanks,

--Jeff

----- Original Message ----- 
From: "Daniel" <Daniel at deeper.co.za>
To: "owasp " <owasp-testing at lists.sourceforge.net>
Sent: Wednesday, August 11, 2004 3:19 AM
Subject: [OWASP-TESTING] wikto


> hey all,
>
> i thought this lovely tool should have a use in your toolboxes when doing
> app tests
>
> http://www.sensepost.com/research/wikto/
>
> its pretty cool, ive been working with Roelof on testing it, and im
impressed
>
> Daniel
>
>
>
> -------------------------------------------------------
> SF.Net email is sponsored by Shop4tech.com-Lowest price on Blank Media
> 100pk Sonic DVD-R 4x for only $29 -100pk Sonic DVD+R for only $33
> Save 50% off Retail on Ink & Toner - Free Shipping and Free Gift.
> http://www.shop4tech.com/z/Inkjet_Cartridges/9_108_r285
> _______________________________________________
> owasp-testing mailing list
> owasp-testing at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/owasp-testing




From roelof at sensepost.com  Thu Aug 12 01:42:33 2004
From: roelof at sensepost.com (Roelof Temmingh)
Date: Thu, 12 Aug 2004 07:42:33 +0200 (SAST)
Subject: [OWASP-TESTING] wikto
In-Reply-To: <00f401c47fd9$6c2d37b0$0464a8c0@intranet.aspectsecurity.com>
Message-ID: <20040812072949.P36200-100000@redknuckle.sensepost.com>

Jeff,Dan & the rest of OWASP,

We havent given much thought to the licensing issue. In fact, we have
killed the link to the app for now, while we sort that out. I guess if we
are using the Nikto DB, and Nikto is GPL..then we have to be GPL as well.
I spoke to the Nikto guys at Defcon, mailed them yesterday - we will see
what they say.

The idea with Wikto was never to make money from it. On the
other hand we dont want to hand out the source just yet (for the fear that
someone will stick a logo on it and try to sell it). The spirit of the
project was that anyone could contribute (we spoke to Saumil Shah at
BlackHat to bully him into building HTTPrint into it - he kinda agree but
time scales are vague and there has not been any formal commitment), and
that contributors can get the source. If you don't want to run the tool as
you fear it has "hidden features" you don't have to. It has no such
features...but you have the right to decide for yourself.

So - bottom line - watch this space while we think about the licensing. It
won't take too long. Oh - and if you have any ideas/feelings on how to
license it - drop us an email at research at sensepost.com.

Regards,
Roelof.

=====================
Roelof Temmingh
+ 27 12 460 0880
GMT+2
=====================
On Wed, 11 Aug 2004, Jeff Williams wrote:

> Looks interesting. Can you clarify the license it is offered under? All I
> could find in the docs is that it is NOT offered with source.  I'd be
> interested to know if it is free, can be used commercially, etc...  Is it
> under the GPL since Nikto is GPL?
>
> Thanks,
>
> --Jeff
>
> ----- Original Message -----
> From: "Daniel" <Daniel at deeper.co.za>
> To: "owasp " <owasp-testing at lists.sourceforge.net>
> Sent: Wednesday, August 11, 2004 3:19 AM
> Subject: [OWASP-TESTING] wikto
>
>
> > hey all,
> >
> > i thought this lovely tool should have a use in your toolboxes when doing
> > app tests
> >
> > http://www.sensepost.com/research/wikto/
> >
> > its pretty cool, ive been working with Roelof on testing it, and im
> impressed
> >
> > Daniel
> >
> >
> >
> > -------------------------------------------------------
> > SF.Net email is sponsored by Shop4tech.com-Lowest price on Blank Media
> > 100pk Sonic DVD-R 4x for only $29 -100pk Sonic DVD+R for only $33
> > Save 50% off Retail on Ink & Toner - Free Shipping and Free Gift.
> > http://www.shop4tech.com/z/Inkjet_Cartridges/9_108_r285
> > _______________________________________________
> > owasp-testing mailing list
> > owasp-testing at lists.sourceforge.net
> > https://lists.sourceforge.net/lists/listinfo/owasp-testing
>




From Daniel at deeper.co.za  Fri Aug 13 08:46:02 2004
From: Daniel at deeper.co.za (Daniel)
Date: Fri, 13 Aug 2004 13:46:02 +0100 (BST)
Subject: [OWASP-TESTING] Phase Two, ver 3
Message-ID: <37620.194.203.201.168.1092401162.squirrel@194.203.201.168>

Hi All,

Attached is ver 3 of the outline, I've tried to implement Mark's comments
from before into the layout and also make it readable.

I'm hoping that using this structure will allow us to join it up with
phase 1 at a later date, but i could be on the wrong path and totally
wrong.

So what do i need from everyone?

- Review the structure and comment
- Start thinking about content and if we need to add/remove any
- Start thinking about the area's you would like to complete

I'm concerned about the amount of people I've been subscribing to the
list, and still only hearing the regulars and none of the new joiners.

Daniel


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Testing_Guide_II_structure_v3.doc
Type: application/msword
Size: 43008 bytes
Desc: not available
Url : http://lists.owasp.org/pipermail/owasp-testing/attachments/20040813/df014fa1/attachment.doc 

From mark at curphey.com  Fri Aug 13 17:50:41 2004
From: mark at curphey.com (Mark Curphey)
Date: Fri, 13 Aug 2004 17:50:41 -0400
Subject: [OWASP-TESTING] Guess What ?
Message-ID: <200408132150.RAA06688@thunderer.cnchost.com>

Something got in the way of finishing Testing 1.0....I don't know what to
say. If anyone wants to take the updates Larry and I have made and complete
the final bits feel free. If not it will be next week for sure;-)




From jfernandez at germinus.com  Mon Aug 23 08:54:44 2004
From: jfernandez at germinus.com (Javier Fernandez-Sanguino)
Date: Mon, 23 Aug 2004 14:54:44 +0200
Subject: [OWASP-TESTING] Comments on the Draft Version 1.0 of the Testing Guide
Message-ID: <4129E914.2010205@germinus.com>

Hi, I'm back of vacation, with a number of comments related to the 
Testing Guide. Since I have a number of them I will just dump them 
here and see if they are useful and/or spark some discussion.

- Chapter 1: The "SDLC". When talking about figure 1 it says "the 
following figure shows a generic SDLC model". I actually believe the 
figure says much more since it also shows the increasing cost of 
fixing bugs in each of the phases. It might be worthwhile stressing 
that out here (even if it is also said further along the document) 
saying that the cost of fixing bugs (generally speaking) increases the 
later they are fixed.

- Chapter 2: It lacks and introduction to what will be covered in the 
Chapter. Something on the lines of: "There are some misconceptions 
when developing a testing methodology to weed out security bugs in 
software. This chapter covers some of the basic principles that should 
be taken into account when testing for security bugs in software."

- Chapter 2: "Think Strategically..." could be improved in the 
discussion about the bug/patch/fix cycle. Specifically, it could 
include the the usual "window of exposure" picture as developed by 
Bruce Schenier at http://www.schneier.com/crypto-gram-0009.html#1. 
Moreover, it could mention that, generally speaking, the time between 
a vulnerability is discovered and an automated attack is developed is 
continuously going down leaving no time to apply patches (worms show 
have shown this fact over the years). Even when developing custom 
software (i.e. software which will not be pushed out to the wide 
public) it might be worth including a direct reference to @stake's 
article (included in the references at the end) describing the cost to 
deploy patches in environments vs. the cost of fixing them in the 
design phase. I think it's also worth substituting (or enhancing) the 
'Wrong!' statement there with something on the lines of

"There are several wrong assumptions in this line of thinking: patches 
interfere with the normal operations and might break existing 
applications, not all the product's consumers will apply patches 
precisely because of this issue or because they lack knowledge about 
the patch's existance and it is being demonstrated that the typical 
window of vulnerability does not provide enought time for patch 
installation in the time between a a vulnerability is uncovered and an 
automated attack against is developed and released."

- Chapter 2: "The SDLC is King". Maybe enhance the checklist with 
something on the lines of:

"Security testing should be done withing the framework of an existing 
SDLC in order to produce software with as few security bugs as 
possible. Thus, it must blend with all of the phases of a SDLC, from 
the early stages of design to the last stages of operations and 
maintenance."

- Chapter 2: "Test Early and often". Regarding developers education:

"Knowledge of typical security vulnerabitilies is a big advantage for 
developers since it will help them avoid common mistakes. Although new 
libraries, tools or languages might help desing better programs (with 
less security bugs) new threats arise constantly and developers must 
be aware of those that affect the software they are developing. 
Education in security testing also helps developers acquire the 
appropiate mindset to test and application from an attacker's 
perspective."

- Chapter 2: "Mindset". Add the term 'thinking out of the box' to the 
"Thnk like an attacker or cracker" checklist item.

- Chapter 2: "Use The Right Tools". I think the "Shouldn't bring a 
knife to a gun fight item" should be removed or improved with a more 
detailed explanation there.

- Chapter 2: "Develop Metrics". Add the following items:

	- Create consistent metrics to determine the security level of your 
code. The OWASP Metrics project can help you here.
	- Automate metrics extraction from available code
	- Analyse the evolution of values derived from metrics between the 
different SL

It might be also worth referencing
http://csdl.computer.org/comp/mags/sp/2004/03/j3018abs.htm
which steems from http://www.cyberpartnership.org/Software%20Pro.pdf
and http://www.cyberpartnership.org/SDLCFULL.pdf
It talks about an average number of defects per # of line of code in 
an normal software development process versus one that introduces a 
security methodology in its SDLC.

- Chapter 4: It's also missing an introduction to the chapter. 
Moreover, I don't understand why this chapter covers only Review and 
Manual inspections instead of briefly talking about the different 
techniques (reviews, penetration testing, etc...) and leave up the 
detail regarding reviews to a separate chapter. I believe the title 
'Testing Techniques Explained' is misleading.

- Chapter 4: "Studies and research reports show that maximum failure 
of a ..." this phrase is ok but it is missing up a reference to a 
paper backing up the point.

- Chapter 4: "What is an inspection?" I don't think it really defines 
whan an inspection is. It talks about different roles in the 
inspection process and how meetings should be conducted, but it does 
not say: "An inspection is the process in which different 
individiduals, which do not belong to the development team producing 
the software, inspects the software under development."

- Chapter 4: "Elaboration phase" The final paragraph talks about legal 
requirements broadly. It would be nice to describe some common aspects 
regarding legal requirements. For example, in the EU is mandatory for 
personal data to be treated with due care in applications.
More information at 
http://europa.eu.int/comm/internal_market/privacy/law_en.htm. 
Directive 95/46/EC says:

" (46) Whereas the protection of the rights and freedoms of data 
subjects with regard to the processing of personal data requires that 
appropriate technical and organizational measures be taken, both at 
the time of the design of the processing system and at the time of the 
processing itself, particularly in order to maintain security and 
thereby to prevent any unauthorized processing;"

This introduces obligations to the software developer. Some countries 
(such as Spain) obligue companies to determine the sensitivity level 
of the personal data stored and to take appropiate measures based on 
the sensitivity level, this includes encryption of stored data and 
audits of access to that data.

In the US references to the HIPAA and similar laws might apply.

- Chapter 4: "Code Reviews" I find it confusing that code reviews is 
included here as well as in Chapter 5.

- Chapter 4: "Code Reviews" I don't find the name of "Scripting 
vulnerabilities" appropiate to that checklist item, I believe that 
"Source code integrity" might be more appropiate there.

- Chapter 5: "Source code review - Introduction" I would add, to the 
end of the final paragraph: "as opposed to black box testing, also 
code penetration testing which is covered in chapter 6"

- Chapter 5: "Is source code reviewed needed?" States that only source 
code review can uncover trojans which is not really true. See 
"Reflections on Trusting Trust" 
(http://cm.bell-labs.com/who/ken/trust.html). Actually, I don't 
understand why this same example is used later as a reference when 
it's actually these kind of security bugs that cannot be uncovered by 
software review. Note that Ken Thompson splicitly says that the source 
code of the compiler is removed so that no source code revision can 
detect the trojan making use of the chicken-and-egg status of C code 
vs. the compiler. I don't believe this example should be used as one 
security bug that could be uncovered by source code review but, 
rather, as a bug that would never be uncovered by it.

- Chapter 6: "Penetration Testing" Maybe it's worth adding in the 
introduction that penetration testing is in many cases done to test 
the production environment. This has the disadvantage of putting at 
risk the production environment (a pentester could screw it up and 
remove the backend database after all) but has the advantage of 
testing the actual deployment of the application (and the 
infraestructure it depends on).

- Chapter 6: "Advantages and disadvantages" I wouldn't count as an 
advantage, but rather as a fact, that penetration testing results vary 
with the effort (and knowledge) dedicated by the pentesting team. 
However, it does not usually scale. More effort might, or might not, 
detect new vulnerabilities it usually gets to a point when you will 
not detect more vulnerabilities regardless of the time dedicated to 
it. It is true, however, that less effort will usually detect less 
vulnerabilities. This scaling is not something you can depend on however.

- Chapter 6: "Advantages and disadvantages" I would add as an 
advantage that penetration testing usually reviews systems and 
architectures that the application relies on (firewalls, web service 
or application servers setup, etc...)

- Chapter 6: "Advantages and disadvantages" says "Accuracy is a 
problem (...) must rely on information sent from the application" 
which is not 100% true. Pentesters also realy on the information sent 
by the infraestructure that supports the application, think of a 
misconfigured webserserver that returns detailed information on the 
programming error that breaks and application, or when it fails when 
accessing a backend...

- Chapter 6: "Advantages and disadvantages" I would add as a 
disadvantage that pentesting and specially automated scanners 
concentrate on common deployment mistakes or vulnerabilities and do 
not necessarily concentrate on the company's concerns (or specific risks)

- Chapter 6: "Advantages and disadvantages" I would also add as a 
disadvantage that pentesting teams are not usually focused on 
applications but on broader systems (think OSSTMM for example).

- Chapter 6: "Why is PenTesting Needed?" Besides server-level 
vulnerabilities pentesting also finds out configuration 
vulnerabilities and also issues when deploying the application. For 
example, in some situations the code deployed into production might 
not be the same code as the one developed or the environment it is 
deployed to varies. It might be worth noting that too.

- Chapter 6: "Approaches to Penetration testing" I think it's best to 
order the different styles by order of preference (i.e. Prima Donna last)

- Chapter 6: "Approaches to Penetration testing - Capture the flag" It 
might be worth stressing there that these in these tests a test that 
fails does not mean anything. Moreover, you might never know if the 
pentesting team actually _did_ anything.

- Chapter 6: "Guessing the architecture" A penetation tester also 
tries to determine how it is implemented and what technology is used 
since some flaws are specific to language or technology.

- Chapter 6: "Viewing Source Code to Better Understand..." It fails to 
point out that some server vulnerabilities might disclose source code 
(or fragments of it) which might help in the analysis. Also, in 
penetration testing source code is sometimes obtained from side 
channels used for publishing (think of an open FTP server)

- Chapter 6: "So Why Not Automate all of this?" It might be worth 
adding a list of things an automated scanner is good at, for example: 
brute forcing user accounts, finding URLs that are not published 
(through dictionary attacks against an application), finding typical 
input handling errors and common server security bugs due to 
misconfiguration or to unpatched vulnerabilities.

- Chapter 7: "Example 2: Bad Cryptopgraphy" Has a typo it says:

"Clearly, aw we explain the scheme..."

it should say

"Clearly, as we explain the scheme..."

- Appendix A: Testing Tools, does not include some open source blax 
box scanners such as Nessus (it does have some plugins to detect web 
application vulnerabilities) and Nikto/Whisker. It might be worth 
adding also some applications used as intermediate proxies for black 
box scanning (SPIKE does some of this too) like httpush ( 
http://sourceforge.net/projects/httpush), Exodus, Achilles 
(http://www.digizen-security.com/downloads/achilles-0-27.zip). 
Commercial: Paessler Site Inspector 
(http://www.paessler.com/products/psi) formerly IEBooster) and maybe 
some others might be relevant here...


That's more or less all the comments I had in mind, I hope they are 
useful...

Regards

Javier




From juan.calderon at ge.com  Tue Aug 24 19:59:35 2004
From: juan.calderon at ge.com (Calderon, Juan Carlos (GE Commercial Finance, NonGE))
Date: Tue, 24 Aug 2004 19:59:35 -0400
Subject: [OWASP-TESTING] OWASP-Spanish mailing list is up
Message-ID: <999169B0CC0F2A418615C28851C5C0710740BC9D@CINMLVEM09.e2k.ad.ge.com>

Hello all

I'm pound to announce the OWASP-Spanish list is up and running, This list is intended to help coordinate efforts for translating OWASP documents to spanish and to provide support for new OWASP Spanish-spoken readers.

As a little update to all of you, we just finished OWASP Top Ten 2004 translation (currently at Tech Edition) and will be soon released,  Now we are starting to work on Web Application Pen Test Checklist 1.2, and I hope we can release it in 3 weeks more o less. 

Thanks to people contributing in this effort to make OWASP open to readers of 2nd more-spoken-language in the world.

"Unete a nosotros"

Juan C Calderon
Sr Application Security Auditor
www.softtek.com

IMPORTANTE: Los documentos y archivos que se acompa?an a esta transmisi?n, contienen informaci?n confidencial la cual es legalmente secreta. Esta informaci?n puede ser usada ?nicamente por el destinatario cuyo nombre aparece inserto en esta transmisi?n. Si usted ha recibido esta transmisi?n por error, notif?quenos inmediatamente por esta misma v?a, y borre el archivo y sus anexos. Se hace de su conocimiento por medio de esta nota, que cualquier divulgaci?n, copia, distribuci?n o toma de cualquier acci?n derivada de la informaci?n confiada en esta transmisi?n, queda estrictamente prohibido, el incumplimiento de esto genera responsabilidad legal.

IMPORTANT: The documents and files attached to this transmission contain confidential information that must be kept secret by law. This information is for the exclusive use of the specified recipient whose name appears in this transmission. If you have received this message by mistake, please notify us immediately by return e-mail and delete the file and its attachments. You are hereby notified that any dissemination, copying, distribution or adoption of any action arising from the confidential information contained herein is strictly prohibited. Any violation will be penalized by law. 




From mark at curphey.com  Fri Aug 27 23:01:24 2004
From: mark at curphey.com (Mark Curphey)
Date: Fri, 27 Aug 2004 23:01:24 -0400
Subject: [OWASP-TESTING] FW: http://www.ussecurityawareness.org/highres/infosec-program.html
Message-ID: <200408280301.XAA07046@devonshire.cnchost.com>

All take a bow !

3 r d link down! 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://lists.owasp.org/pipermail/owasp-testing/attachments/20040827/7b971e0a/attachment.html 

From mark at curphey.com  Mon Aug 30 19:00:04 2004
From: mark at curphey.com (Mark Curphey)
Date: Mon, 30 Aug 2004 19:00:04 -0400
Subject: [OWASP-TESTING] Any news on the updates Andrew was making for Testing version 1 ?
Message-ID: <200408302300.TAA04014@warspite.cnchost.com>




