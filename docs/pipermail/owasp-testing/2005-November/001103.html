<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [OWASP-TESTING] WAPT submission, revised
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:owasp-testing%40lists.owasp.org?Subject=%5BOWASP-TESTING%5D%20WAPT%20submission%2C%20revised&In-Reply-To=4382dfcd.1aaa0f3b.1340.4461%40mx.gmail.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001102.html">
   <LINK REL="Next"  HREF="001105.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[OWASP-TESTING] WAPT submission, revised</H1>
    <B>Javier Fernandez-Sanguino</B> 
    <A HREF="mailto:owasp-testing%40lists.owasp.org?Subject=%5BOWASP-TESTING%5D%20WAPT%20submission%2C%20revised&In-Reply-To=4382dfcd.1aaa0f3b.1340.4461%40mx.gmail.com"
       TITLE="[OWASP-TESTING] WAPT submission, revised">jfernandez at germinus.com
       </A><BR>
    <I>Tue Nov 22 07:06:40 EST 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="001102.html">[OWASP-TESTING] WAPT submission, revised
</A></li>
        <LI>Next message: <A HREF="001105.html">[OWASP-TESTING] WAPT submission, revised
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1103">[ date ]</a>
              <a href="thread.html#1103">[ thread ]</a>
              <a href="subject.html#1103">[ subject ]</a>
              <a href="author.html#1103">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Mauro Bregolin wrote:

&gt;<i> Javier,
</I>&gt;<i> 
</I>&gt;<i> I realized I (dumbly) overlooked your previous message and failed to read
</I>&gt;<i> your original txt attachment. That's why your input never made it to the
</I>&gt;<i> revised version.
</I>&gt;<i> 
</I>&gt;<i> Concerning your original comments regarding strategies to spot files, I do
</I>&gt;<i> not completely agree.
</I>&gt;<i> I wouldn't say that looking at access times is less FP-prone than the method
</I>&gt;<i> I was writing about (finding files according to extensions). How much &quot;old&quot;
</I>&gt;<i> is old enough to account for being unreferenced? One month? Three months?
</I>&gt;<i> One week? Your method (which has its own merits) wouldn't notice the huge
</I>&gt;<i> .tar file left yesterday by a careless sysadmin in the web server tree,
</I>&gt;<i> until it &quot;ages&quot; up to the point of being considered &quot;old and unreferenced&quot;
</I>&gt;<i> (provided it doesn't get accessed by an evil hacker in the interim... which
</I>&gt;<i> would keep it &quot;legitimate&quot; for another while).
</I>
I didn't want to imply that my approach was the only approach you 
should take. I just listed several approaches that would allow you to 
find backup/unreferenced files. Summarising, it's best if you do all 
three:

a) find files based on extension
b) find files with old access time
c) look at the logs (optionally traversing the server through a robot 
or manual session) and review which files are *not* being accessed

Those three combined would help spot most of those and weed out false 
positives / negatives of each approach if used exclusively.

For example, if you have a 'login.asp' in your system, but then moved 
over to a different authentication system 'login_pki.asp'. You might 
not be able to use a) in order to find that 'login.asp' is, indeed, 
not being used any more and can be a potential risk since, after all, 
it is a legitimate file extension for your server. You don't catch 
that with a) but you can catch it with b) or c)

&gt;<i> In my opinion, there's no silver bullet in the form of a fully automatic
</I>&gt;<i> solution, because all strategies are based on euristhics, and as such are
</I>
(...)

That's why I propose listing all of them. It seems we agree here.

&gt;<i> Crawling may help solve this, but depending on the web app structure may be
</I>&gt;<i> difficult to fully automatize (anyway, it's surely another source of input
</I>&gt;<i> worth considering).
</I>
Notice that you can either have automatic crawling or &quot;guided&quot; 
crawling. Or, even, review logs from your user's accesses and infer 
from there.

&gt;<i> A good approach would be to combine both search criteria (and possibly
</I>&gt;<i> others that might be devised in addition).
</I>
Agreed.

&gt;<i> Best of all, however, is enforcing strong security policies. Spotting files
</I>&gt;<i> means you are *late*, and did something wrong. Found a .old? Someone did
</I>&gt;<i> in-place editing, what about your change management procedures? Found a .zip
</I>&gt;<i> or a .tar in the wrong place? This denotes inappropriate behavior as well.
</I>&gt;<i> After a software upgrade you find unused JSPs left over? You have some darn
</I>&gt;<i> problem with your software upgrade procedure... etc. etc. But, of course,
</I>&gt;<i> life is different and these things happen and will continue to happen, and
</I>&gt;<i> we must have a way to check.
</I>
That's why having proper policies for operation and maintenance of 
servers should be listed as 'countermeasures'. Indeed, that is already 
there in the section.


&gt;<i> I will reflect this in the chapter and go through your other comments as
</I>&gt;<i> well.
</I>
Cool, thanks.

Regards


Javier


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001102.html">[OWASP-TESTING] WAPT submission, revised
</A></li>
	<LI>Next message: <A HREF="001105.html">[OWASP-TESTING] WAPT submission, revised
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1103">[ date ]</a>
              <a href="thread.html#1103">[ thread ]</a>
              <a href="subject.html#1103">[ subject ]</a>
              <a href="author.html#1103">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.owasp.org/mailman/listinfo/owasp-testing">More information about the Owasp-testing
mailing list</a><br>
</body></html>
