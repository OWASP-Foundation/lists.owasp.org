From beto.cuevas.v at gmail.com  Tue May  7 23:34:34 2013
From: beto.cuevas.v at gmail.com (alberto cuevas)
Date: Tue, 7 May 2013 18:34:34 -0500
Subject: [Owasp-testing] CVSS v2
Message-ID: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>

Hello,

In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes :


"Ideally, there would be a universal risk rating system that would
accurately estimate all risks for all
organization. But a vulnerability that is critical to one organization may
not be very important to another.
So we're presenting a basic framework here that you should customize for
your organization. "

Whereby, the following questions came to mind:

- Is a good idea to use CVSS v2 to score pentest web results? (I think so
that temporal and environmental metrics can be produced diferentes ratings
which determines how critical the vulnerabilitie is for one or another
organization.)

- I read that CVSS v2 has some limitations for score combined
vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
solve this issue?

I wonder if there are opinions on the ups and downs of using CVSS v2 to
rate the pentest web results. I appreciate in advance any help or
information you can give me.

Best Regards,

Beto
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130507/5f76870d/attachment.html>

From eoin.keary at owasp.org  Tue May  7 23:43:46 2013
From: eoin.keary at owasp.org (Eoin)
Date: Wed, 8 May 2013 00:43:46 +0100
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
Message-ID: <29C301DD-BD11-4932-84ED-2A83344296F6@owasp.org>

CVSS pretty much is devoid of context.
It does not consider client attacks IMHO. It's more of a traditional security issue rating system. PCI mapping to CVSS v2 for appsec is pretty poor. 

Eoin Keary
Owasp Global Board
+353 87 977 2988


On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote:

> Hello,
> 
> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes :
> 
> "Ideally, there would be a universal risk rating system that would accurately estimate all risks for all 
> organization. But a vulnerability that is critical to one organization may not be very important to another. 
> So we're presenting a basic framework here that you should customize for your organization. "
> 
> Whereby, the following questions came to mind:
> 
> - Is a good idea to use CVSS v2 to score pentest web results? (I think so that temporal and environmental metrics can be produced diferentes ratings which determines how critical the vulnerabilitie is for one or another organization.)
> 
> - I read that CVSS v2 has some limitations for score combined vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to solve this issue?
> 
> I wonder if there are opinions on the ups and downs of using CVSS v2 to rate the pentest web results. I appreciate in advance any help or information you can give me.
> 
> Best Regards,
> 
> Beto
> _______________________________________________
> Owasp-testing mailing list
> Owasp-testing at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/owasp-testing
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130508/79783db9/attachment.html>

From sysvar0 at gmail.com  Wed May  8 00:35:07 2013
From: sysvar0 at gmail.com (jm)
Date: Tue, 7 May 2013 20:35:07 -0400
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CANBMyhuicieiVfvX7EzDKiAWNLK-w8iEP_u=x+BknHLnFTkqjw@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<29C301DD-BD11-4932-84ED-2A83344296F6@owasp.org>
	<CANBMyhuicieiVfvX7EzDKiAWNLK-w8iEP_u=x+BknHLnFTkqjw@mail.gmail.com>
Message-ID: <CANBMyhu75kcZGVuEOh8PcX6xKNLMH3cnOsQ=xi47qu8FrcLhrw@mail.gmail.com>

Vulnerability-centric
Qualitative
Coarse-grained
Simple
Concise
Contextually extensible
Open framework
Inconsistent implementations
In relative wide-use
One-to-one mappings - no scale well for multiple vulnerabilites

jM

> El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?:
>
>> CVSS pretty much is devoid of context.
>> It does not consider client attacks IMHO. It's more of a traditional
security issue rating system. PCI mapping to CVSS v2 for appsec is pretty
poor.
>>
>> Eoin Keary
>> Owasp Global Board
>> +353 87 977 2988
>>
>>
>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote:
>>
>>> Hello,
>>>
>>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide
v3, notes :
>>>
>>>
>>> "Ideally, there would be a universal risk rating system that would
accurately estimate all risks for all
>>> organization. But a vulnerability that is critical to one organization
may not be very important to another.
>>> So we're presenting a basic framework here that you should customize
for your organization. "
>>>
>>> Whereby, the following questions came to mind:
>>>
>>> - Is a good idea to use CVSS v2 to score pentest web results? (I think
so that temporal and environmental metrics can be produced diferentes
ratings which determines how critical the vulnerabilitie is for one or
another organization.)
>>>
>>> - I read that CVSS v2 has some limitations for score combined
vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
solve this issue?
>>>
>>> I wonder if there are opinions on the ups and downs of using CVSS v2 to
rate the pentest web results. I appreciate in advance any help or
information you can give me.
>>>
>>> Best Regards,
>>>
>>> Beto
>>>
>>> _______________________________________________
>>> Owasp-testing mailing list
>>> Owasp-testing at lists.owasp.org
>>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>
>>
>> _______________________________________________
>> Owasp-testing mailing list
>> Owasp-testing at lists.owasp.org
>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130507/eb1d0b47/attachment.html>

From beto.cuevas.v at gmail.com  Wed May  8 18:06:06 2013
From: beto.cuevas.v at gmail.com (alberto cuevas)
Date: Wed, 8 May 2013 13:06:06 -0500
Subject: [Owasp-testing] CVSS v2
Message-ID: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>

Hello,

In the OWASP Testing Guide, proposes the use of OWASP Risk Rating
Methodology (actually we used this for pentest web results).

- This could be noted as a standard methodology? (I guess the majority of
the community uses this)
- Has anyone seen the limits of this methodology in certain situations?
-  Which other methodologies can be recommended to use rather than OWASP
Risk Rating Methodology?

Thanks in advance for your guidance.

Beto

2013/5/7 jm <sysvar0 at gmail.com>

> Vulnerability-centric
> Qualitative
> Coarse-grained
> Simple
> Concise
> Contextually extensible
> Open framework
> Inconsistent implementations
> In relative wide-use
> One-to-one mappings - no scale well for multiple vulnerabilites
>  El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?:
>
> CVSS pretty much is devoid of context.
>> It does not consider client attacks IMHO. It's more of a traditional
>> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty
>> poor.
>>
>> Eoin Keary
>> Owasp Global Board
>> +353 87 977 2988
>>
>>
>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote:
>>
>> Hello,
>>
>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes :
>>
>>
>> "Ideally, there would be a universal risk rating system that would
>> accurately estimate all risks for all
>> organization. But a vulnerability that is critical to one organization
>> may not be very important to another.
>> So we're presenting a basic framework here that you should customize for
>> your organization. "
>>
>> Whereby, the following questions came to mind:
>>
>> - Is a good idea to use CVSS v2 to score pentest web results? (I think so
>> that temporal and environmental metrics can be produced diferentes ratings
>> which determines how critical the vulnerabilitie is for one or another
>> organization.)
>>
>> - I read that CVSS v2 has some limitations for score combined
>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
>> solve this issue?
>>
>> I wonder if there are opinions on the ups and downs of using CVSS v2 to
>> rate the pentest web results. I appreciate in advance any help or
>> information you can give me.
>>
>> Best Regards,
>>
>> Beto
>>
>> _______________________________________________
>> Owasp-testing mailing list
>> Owasp-testing at lists.owasp.org
>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>
>>
>> _______________________________________________
>> Owasp-testing mailing list
>> Owasp-testing at lists.owasp.org
>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130508/03aa7279/attachment.html>

From christian.heinrich at cmlh.id.au  Thu May  9 03:01:02 2013
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Thu, 9 May 2013 13:01:02 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <29C301DD-BD11-4932-84ED-2A83344296F6@owasp.org>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<29C301DD-BD11-4932-84ED-2A83344296F6@owasp.org>
Message-ID: <CAGKxTUR6vqsH62554_1aQfzQteHT-4f3YxtFrGhyKMe93ukyEw@mail.gmail.com>

Eoin,

CVSSv3 has been in active development since June 2012 (i.e. for almost a
year) and the intent is to address the lack of consideration of the "end
user", i.e. the "client" web browser and has been listed/recorded/minuted
by the CVSS-SIG as per
http://cmlh.id.au/post/25150772855/cvssv3-call-subjects

Since both CVSSv2 and CVSS(v1) consider the lifecycle of a vulnerability
(i.e. from discovery to the development of an exploit) it is *not*
comparable to a "traditional security issue rating system" such as AS/NZS
4360, which has been updated and released as an ISO standard in 2009 i.e.
ISO 31000.

On Wed, May 8, 2013 at 9:43 AM, Eoin <eoin.keary at owasp.org> wrote:

> CVSS pretty much is devoid of context.
> It does not consider client attacks IMHO. It's more of a traditional
> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty
> poor.
>


-- 
Regards,
Christian Heinrich

http://cmlh.id.au/contact
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130509/b68c2e20/attachment.html>

From christian.heinrich at cmlh.id.au  Thu May  9 04:29:41 2013
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Thu, 9 May 2013 14:29:41 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>
References: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>
Message-ID: <CAGKxTUS6ezHTvybtxVFjtYbAC2n4s-jS9y8m16edzAag3jeMtA@mail.gmail.com>

Alberto,

The OWASP Risk Rating Methodology is an exceptionally poor implementation
of integrating two discrete processes i.e. threat modelling with a
"traditional security issue rating" (to reuse Eoin's quote from
http://lists.owasp.org/pipermail/owasp-testing/2013-May/002139.html).

For instance, Google had been aware of the issue with Open Redirects since
2009 (and maybe earlier)
http://googlewebmastercentral.blogspot.com.au/2009/01/open-redirect-urls-is-your-site-being.html.
 This lead to Google indirectly (since this was the only example the
greater webappsec community could use as an example) questioning its
inclusion in the Top Ten 2010 release.

You can observe other examples of the above on the threads related to the
2010 and the proposed 2013 releases of the OWASP Top Ten i.e.
https://www.owasp.org/index.php/Top_10_2013-Note_About_Risks

Another issue with the OWASP Risk Rating Methodology is the greater
commercial exploitation of OWASP by "Aspect Security" of which the thread
is available from
http://lists.owasp.org/pipermail/owasp-board/2013-March/011679.html

Political issues aside, the recommendation I would propose in the context
of an independent auditor presenting the results of a penetration test is
to:

   1. Quote the "impact"/"severity"/"damage consequence"/"base metric" of
   the various sources only, i.e. CVSS (based on the CVE score recorded at
   http://web.nvd.nist.gov/view/vuln/search for independence), OWASP Top
   Ten (i.e. based on their risk rating methodology), etc.
   2. Include a recommendation to measure the "inherent" (i.e. before the
   implementation of controls) and "residual" (i.e. after the implementation
   of controls) risk since audit, and therefore the board are more accepting
   of ISO 31000 as part of their overall risk management.

Of note, I have only measured DREAD (Microsoft) for web applications I have
been involved in the secure development of i.e. *not* as an independent
auditor (where I include DREAD as a recommendation in the Executive Brief
of a penetration testing deliverable nonetheless to raise its awareness
with the intended audience).

You might also want to include a recommendation in the Executive Brief to
consider the threat agent based on STRIDE (Microsoft),
http://www.cert.org/octave/, etc even if they have already.  Please note
that threat agents are not directly related to the
"impact"/"severity"/"damage consequence" in the context of ISO 31000, OWASP
Top Ten, CVSS (i.e. "Base Metrics" only i.e. not "Temporal" Metrics).

On Thu, May 9, 2013 at 4:06 AM, alberto cuevas <beto.cuevas.v at gmail.com>wrote:

> In the OWASP Testing Guide, proposes the use of OWASP Risk Rating
> Methodology (actually we used this for pentest web results).
>
> - This could be noted as a standard methodology? (I guess the majority of
> the community uses this)
> - Has anyone seen the limits of this methodology in certain situations?
> -  Which other methodologies can be recommended to use rather than OWASP
> Risk Rating Methodology?
>

-- 
Regards,
Christian Heinrich

http://cmlh.id.au/contact
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130509/e7b03948/attachment.html>

From sysvar0 at gmail.com  Thu May  9 07:36:04 2013
From: sysvar0 at gmail.com (jm)
Date: Thu, 9 May 2013 03:36:04 -0400
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>
References: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>
Message-ID: <CANBMyhsJvcjhH_eK3TWmj=w8GnM8rjkFu0gwUb0-M0TVt6QEcA@mail.gmail.com>

I look at the OWASP risk rating methodology.

My comments as follows.

It does not really distinguish between a specific occurence and
the prevalence or distribution of an affected application in a given
context.
It does not sufficiently factor in the value or the role of the application
within the context to the organization, the execution environment, or the
remediation cost.

In Threat Agent factors.
-Size of group of threat does not qualify type.
-Opportunity should speak to motive and not to a level of access.

In Vulnerability factors.
-Discoverability and exploitability are not very helpful in expressing the
complexity of the attack.
-Under awareness, I do not think that how well known a vulnerability is for
a group of threat agents is a reasonable question to ask, and am not
certain of a practical scenario where hidden would be assigned. It could
presume knowledge about the MO of a threat profile - not typically
vulnerability-centric, and this level of detail may be beyond the reach of
the organization or of the assessor. Instead, a more reasonable question
might be centered around any evidence of disclosure of said vulnerability
in the public domain, and perhaps a qualifier describing the level of
confidence of the report and whether the issue was acknowledged by the
vendor.
A qualifier describing the age of the vulnerability could be useful
Around intrusion detection, two properties seem to be implied, the
detectability or ease of detection and the action of review. The ease of
detection from the generation of a cyber observable may depend on other
components such as a system-centric configuration settings, and the
reviewing, freqency of review, etc. speak to potential / components of
another system.









On Wed, May 8, 2013 at 2:06 PM, alberto cuevas <beto.cuevas.v at gmail.com>wrote:

> Hello,
>
> In the OWASP Testing Guide, proposes the use of OWASP Risk Rating
> Methodology (actually we used this for pentest web results).
>
> - This could be noted as a standard methodology? (I guess the majority of
> the community uses this)
> - Has anyone seen the limits of this methodology in certain situations?
> -  Which other methodologies can be recommended to use rather than OWASP
> Risk Rating Methodology?
>
> Thanks in advance for your guidance.
>
> Beto
>
> 2013/5/7 jm <sysvar0 at gmail.com>
>
>> Vulnerability-centric
>> Qualitative
>> Coarse-grained
>> Simple
>> Concise
>> Contextually extensible
>> Open framework
>> Inconsistent implementations
>> In relative wide-use
>> One-to-one mappings - no scale well for multiple vulnerabilites
>>  El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?:
>>
>> CVSS pretty much is devoid of context.
>>> It does not consider client attacks IMHO. It's more of a traditional
>>> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty
>>> poor.
>>>
>>> Eoin Keary
>>> Owasp Global Board
>>> +353 87 977 2988
>>>
>>>
>>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote:
>>>
>>> Hello,
>>>
>>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes :
>>>
>>>
>>> "Ideally, there would be a universal risk rating system that would
>>> accurately estimate all risks for all
>>> organization. But a vulnerability that is critical to one organization
>>> may not be very important to another.
>>> So we're presenting a basic framework here that you should customize for
>>> your organization. "
>>>
>>> Whereby, the following questions came to mind:
>>>
>>> - Is a good idea to use CVSS v2 to score pentest web results? (I think
>>> so that temporal and environmental metrics can be produced diferentes
>>> ratings which determines how critical the vulnerabilitie is for one or
>>> another organization.)
>>>
>>> - I read that CVSS v2 has some limitations for score combined
>>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
>>> solve this issue?
>>>
>>> I wonder if there are opinions on the ups and downs of using CVSS v2 to
>>> rate the pentest web results. I appreciate in advance any help or
>>> information you can give me.
>>>
>>> Best Regards,
>>>
>>> Beto
>>>
>>> _______________________________________________
>>> Owasp-testing mailing list
>>> Owasp-testing at lists.owasp.org
>>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>>
>>>
>>> _______________________________________________
>>> Owasp-testing mailing list
>>> Owasp-testing at lists.owasp.org
>>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130509/df4151e6/attachment-0001.html>

From jim.manico at owasp.org  Thu May  9 07:54:44 2013
From: jim.manico at owasp.org (Jim Manico)
Date: Thu, 09 May 2013 17:54:44 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CANBMyhsJvcjhH_eK3TWmj=w8GnM8rjkFu0gwUb0-M0TVt6QEcA@mail.gmail.com>
References: <CACWUwBx95OyfV6sN3EJaGY5j+JNPCPse=QvTJ=KGYCq7iXHWdQ@mail.gmail.com>
	<CANBMyhsJvcjhH_eK3TWmj=w8GnM8rjkFu0gwUb0-M0TVt6QEcA@mail.gmail.com>
Message-ID: <518B5644.7080109@owasp.org>

Keep in mind, all of the factors can be changed.

I am most worried about the math that is used to compute overall business impact. It's an average of business factors which might improperly reduce the overall business impact. 

Check out the section on "repeatable process" under https://www.owasp.org/index.php/OWASP_Risk_Rating_Methodology#Business_Impact_Factors to see what I'm talking about.

I think you want to set specific weights for each business impact factors specific to the context of your business and let the highest value be the true overall business impact.

And really, when it comes to true risk mathematics, this is incredibly lightweight. I would not run a risk practice on this fuzzy math alone.

Cheers,
Jim




> I look at the OWASP risk rating methodology.
> 
> My comments as follows.
> 
> It does not really distinguish between a specific occurence and
> the prevalence or distribution of an affected application in a given
> context.
> It does not sufficiently factor in the value or the role of the application
> within the context to the organization, the execution environment, or the
> remediation cost.
> 
> In Threat Agent factors.
> -Size of group of threat does not qualify type.
> -Opportunity should speak to motive and not to a level of access.
> 
> In Vulnerability factors.
> -Discoverability and exploitability are not very helpful in expressing the
> complexity of the attack.
> -Under awareness, I do not think that how well known a vulnerability is for
> a group of threat agents is a reasonable question to ask, and am not
> certain of a practical scenario where hidden would be assigned. It could
> presume knowledge about the MO of a threat profile - not typically
> vulnerability-centric, and this level of detail may be beyond the reach of
> the organization or of the assessor. Instead, a more reasonable question
> might be centered around any evidence of disclosure of said vulnerability
> in the public domain, and perhaps a qualifier describing the level of
> confidence of the report and whether the issue was acknowledged by the
> vendor.
> A qualifier describing the age of the vulnerability could be useful
> Around intrusion detection, two properties seem to be implied, the
> detectability or ease of detection and the action of review. The ease of
> detection from the generation of a cyber observable may depend on other
> components such as a system-centric configuration settings, and the
> reviewing, freqency of review, etc. speak to potential / components of
> another system.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Wed, May 8, 2013 at 2:06 PM, alberto cuevas <beto.cuevas.v at gmail.com>wrote:
> 
>> Hello,
>>
>> In the OWASP Testing Guide, proposes the use of OWASP Risk Rating
>> Methodology (actually we used this for pentest web results).
>>
>> - This could be noted as a standard methodology? (I guess the majority of
>> the community uses this)
>> - Has anyone seen the limits of this methodology in certain situations?
>> -  Which other methodologies can be recommended to use rather than OWASP
>> Risk Rating Methodology?
>>
>> Thanks in advance for your guidance.
>>
>> Beto
>>
>> 2013/5/7 jm <sysvar0 at gmail.com>
>>
>>> Vulnerability-centric
>>> Qualitative
>>> Coarse-grained
>>> Simple
>>> Concise
>>> Contextually extensible
>>> Open framework
>>> Inconsistent implementations
>>> In relative wide-use
>>> One-to-one mappings - no scale well for multiple vulnerabilites
>>>  El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?:
>>>
>>> CVSS pretty much is devoid of context.
>>>> It does not consider client attacks IMHO. It's more of a traditional
>>>> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty
>>>> poor.
>>>>
>>>> Eoin Keary
>>>> Owasp Global Board
>>>> +353 87 977 2988
>>>>
>>>>
>>>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote:
>>>>
>>>> Hello,
>>>>
>>>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes :
>>>>
>>>>
>>>> "Ideally, there would be a universal risk rating system that would
>>>> accurately estimate all risks for all
>>>> organization. But a vulnerability that is critical to one organization
>>>> may not be very important to another.
>>>> So we're presenting a basic framework here that you should customize for
>>>> your organization. "
>>>>
>>>> Whereby, the following questions came to mind:
>>>>
>>>> - Is a good idea to use CVSS v2 to score pentest web results? (I think
>>>> so that temporal and environmental metrics can be produced diferentes
>>>> ratings which determines how critical the vulnerabilitie is for one or
>>>> another organization.)
>>>>
>>>> - I read that CVSS v2 has some limitations for score combined
>>>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
>>>> solve this issue?
>>>>
>>>> I wonder if there are opinions on the ups and downs of using CVSS v2 to
>>>> rate the pentest web results. I appreciate in advance any help or
>>>> information you can give me.
>>>>
>>>> Best Regards,
>>>>
>>>> Beto
>>>>
>>>> _______________________________________________
>>>> Owasp-testing mailing list
>>>> Owasp-testing at lists.owasp.org
>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>>>
>>>>
>>>> _______________________________________________
>>>> Owasp-testing mailing list
>>>> Owasp-testing at lists.owasp.org
>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing
>>>>
>>>
> 
> 
> 
> _______________________________________________
> Owasp-testing mailing list
> Owasp-testing at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/owasp-testing
> 


From andrew at ionize.com.au  Thu May  9 11:13:58 2013
From: andrew at ionize.com.au (Andrew Muller)
Date: Thu, 9 May 2013 21:13:58 +1000 (EST)
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <518B5644.7080109@owasp.org>
Message-ID: <19644462.6551.1368098038460.JavaMail.root@ionize.com.au>

I suggest we refer to calculation of business impact levels and contribution of the security testing results to a risk management process, and explain how it could be done, not how it should be done. 

Business impact can be calculated in as many ways as there are businesses, so suggestions and references may help, but anything more may result in the Test Guide process being difficult to integrate. Similarly for risk management. For example, you allude to quantitative risk analysis, Jim, but I've seen quite a lot of qualitative risk analysis in my travels. 

I believe the Test Guide needs to focus on what it does best (verifying and validating application security controls and finding vulnerabilities in applications), the rest is up to the business analysts and risk professionals. While the calculation of vulnerability severity metrics is currently flawed as Eoin points out, attempts to fix it are on the way. This is unfortunate, but it is an industry standard and I believe we should try to work with it as much as we can and change it when we can. 

I am not a fan of reinventing the wheel. The many, varied and often failed attempts to write security testing methodologies drives me up the wall. Business impact levels, risk management processes and vulnerability severity metrics have all been done before by many people in many ways. I believe in the approach of reusing, refining, and when there is no other option, redoing. 

regards, 
Andrew 


----- Original Message -----

From: "Jim Manico" <jim.manico at owasp.org> 
To: "jm" <sysvar0 at gmail.com> 
Cc: owasp-testing at lists.owasp.org 
Sent: Thursday, May 9, 2013 5:54:44 PM 
Subject: Re: [Owasp-testing] CVSS v2 

Keep in mind, all of the factors can be changed. 

I am most worried about the math that is used to compute overall business impact. It's an average of business factors which might improperly reduce the overall business impact. 

Check out the section on "repeatable process" under https://www.owasp.org/index.php/OWASP_Risk_Rating_Methodology#Business_Impact_Factors to see what I'm talking about. 

I think you want to set specific weights for each business impact factors specific to the context of your business and let the highest value be the true overall business impact. 

And really, when it comes to true risk mathematics, this is incredibly lightweight. I would not run a risk practice on this fuzzy math alone. 

Cheers, 
Jim 




> I look at the OWASP risk rating methodology. 
> 
> My comments as follows. 
> 
> It does not really distinguish between a specific occurence and 
> the prevalence or distribution of an affected application in a given 
> context. 
> It does not sufficiently factor in the value or the role of the application 
> within the context to the organization, the execution environment, or the 
> remediation cost. 
> 
> In Threat Agent factors. 
> -Size of group of threat does not qualify type. 
> -Opportunity should speak to motive and not to a level of access. 
> 
> In Vulnerability factors. 
> -Discoverability and exploitability are not very helpful in expressing the 
> complexity of the attack. 
> -Under awareness, I do not think that how well known a vulnerability is for 
> a group of threat agents is a reasonable question to ask, and am not 
> certain of a practical scenario where hidden would be assigned. It could 
> presume knowledge about the MO of a threat profile - not typically 
> vulnerability-centric, and this level of detail may be beyond the reach of 
> the organization or of the assessor. Instead, a more reasonable question 
> might be centered around any evidence of disclosure of said vulnerability 
> in the public domain, and perhaps a qualifier describing the level of 
> confidence of the report and whether the issue was acknowledged by the 
> vendor. 
> A qualifier describing the age of the vulnerability could be useful 
> Around intrusion detection, two properties seem to be implied, the 
> detectability or ease of detection and the action of review. The ease of 
> detection from the generation of a cyber observable may depend on other 
> components such as a system-centric configuration settings, and the 
> reviewing, freqency of review, etc. speak to potential / components of 
> another system. 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Wed, May 8, 2013 at 2:06 PM, alberto cuevas <beto.cuevas.v at gmail.com>wrote: 
> 
>> Hello, 
>> 
>> In the OWASP Testing Guide, proposes the use of OWASP Risk Rating 
>> Methodology (actually we used this for pentest web results). 
>> 
>> - This could be noted as a standard methodology? (I guess the majority of 
>> the community uses this) 
>> - Has anyone seen the limits of this methodology in certain situations? 
>> - Which other methodologies can be recommended to use rather than OWASP 
>> Risk Rating Methodology? 
>> 
>> Thanks in advance for your guidance. 
>> 
>> Beto 
>> 
>> 2013/5/7 jm <sysvar0 at gmail.com> 
>> 
>>> Vulnerability-centric 
>>> Qualitative 
>>> Coarse-grained 
>>> Simple 
>>> Concise 
>>> Contextually extensible 
>>> Open framework 
>>> Inconsistent implementations 
>>> In relative wide-use 
>>> One-to-one mappings - no scale well for multiple vulnerabilites 
>>> El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?: 
>>> 
>>> CVSS pretty much is devoid of context. 
>>>> It does not consider client attacks IMHO. It's more of a traditional 
>>>> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty 
>>>> poor. 
>>>> 
>>>> Eoin Keary 
>>>> Owasp Global Board 
>>>> +353 87 977 2988 
>>>> 
>>>> 
>>>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote: 
>>>> 
>>>> Hello, 
>>>> 
>>>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes : 
>>>> 
>>>> 
>>>> "Ideally, there would be a universal risk rating system that would 
>>>> accurately estimate all risks for all 
>>>> organization. But a vulnerability that is critical to one organization 
>>>> may not be very important to another. 
>>>> So we're presenting a basic framework here that you should customize for 
>>>> your organization. " 
>>>> 
>>>> Whereby, the following questions came to mind: 
>>>> 
>>>> - Is a good idea to use CVSS v2 to score pentest web results? (I think 
>>>> so that temporal and environmental metrics can be produced diferentes 
>>>> ratings which determines how critical the vulnerabilitie is for one or 
>>>> another organization.) 
>>>> 
>>>> - I read that CVSS v2 has some limitations for score combined 
>>>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to 
>>>> solve this issue? 
>>>> 
>>>> I wonder if there are opinions on the ups and downs of using CVSS v2 to 
>>>> rate the pentest web results. I appreciate in advance any help or 
>>>> information you can give me. 
>>>> 
>>>> Best Regards, 
>>>> 
>>>> Beto 
>>>> 
>>>> _______________________________________________ 
>>>> Owasp-testing mailing list 
>>>> Owasp-testing at lists.owasp.org 
>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing 
>>>> 
>>>> 
>>>> _______________________________________________ 
>>>> Owasp-testing mailing list 
>>>> Owasp-testing at lists.owasp.org 
>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing 
>>>> 
>>> 
> 
> 
> 
> _______________________________________________ 
> Owasp-testing mailing list 
> Owasp-testing at lists.owasp.org 
> https://lists.owasp.org/mailman/listinfo/owasp-testing 
> 

_______________________________________________ 
Owasp-testing mailing list 
Owasp-testing at lists.owasp.org 
https://lists.owasp.org/mailman/listinfo/owasp-testing 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130509/a1698881/attachment.html>

From jim.manico at owasp.org  Thu May  9 11:45:34 2013
From: jim.manico at owasp.org (Jim Manico)
Date: Thu, 09 May 2013 21:45:34 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <19644462.6551.1368098038460.JavaMail.root@ionize.com.au>
References: <19644462.6551.1368098038460.JavaMail.root@ionize.com.au>
Message-ID: <518B8C5E.9020202@owasp.org>

+1, sharp perspective Andrew.

- Jim

> I suggest we refer to calculation of business impact levels and contribution of the security testing results to a risk management process, and explain how it could be done, not how it should be done. 
> 
> Business impact can be calculated in as many ways as there are businesses, so suggestions and references may help, but anything more may result in the Test Guide process being difficult to integrate. Similarly for risk management. For example, you allude to quantitative risk analysis, Jim, but I've seen quite a lot of qualitative risk analysis in my travels. 
> 
> I believe the Test Guide needs to focus on what it does best (verifying and validating application security controls and finding vulnerabilities in applications), the rest is up to the business analysts and risk professionals. While the calculation of vulnerability severity metrics is currently flawed as Eoin points out, attempts to fix it are on the way. This is unfortunate, but it is an industry standard and I believe we should try to work with it as much as we can and change it when we can. 
> 
> I am not a fan of reinventing the wheel. The many, varied and often failed attempts to write security testing methodologies drives me up the wall. Business impact levels, risk management processes and vulnerability severity metrics have all been done before by many people in many ways. I believe in the approach of reusing, refining, and when there is no other option, redoing. 
> 
> regards, 
> Andrew 
> 
> 
> ----- Original Message -----
> 
> From: "Jim Manico" <jim.manico at owasp.org> 
> To: "jm" <sysvar0 at gmail.com> 
> Cc: owasp-testing at lists.owasp.org 
> Sent: Thursday, May 9, 2013 5:54:44 PM 
> Subject: Re: [Owasp-testing] CVSS v2 
> 
> Keep in mind, all of the factors can be changed. 
> 
> I am most worried about the math that is used to compute overall business impact. It's an average of business factors which might improperly reduce the overall business impact. 
> 
> Check out the section on "repeatable process" under https://www.owasp.org/index.php/OWASP_Risk_Rating_Methodology#Business_Impact_Factors to see what I'm talking about. 
> 
> I think you want to set specific weights for each business impact factors specific to the context of your business and let the highest value be the true overall business impact. 
> 
> And really, when it comes to true risk mathematics, this is incredibly lightweight. I would not run a risk practice on this fuzzy math alone. 
> 
> Cheers, 
> Jim 
> 
> 
> 
> 
>> I look at the OWASP risk rating methodology. 
>>
>> My comments as follows. 
>>
>> It does not really distinguish between a specific occurence and 
>> the prevalence or distribution of an affected application in a given 
>> context. 
>> It does not sufficiently factor in the value or the role of the application 
>> within the context to the organization, the execution environment, or the 
>> remediation cost. 
>>
>> In Threat Agent factors. 
>> -Size of group of threat does not qualify type. 
>> -Opportunity should speak to motive and not to a level of access. 
>>
>> In Vulnerability factors. 
>> -Discoverability and exploitability are not very helpful in expressing the 
>> complexity of the attack. 
>> -Under awareness, I do not think that how well known a vulnerability is for 
>> a group of threat agents is a reasonable question to ask, and am not 
>> certain of a practical scenario where hidden would be assigned. It could 
>> presume knowledge about the MO of a threat profile - not typically 
>> vulnerability-centric, and this level of detail may be beyond the reach of 
>> the organization or of the assessor. Instead, a more reasonable question 
>> might be centered around any evidence of disclosure of said vulnerability 
>> in the public domain, and perhaps a qualifier describing the level of 
>> confidence of the report and whether the issue was acknowledged by the 
>> vendor. 
>> A qualifier describing the age of the vulnerability could be useful 
>> Around intrusion detection, two properties seem to be implied, the 
>> detectability or ease of detection and the action of review. The ease of 
>> detection from the generation of a cyber observable may depend on other 
>> components such as a system-centric configuration settings, and the 
>> reviewing, freqency of review, etc. speak to potential / components of 
>> another system. 
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Wed, May 8, 2013 at 2:06 PM, alberto cuevas <beto.cuevas.v at gmail.com>wrote: 
>>
>>> Hello, 
>>>
>>> In the OWASP Testing Guide, proposes the use of OWASP Risk Rating 
>>> Methodology (actually we used this for pentest web results). 
>>>
>>> - This could be noted as a standard methodology? (I guess the majority of 
>>> the community uses this) 
>>> - Has anyone seen the limits of this methodology in certain situations? 
>>> - Which other methodologies can be recommended to use rather than OWASP 
>>> Risk Rating Methodology? 
>>>
>>> Thanks in advance for your guidance. 
>>>
>>> Beto 
>>>
>>> 2013/5/7 jm <sysvar0 at gmail.com> 
>>>
>>>> Vulnerability-centric 
>>>> Qualitative 
>>>> Coarse-grained 
>>>> Simple 
>>>> Concise 
>>>> Contextually extensible 
>>>> Open framework 
>>>> Inconsistent implementations 
>>>> In relative wide-use 
>>>> One-to-one mappings - no scale well for multiple vulnerabilites 
>>>> El may 7, 2013 7:46 p.m., "Eoin" <eoin.keary at owasp.org> escribi?: 
>>>>
>>>> CVSS pretty much is devoid of context. 
>>>>> It does not consider client attacks IMHO. It's more of a traditional 
>>>>> security issue rating system. PCI mapping to CVSS v2 for appsec is pretty 
>>>>> poor. 
>>>>>
>>>>> Eoin Keary 
>>>>> Owasp Global Board 
>>>>> +353 87 977 2988 
>>>>>
>>>>>
>>>>> On 8 May 2013, at 00:34, alberto cuevas <beto.cuevas.v at gmail.com> wrote: 
>>>>>
>>>>> Hello, 
>>>>>
>>>>> In the section 5.1 HOW TO VALUE THE REAL RISK in OWASP Testing Guide v3, notes : 
>>>>>
>>>>>
>>>>> "Ideally, there would be a universal risk rating system that would 
>>>>> accurately estimate all risks for all 
>>>>> organization. But a vulnerability that is critical to one organization 
>>>>> may not be very important to another. 
>>>>> So we're presenting a basic framework here that you should customize for 
>>>>> your organization. " 
>>>>>
>>>>> Whereby, the following questions came to mind: 
>>>>>
>>>>> - Is a good idea to use CVSS v2 to score pentest web results? (I think 
>>>>> so that temporal and environmental metrics can be produced diferentes 
>>>>> ratings which determines how critical the vulnerabilitie is for one or 
>>>>> another organization.) 
>>>>>
>>>>> - I read that CVSS v2 has some limitations for score combined 
>>>>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to 
>>>>> solve this issue? 
>>>>>
>>>>> I wonder if there are opinions on the ups and downs of using CVSS v2 to 
>>>>> rate the pentest web results. I appreciate in advance any help or 
>>>>> information you can give me. 
>>>>>
>>>>> Best Regards, 
>>>>>
>>>>> Beto 
>>>>>
>>>>> _______________________________________________ 
>>>>> Owasp-testing mailing list 
>>>>> Owasp-testing at lists.owasp.org 
>>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing 
>>>>>
>>>>>
>>>>> _______________________________________________ 
>>>>> Owasp-testing mailing list 
>>>>> Owasp-testing at lists.owasp.org 
>>>>> https://lists.owasp.org/mailman/listinfo/owasp-testing 
>>>>>
>>>>
>>
>>
>>
>> _______________________________________________ 
>> Owasp-testing mailing list 
>> Owasp-testing at lists.owasp.org 
>> https://lists.owasp.org/mailman/listinfo/owasp-testing 
>>
> 
> _______________________________________________ 
> Owasp-testing mailing list 
> Owasp-testing at lists.owasp.org 
> https://lists.owasp.org/mailman/listinfo/owasp-testing 
> 
> 


From colin.watson at owasp.org  Thu May  9 15:19:07 2013
From: colin.watson at owasp.org (Colin Watson)
Date: Thu, 9 May 2013 17:19:07 +0200
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CAAxdBB=UShCG2jR_Tju9o5-LPRWNG6LTFjxSLkk7UCZVF+qTsg@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<CAAxdBB=UShCG2jR_Tju9o5-LPRWNG6LTFjxSLkk7UCZVF+qTsg@mail.gmail.com>
Message-ID: <CAAxdBBn=4PzYC9Jg5Yj1J8dutFDcsmeos4f-Ej8fX7FGDEd7Yg@mail.gmail.com>

Beto

You have received lots of great feedback from others on this list.

May I add some other aspects to consider:

- what purpose the "score" will be used for
- what will the "scores" be compared with?
- has some particular scoring method been used previously for this
application/business/company?
- ability for the target audience to understand it
- on whom is the impact being considered - we often assume "business
impact", but the impact on individuals, other parties and society may
also need to be considered?

Colin




On 8 May 2013 09:14, Colin Watson <colin.watson at owasp.org> wrote:
> Beto
>
> Your questions are very pertinent, and Eoin's reply is correct.
>
>> - Is a good idea to use CVSS v2 to score pentest web results? (I think so
>> that temporal and environmental metrics can be produced diferentes ratings
>> which determines how critical the vulnerabilitie is for one or another
>> organization.)
>
> I would avoid CVSS2 at all costs for application vulnerabilities if
> possible. Yes, people have been known to fiddle with the values to
> obtain the CVSS2 score they want. If anything other than the base
> score is presented, be suspicious. If the vector is not provided (it
> is a requirement), then be extremely suspicious.
>
>> - I read that CVSS v2 has some limitations for score combined
>> vulnerabilties, So, in case to sue CVSS v2 to score, Do exist some mode to
>> solve this issue?
>
> CVSS2 has no relevance at all to combinations of vulnerabilities.
>
> Also, the impact is measures against the target "system", and for many
> organisations things like data, reputation, human safety, share price,
> ethics are more important concerns. You need to determine the impact
> and likelihood for the particular application/organisation.
>
> Colin

From christian.heinrich at cmlh.id.au  Fri May 10 05:32:45 2013
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Fri, 10 May 2013 15:32:45 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CAAxdBBn=4PzYC9Jg5Yj1J8dutFDcsmeos4f-Ej8fX7FGDEd7Yg@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<CAAxdBB=UShCG2jR_Tju9o5-LPRWNG6LTFjxSLkk7UCZVF+qTsg@mail.gmail.com>
	<CAAxdBBn=4PzYC9Jg5Yj1J8dutFDcsmeos4f-Ej8fX7FGDEd7Yg@mail.gmail.com>
Message-ID: <CAGKxTUQ-nKsh2OK-ib=ePZ+=8nHh5ZRW34N2DTn+yc5t=2ky4Q@mail.gmail.com>

Colin,

On Fri, May 10, 2013 at 1:19 AM, Colin Watson <colin.watson at owasp.org>wrote:

> On 8 May 2013 09:14, Colin Watson <colin.watson at owasp.org> wrote:>

> I would avoid CVSS2 at all costs for application vulnerabilities if
> > possible. Yes, people have been known to fiddle with the values to
> > obtain the CVSS2 score they want. If anything other than the base
> > score is presented, be suspicious. If the vector is not provided (it
> > is a requirement), then be extremely suspicious.
>

I am not sure how you formed this opinion but the undisputed facts are:

   1. CVSS is intended to provide the priority of the implementation of
   workarounds and patches independent of the "nonces", i.e. those that are
   "Common[VSS]", to the Operating System and/or Application.  Hence, CVSS
   considers a much greater scope than a "single" web application.
   2. The "Base Score" can be verified by consulting either
   http://osvdb.org/ and http://web.nvd.nist.gov/view/vuln/search which are
   *independent* of the affected software vendor.
   3. http://nvd.nist.gov/cvss.cfm?vectorinfo is published by both
   http://osvdb.org/ and http://web.nvd.nist.gov/view/vuln/search also.
   4. It is not possible to calculate the "Temporal Metric" without the
   "Base Metric".  I would be interested in reviewing the source you cited for
   this since the one of the
   http://cmlh.id.au/post/25150772855/cvssv3-call-subjects put forward is
   "a real time for Temporal Metrics"

On Fri, May 10, 2013 at 1:19 AM, Colin Watson <colin.watson at owasp.org>
 wrote:

> On 8 May 2013 09:14, Colin Watson <colin.watson at owasp.org> wrote:>

> CVSS2 has no relevance at all to combinations of vulnerabilities.
>

I'll repeat from 1. above i.e.  "CVSS is intended to provide the priority
of the implementation of workarounds and patches independent of the
"nonces", i.e. those that are "CommonVSS", to the Operating System and/or
Application.  Hence, CVSS considers a much greater scope than a "single"
web application."

On Fri, May 10, 2013 at 1:19 AM, Colin Watson <colin.watson at owasp.org>
 wrote:

> On 8 May 2013 09:14, Colin Watson <colin.watson at owasp.org> wrote:>

> Also, the impact is measures against the target "system", and for many
> > organisations things like data, reputation, human safety, share price,
> > ethics are more important concerns. You need to determine the impact
> > and likelihood for the particular application/organisation.
>

These are "Environmental" vectors that are measured by the end user.

-- 
Regards,
Christian Heinrich

http://cmlh.id.au/contact
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130510/ecf54028/attachment.html>

From colin.watson at owasp.org  Fri May 10 07:18:53 2013
From: colin.watson at owasp.org (Colin Watson)
Date: Fri, 10 May 2013 09:18:53 +0200
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CAGKxTUQ-nKsh2OK-ib=ePZ+=8nHh5ZRW34N2DTn+yc5t=2ky4Q@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<CAAxdBB=UShCG2jR_Tju9o5-LPRWNG6LTFjxSLkk7UCZVF+qTsg@mail.gmail.com>
	<CAAxdBBn=4PzYC9Jg5Yj1J8dutFDcsmeos4f-Ej8fX7FGDEd7Yg@mail.gmail.com>
	<CAGKxTUQ-nKsh2OK-ib=ePZ+=8nHh5ZRW34N2DTn+yc5t=2ky4Q@mail.gmail.com>
Message-ID: <CAAxdBBkCUtzu-BmcrUgTvefG=aaAyL7iy+oUQ2t_RfbQW1dtfA@mail.gmail.com>

Christian

Very useful points and references, which I don't disagree with.

For custom-built web applications, which I think was the original
question, I would personally not use CVSS2. I am keeping my eyes on
CWRAF and CWSS:

   http://cwe.mitre.org/cwraf/

Colin

From christian.heinrich at cmlh.id.au  Sat May 11 02:25:33 2013
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Sat, 11 May 2013 12:25:33 +1000
Subject: [Owasp-testing] CVSS v2
In-Reply-To: <CAAxdBBkCUtzu-BmcrUgTvefG=aaAyL7iy+oUQ2t_RfbQW1dtfA@mail.gmail.com>
References: <CACWUwBx2Eqc1UBx+idG7pxkdDsvQXjkM-pLa-1y3J0mvURSqxg@mail.gmail.com>
	<CAAxdBB=UShCG2jR_Tju9o5-LPRWNG6LTFjxSLkk7UCZVF+qTsg@mail.gmail.com>
	<CAAxdBBn=4PzYC9Jg5Yj1J8dutFDcsmeos4f-Ej8fX7FGDEd7Yg@mail.gmail.com>
	<CAGKxTUQ-nKsh2OK-ib=ePZ+=8nHh5ZRW34N2DTn+yc5t=2ky4Q@mail.gmail.com>
	<CAAxdBBkCUtzu-BmcrUgTvefG=aaAyL7iy+oUQ2t_RfbQW1dtfA@mail.gmail.com>
Message-ID: <CAGKxTUSm262uxh5Q-zUEqKfr7A3z3E5ijx_WJ6mDtQJC1mD2Cg@mail.gmail.com>

Colin,

On Fri, May 10, 2013 at 5:18 PM, Colin Watson <colin.watson at owasp.org>wrote:

> Very useful points and references, which I don't disagree with.
>

I also presented http://www.slideshare.net/cmlh/cvss from 2006 and as part
of this research considered the published minutes of the FIRST SIG
conference calls during the development of CVSSv2.

As I have stated previously, the issues identified within
http://www.slideshare.net/cmlh/cvss are being addressed by the FIRST
CVSS-SIG for CVSSv3.

On Fri, May 10, 2013 at 5:18 PM, Colin Watson <colin.watson at owasp.org>
 wrote:
>
> For custom-built web applications, which I think was the original
> question, I would personally not use CVSS2. I am keeping my eyes on
> CWRAF and CWSS:
>
>    http://cwe.mitre.org/cwraf/
>

I include CWRAF as a recommendation in the Executive Brief since I believe
the risk management function of the business is better at measuring their
residual risk when acting as the external independent auditor.

Also, you may still be able to locate CVE(s) of the published API(s) since
developer tends to reuse API(s) in the development of multiple web
applications.  Hence, it may still possible to quote the CVSS Base Score in
the deliverable as part of encouraging the business to leverage CWRAF.



-- 
Regards,
Christian Heinrich

http://cmlh.id.au/contact
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130511/62f23804/attachment.html>

From jim.manico at owasp.org  Sun May 19 06:50:34 2013
From: jim.manico at owasp.org (Jim Manico)
Date: Sat, 18 May 2013 23:50:34 -0700
Subject: [Owasp-testing] New Project Co-leader Andrew Muller
Message-ID: <5198763A.3060803@owasp.org>

Hello all,

I am very pleased to announce a new co-leader for the OWASP Testing Guide Project!

Please thank Andrew Muller for stepping up and agreeing to help Matteo Meucci lead this project. Andrew will be helping drive the next version of the OWASP Testing Guide to completion.

Thank you Andrew and we all look forward to the next version of this guide.

Aloha,
Jim Manico

PS: I also took a moment to fix the tabs on the homepage of this project at https://www.owasp.org/index.php/OWASP_Testing_Project . If you want any other help with the wiki, please just ask. :)


From mehdi_yami at yahoo.com  Tue May 21 07:00:40 2013
From: mehdi_yami at yahoo.com (false)
Date: Tue, 21 May 2013 00:00:40 -0700 (PDT)
Subject: [Owasp-testing] Relation between OWASP ASVS and testing guide
Message-ID: <1369119640.67257.YahooMailNeo@web140306.mail.bf1.yahoo.com>

Hi,
I am?studied?a little about both?OWASP Testing guide and?OWASP ASVS. I found that Testing guide is more practical and it provides real test cases and guidelines for testing, but ASVS is more better for business purposes and describing?different?levels of ?testing for pricing and contract description but it does not provide any details about how we must verify requirements...

Now I am confusing about this that there is a gap between these two?guidelines?to apply security testing for business purposes... Is there any?guidelines?to specify and resolve this gap?

Thx,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130521/e1bbd992/attachment.html>

From herman at astyran.com  Tue May 21 07:13:55 2013
From: herman at astyran.com (Herman Stevens)
Date: Tue, 21 May 2013 07:13:55 +0000
Subject: [Owasp-testing] Relation between OWASP ASVS and testing guide
In-Reply-To: <1369119640.67257.YahooMailNeo@web140306.mail.bf1.yahoo.com>
References: <1369119640.67257.YahooMailNeo@web140306.mail.bf1.yahoo.com>
Message-ID: <3E66820262278D4F9B9097FE9A6C1D9554C6350F@HKNPRD0211MB421.apcprd02.prod.outlook.com>

Hi,

A while ago I posted the following, hopefully it can help:


*         http://blog.astyran.sg/2011/06/real-world-against-owasp-asvs.html

*         http://blog.astyran.sg/2012/03/mapping-skies-owasp-asvs-against.html

Unfortunately, I never finished the complete mapping. I believe that people are working on new versions of the ASVS and the Testing Guide.

In my vision, the ASVS should only iclude things that are _directly_ relevant for security. Anything that is a "nice to have" should not be included, since business manager will question the purpose (why put any money into a that?). Anything that cannot be reliably tested should be tossed out too.

Sincerely,

Herman


From: owasp-testing-bounces at lists.owasp.org [mailto:owasp-testing-bounces at lists.owasp.org] On Behalf Of false
Sent: Tuesday, 21 May, 2013 3:01 PM
To: owasp-testing at lists.owasp.org
Subject: [Owasp-testing] Relation between OWASP ASVS and testing guide

Hi,
I am studied a little about both OWASP Testing guide and OWASP ASVS. I found that Testing guide is more practical and it provides real test cases and guidelines for testing, but ASVS is more better for business purposes and describing different levels of  testing for pricing and contract description but it does not provide any details about how we must verify requirements...

Now I am confusing about this that there is a gap between these two guidelines to apply security testing for business purposes... Is there any guidelines to specify and resolve this gap?

Thx,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130521/129f6b20/attachment.html>

From mehdi_yami at yahoo.com  Tue May 21 07:39:36 2013
From: mehdi_yami at yahoo.com (false)
Date: Tue, 21 May 2013 00:39:36 -0700 (PDT)
Subject: [Owasp-testing] Relation between OWASP ASVS and testing guide
Message-ID: <1369121976.55807.YahooMailNeo@web140302.mail.bf1.yahoo.com>

Thx Herman,
I had reed your useful post before posting on this list, i was confused about part 2 of that post.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-testing/attachments/20130521/8c4d6a16/attachment.html>

