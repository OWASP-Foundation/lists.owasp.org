From JMcGovern at virtusa.com  Mon Nov  1 09:53:03 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Mon, 1 Nov 2010 09:53:03 -0400
Subject: [SAMM] CLASP vs. SAMM
In-Reply-To: <fb99f8665640.4ccd5589@shaw.ca>
References: <fb99f8665640.4ccd5589@shaw.ca>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE08A@ws-mailsvr.Virtusa.com>

Being from an "enterprise" background, I am of the belief that CLASP has
accomplished its mission. While we collectively can make minor
improvements and come out with an updated version, the reality is that
SAMM will add orders of magnitude additional value to enterprises than
CLASP could ever hope for. With that being said, there is some merit in
asking on the CLASP mailing list, what are the things you would tweak to
make CLASP better?

 

James McGovern
Insurance SBU 

Virtusa Corporation

100 Northfield Drive, Suite 305 | Windsor, CT | 06095

Phone:  860 688 9900 Ext:  1037 | Facsimile:  860 688 2890  

  <http://www.virtusa.com/>    <http://www.virtusa.com/blog/>   
<https://twitter.com/VirtusaCorp>   
<http://www.linkedin.com/companies/virtusa>   
<http://www.facebook.com/VirtusaCorp> 

 

From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of JIM BIRD
Sent: Sunday, October 31, 2010 1:40 PM
To: owasp-clasp at lists.owasp.org; samm at lists.owasp.org
Subject: [SAMM] CLASP vs SAMM

 

I was interested to see a chapter covering CLASP in Mark Merkow and
Laksh Raghanvan's new book "Secure and Resilient Software Development".
This raised some questions about the state of support for CLASP and its
roadmap. I was under the impression that CLASP was going to be replaced
over time by SAMM: as Pravir called SAMM "CLASP on steroids" at one
point. I thought that CLASP was going to be orphaned as a result.

Now I understand that SAMM is at its core a maturity model not a secure
SDLC so this was confusing to me at the time and still is confusing.
I've been following both mailing lists for some time now (there has been
essentially nothing on CLASP in a long time so it hasn't been
distracting).CLASP doesn't seem to be actively maintained and isn't
keeping up with the other mainline initiatives at OWASP. SAMM has much
more momentum behind it, and is a more active project. But I don't see
how the two projects will converge.

To be honest I was surprised that a brand new book would reference
CLASP. As a software developer looking for a secure SDLC for a
reference, it makes a lot more sense to work with Microsoft's SDL than
CLASP given that SDL is more current and complete and has a lot more
resources and momentum. Is CLASP still alive? And how are CLASP and SAMM
supposed to fit together?

Jim Bird


Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0001.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 1397 bytes
Desc: image001.jpg
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0001.jpe 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 744 bytes
Desc: image002.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0004.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 1211 bytes
Desc: image003.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0005.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 789 bytes
Desc: image004.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0006.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 763 bytes
Desc: image005.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/20ba25e4/attachment-0007.gif 

From JMcGovern at virtusa.com  Mon Nov  1 09:55:31 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Mon, 1 Nov 2010 09:55:31 -0400
Subject: [SAMM] Agile Software Development
In-Reply-To: <fb99f8665640.4ccd5589@shaw.ca>
References: <fb99f8665640.4ccd5589@shaw.ca>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE08C@ws-mailsvr.Virtusa.com>

Many maturity models penalize Agile approaches to software development
since the focus isn't on creation of comprehensive documentation
upfront. Is there merit in providing "audit" guidance for those who are
leveraging Agile methods? How do we encourage folks to think about
maturity in an iterative way and not interpret SAMM as being more
waterfall-oriented?

 

James McGovern
Insurance SBU 

Virtusa Corporation

100 Northfield Drive, Suite 305 | Windsor, CT | 06095

Phone:  860 688 9900 Ext:  1037 | Facsimile:  860 688 2890  

  <http://www.virtusa.com/>    <http://www.virtusa.com/blog/>   
<https://twitter.com/VirtusaCorp>   
<http://www.linkedin.com/companies/virtusa>   
<http://www.facebook.com/VirtusaCorp> 

 


Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 1397 bytes
Desc: image001.jpg
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment.jpe 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 744 bytes
Desc: image002.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 1211 bytes
Desc: image003.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment-0001.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 789 bytes
Desc: image004.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment-0002.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 763 bytes
Desc: image005.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101101/5b30c918/attachment-0003.gif 

From John.Steven at owasp.org  Mon Nov  1 11:45:00 2010
From: John.Steven at owasp.org (John Steven)
Date: Mon, 1 Nov 2010 11:45:00 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 2
In-Reply-To: <mailman.11.1288627205.8881.samm@lists.owasp.org>
References: <mailman.11.1288627205.8881.samm@lists.owasp.org>
Message-ID: <AANLkTimcHCzAYTfWBr4UKfjPMEzQCygBXmydcvwapqnU@mail.gmail.com>

James,

I agree that many maturity models can penalize agile methods. When it
comes to security this need-not be true.

I've helped a few organizations adopt security activities within an
agile framework. Several activities were easy to introduce as
evolutionary or incremental steps for existing activities--rather than
revolutionary change.

Simple improvements included :(*1):

* Misuse/abuse case documentation (AM2.1)
* Create security features guidance (SFD 1.1)
* Identification of reuse opportunities (SFD 2.3) (*2)
* Use of Findbugs/etc (CR3.1)
* Peer (code) review
* Create security tests (AM3.2)

I arrived to find some of these activities in place, introduced some
others, and others emerged from conversations with agile
teams--without much arm-twisting.

Other activities occurred as well, I've just provided a partial list
here. While I specifically avoided listing infrastructural activities
(like policy, etc.) notice that at least one agile team I worked with
did set out and create some security features guidance internal to
their dev team: a 'shadow' of their organization's security policy.
They had someone sharp on their team interpret policy/stds. and cast
it in usable terms for the tiger-team doing development to keep handy.
This was clever.

What's particularly interesting here is that activities related to
design, another purportedly de-prioritized element of agile process,
remains well represented.  Perhaps this is my bias ;-)

-jOHN

(*1) - Coded  with BSIMM identifiers despite fear that it will
generate cries of sacrilege b/c organizations got credit for doing
these activities when they were surveyed. This is proof beyond my
email that not only did someone following Agile do security activities
but that to maturity model folk--it mattered.

(*2) - One case was OWASP ESAPI, one was an internal (LoB) toolkit,
another was internal (provided by shared services)



On Mon, Nov 1, 2010 at 12:00 PM,  <samm-request at lists.owasp.org> wrote:
> Send SAMM mailing list submissions to
> ? ? ? ?samm at lists.owasp.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> ? ? ? ?https://lists.owasp.org/mailman/listinfo/samm
> or, via email, send a message with subject or body 'help' to
> ? ? ? ?samm-request at lists.owasp.org
>
> You can reach the person managing the list at
> ? ? ? ?samm-owner at lists.owasp.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of SAMM digest..."
>
>
> Today's Topics:
>
> ? 1. Agile Software Development (James McGovern)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 1 Nov 2010 09:55:31 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE08C at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; charset="us-ascii"
>
> Many maturity models penalize Agile approaches to software development
> since the focus isn't on creation of comprehensive documentation
> upfront. Is there merit in providing "audit" guidance for those who are
> leveraging Agile methods? How do we encourage folks to think about
> maturity in an iterative way and not interpret SAMM as being more
> waterfall-oriented?
>
>
>
> James McGovern
> Insurance SBU
>
> Virtusa Corporation
>
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>
> Phone: ?860 688 9900 Ext: ?1037 | Facsimile: ?860 688 2890
>
> ?<http://www.virtusa.com/> ? ?<http://www.virtusa.com/blog/>
> <https://twitter.com/VirtusaCorp>
> <http://www.linkedin.com/companies/virtusa>
> <http://www.facebook.com/VirtusaCorp>
>
>
>
>
> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
> ---------------------------------------------------------------------------------------------

From JMcGovern at virtusa.com  Mon Nov  1 14:32:41 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Mon, 1 Nov 2010 14:32:41 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 2
In-Reply-To: <AANLkTimcHCzAYTfWBr4UKfjPMEzQCygBXmydcvwapqnU@mail.gmail.com>
References: <mailman.11.1288627205.8881.samm@lists.owasp.org>
	<AANLkTimcHCzAYTfWBr4UKfjPMEzQCygBXmydcvwapqnU@mail.gmail.com>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE105@ws-mailsvr.Virtusa.com>

How would/should we think about concepts such as Agile Protection Poker (http://collaboration.csc.ncsu.edu/laurie/Papers/essos09_submission_30.pdf) or having a security-oriented sprint as a component of a higher-level of software assurance?

James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??

-----Original Message-----
From: jsteven at maladjustment.org [mailto:jsteven at maladjustment.org] On Behalf Of John Steven
Sent: Monday, November 01, 2010 11:45 AM
To: samm at lists.owasp.org
Cc: James McGovern
Subject: Re: SAMM Digest, Vol 20, Issue 2

James,

I agree that many maturity models can penalize agile methods. When it
comes to security this need-not be true.

I've helped a few organizations adopt security activities within an
agile framework. Several activities were easy to introduce as
evolutionary or incremental steps for existing activities--rather than
revolutionary change.

Simple improvements included :(*1):

* Misuse/abuse case documentation (AM2.1)
* Create security features guidance (SFD 1.1)
* Identification of reuse opportunities (SFD 2.3) (*2)
* Use of Findbugs/etc (CR3.1)
* Peer (code) review
* Create security tests (AM3.2)

I arrived to find some of these activities in place, introduced some
others, and others emerged from conversations with agile
teams--without much arm-twisting.

Other activities occurred as well, I've just provided a partial list
here. While I specifically avoided listing infrastructural activities
(like policy, etc.) notice that at least one agile team I worked with
did set out and create some security features guidance internal to
their dev team: a 'shadow' of their organization's security policy.
They had someone sharp on their team interpret policy/stds. and cast
it in usable terms for the tiger-team doing development to keep handy.
This was clever.

What's particularly interesting here is that activities related to
design, another purportedly de-prioritized element of agile process,
remains well represented.  Perhaps this is my bias ;-)

-jOHN

(*1) - Coded  with BSIMM identifiers despite fear that it will
generate cries of sacrilege b/c organizations got credit for doing
these activities when they were surveyed. This is proof beyond my
email that not only did someone following Agile do security activities
but that to maturity model folk--it mattered.

(*2) - One case was OWASP ESAPI, one was an internal (LoB) toolkit,
another was internal (provided by shared services)



On Mon, Nov 1, 2010 at 12:00 PM,  <samm-request at lists.owasp.org> wrote:
> Send SAMM mailing list submissions to
> ? ? ? ?samm at lists.owasp.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> ? ? ? ?https://lists.owasp.org/mailman/listinfo/samm
> or, via email, send a message with subject or body 'help' to
> ? ? ? ?samm-request at lists.owasp.org
>
> You can reach the person managing the list at
> ? ? ? ?samm-owner at lists.owasp.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of SAMM digest..."
>
>
> Today's Topics:
>
> ? 1. Agile Software Development (James McGovern)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 1 Nov 2010 09:55:31 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE08C at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; charset="us-ascii"
>
> Many maturity models penalize Agile approaches to software development
> since the focus isn't on creation of comprehensive documentation
> upfront. Is there merit in providing "audit" guidance for those who are
> leveraging Agile methods? How do we encourage folks to think about
> maturity in an iterative way and not interpret SAMM as being more
> waterfall-oriented?
>
>
>
> James McGovern
> Insurance SBU
>
> Virtusa Corporation
>
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>
> Phone: ?860 688 9900 Ext: ?1037 | Facsimile: ?860 688 2890
>
> ?<http://www.virtusa.com/> ? ?<http://www.virtusa.com/blog/>
> <https://twitter.com/VirtusaCorp>
> <http://www.linkedin.com/companies/virtusa>
> <http://www.facebook.com/VirtusaCorp>
>
>
>
>
> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
> ---------------------------------------------------------------------------------------------

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------

From John.Steven at owasp.org  Mon Nov  1 17:07:11 2010
From: John.Steven at owasp.org (John Steven)
Date: Mon, 1 Nov 2010 17:07:11 -0400
Subject: [SAMM] Agile Software Development
Message-ID: <AANLkTinbGhqb9hBfaj5Bz7-kJS+kMvLswkFPQXR1ro91@mail.gmail.com>

James,

I think this represents two important questions: first: are
security-oriented sprints advisable? Classic objections come to mind:





On Mon, Nov 1, 2010 at 2:32 PM, James McGovern <JMcGovern at virtusa.com> wrote:
> How would/should we think about concepts such as Agile Protection Poker (http://collaboration.csc.ncsu.edu/laurie/Papers/essos09_submission_30.pdf) or having a security-oriented sprint as a component of a higher-level of software assurance?
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890
>
>
> -----Original Message-----
> From: jsteven at maladjustment.org [mailto:jsteven at maladjustment.org] On Behalf Of John Steven
> Sent: Monday, November 01, 2010 11:45 AM
> To: samm at lists.owasp.org
> Cc: James McGovern
> Subject: Re: SAMM Digest, Vol 20, Issue 2
>
> James,
>
> I agree that many maturity models can penalize agile methods. When it
> comes to security this need-not be true.
>
> I've helped a few organizations adopt security activities within an
> agile framework. Several activities were easy to introduce as
> evolutionary or incremental steps for existing activities--rather than
> revolutionary change.
>
> Simple improvements included :(*1):
>
> * Misuse/abuse case documentation (AM2.1)
> * Create security features guidance (SFD 1.1)
> * Identification of reuse opportunities (SFD 2.3) (*2)
> * Use of Findbugs/etc (CR3.1)
> * Peer (code) review
> * Create security tests (AM3.2)
>
> I arrived to find some of these activities in place, introduced some
> others, and others emerged from conversations with agile
> teams--without much arm-twisting.
>
> Other activities occurred as well, I've just provided a partial list
> here. While I specifically avoided listing infrastructural activities
> (like policy, etc.) notice that at least one agile team I worked with
> did set out and create some security features guidance internal to
> their dev team: a 'shadow' of their organization's security policy.
> They had someone sharp on their team interpret policy/stds. and cast
> it in usable terms for the tiger-team doing development to keep handy.
> This was clever.
>
> What's particularly interesting here is that activities related to
> design, another purportedly de-prioritized element of agile process,
> remains well represented. ?Perhaps this is my bias ;-)
>
> -jOHN
>
> (*1) - Coded ?with BSIMM identifiers despite fear that it will
> generate cries of sacrilege b/c organizations got credit for doing
> these activities when they were surveyed. This is proof beyond my
> email that not only did someone following Agile do security activities
> but that to maturity model folk--it mattered.
>
> (*2) - One case was OWASP ESAPI, one was an internal (LoB) toolkit,
> another was internal (provided by shared services)
>
>
>
> On Mon, Nov 1, 2010 at 12:00 PM, ?<samm-request at lists.owasp.org> wrote:
>> Send SAMM mailing list submissions to
>> ? ? ? ?samm at lists.owasp.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> ? ? ? ?https://lists.owasp.org/mailman/listinfo/samm
>> or, via email, send a message with subject or body 'help' to
>> ? ? ? ?samm-request at lists.owasp.org
>>
>> You can reach the person managing the list at
>> ? ? ? ?samm-owner at lists.owasp.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of SAMM digest..."
>>
>>
>> Today's Topics:
>>
>> ? 1. Agile Software Development (James McGovern)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 1 Nov 2010 09:55:31 -0400
>> From: "James McGovern" <JMcGovern at virtusa.com>
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>> Message-ID:
>> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE08C at ws-mailsvr.Virtusa.com>
>> Content-Type: text/plain; charset="us-ascii"
>>
>> Many maturity models penalize Agile approaches to software development
>> since the focus isn't on creation of comprehensive documentation
>> upfront. Is there merit in providing "audit" guidance for those who are
>> leveraging Agile methods? How do we encourage folks to think about
>> maturity in an iterative way and not interpret SAMM as being more
>> waterfall-oriented?
>>
>>
>>
>> James McGovern
>> Insurance SBU
>>
>> Virtusa Corporation
>>
>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>
>> Phone: ?860 688 9900 Ext: ?1037 | Facsimile: ?860 688 2890
>>
>> ?<http://www.virtusa.com/> ? ?<http://www.virtusa.com/blog/>
>> <https://twitter.com/VirtusaCorp>
>> <http://www.linkedin.com/companies/virtusa>
>> <http://www.facebook.com/VirtusaCorp>

From John.Steven at owasp.org  Mon Nov  1 17:27:58 2010
From: John.Steven at owasp.org (John Steven)
Date: Mon, 1 Nov 2010 17:27:58 -0400
Subject: [SAMM]  Agile Software Development
Message-ID: <AANLkTik8g2x+AM4b0kV=5xOfoq--ejVFDXqofijFoe6m@mail.gmail.com>

James,

Your reply poses two questions. First, "Are security-oriented sprints
advisable?" This question conjures the classic set of security
objections:

* You can't bolt security on later
* Security is an emergent property, it must be foremost in one's mind
during every release
* and so forth.

I don't disagree with those old saws. I've seen very productive
security (and other non-functional) sprints though. In particular,
I've seen security sprints provide the following benefits for
well-trained teams:

* Integrating with a security service, provided by shared services (such as URL-
  based authentication)
* Upgrading from a stub-implementation to a proper security control (such as
  encrypted channels or stores)
* Adding business logic rules for previous end-to-end proof-of-concepts (such
  as support for invaliding log-ins after an ID is deleted in SSO)

These feature-related sprint goals fit easily. I've also experienced
teams using sprints for exploration/prototyping, with goals such as:

* Identify all entities containing PII
* Conduct exploratory (security) testing to determine with XXX is exploitable
* Identify all components affected by YYY authorization check

On the other hand, I've not seen a single sprint "squash all XSS bugs"
or "implement access control, application-wide" or similar.

Note the slippery slope between 'integrating with a security service'
and 'implementing access control, application-wide'. James, I don't
expect that someone of your experience would make this mistake (in
fact, quite the contrary) but I did find that a key success factor was
the team's ability to break larger tasks up into sprint-sized chunks
in order to keep to standard sprint sizes. The last group of sprint
goals was designed to do exactly that. Each served as part of a larger
multi-sprint initiative. One team in particular was particularly good
at this kind of multi-sprint planning as they were used to dealing
with this in the realm of performance/scalability: they had gone from
Sql-lite to a fancy Oracle back-end. This was not their first
rodeo.What was neat, for me, was that they needed very little
"Security SME" to decompose their security tasks into sprint-sized
chunks once the misuse was documented... or the impact of the shared
service was understood... or... :D

-jOHN


On Mon, Nov 1, 2010 at 2:32 PM, James McGovern <JMcGovern at virtusa.com> wrote:
> How would/should we think about concepts such as Agile Protection Poker (http://collaboration.csc.ncsu.edu/laurie/Papers/essos09_submission_30.pdf) or having a security-oriented sprint as a component of a higher-level of software assurance?
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890
>
>
> -----Original Message-----
> From: jsteven at maladjustment.org [mailto:jsteven at maladjustment.org] On Behalf Of John Steven
> Sent: Monday, November 01, 2010 11:45 AM
> To: samm at lists.owasp.org
> Cc: James McGovern
> Subject: Re: SAMM Digest, Vol 20, Issue 2
>
> James,
>
> I agree that many maturity models can penalize agile methods. When it
> comes to security this need-not be true.
>
> I've helped a few organizations adopt security activities within an
> agile framework. Several activities were easy to introduce as
> evolutionary or incremental steps for existing activities--rather than
> revolutionary change.
>
> Simple improvements included :(*1):
>
> * Misuse/abuse case documentation (AM2.1)
> * Create security features guidance (SFD 1.1)
> * Identification of reuse opportunities (SFD 2.3) (*2)
> * Use of Findbugs/etc (CR3.1)
> * Peer (code) review
> * Create security tests (AM3.2)
>
> I arrived to find some of these activities in place, introduced some
> others, and others emerged from conversations with agile
> teams--without much arm-twisting.
>
> Other activities occurred as well, I've just provided a partial list
> here. While I specifically avoided listing infrastructural activities
> (like policy, etc.) notice that at least one agile team I worked with
> did set out and create some security features guidance internal to
> their dev team: a 'shadow' of their organization's security policy.
> They had someone sharp on their team interpret policy/stds. and cast
> it in usable terms for the tiger-team doing development to keep handy.
> This was clever.
>
> What's particularly interesting here is that activities related to
> design, another purportedly de-prioritized element of agile process,
> remains well represented. ?Perhaps this is my bias ;-)
>
> -jOHN
>
> (*1) - Coded ?with BSIMM identifiers despite fear that it will
> generate cries of sacrilege b/c organizations got credit for doing
> these activities when they were surveyed. This is proof beyond my
> email that not only did someone following Agile do security activities
> but that to maturity model folk--it mattered.
>
> (*2) - One case was OWASP ESAPI, one was an internal (LoB) toolkit,
> another was internal (provided by shared services)
>
>
>
> On Mon, Nov 1, 2010 at 12:00 PM, ?<samm-request at lists.owasp.org> wrote:
>> Send SAMM mailing list submissions to
>> ? ? ? ?samm at lists.owasp.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> ? ? ? ?https://lists.owasp.org/mailman/listinfo/samm
>> or, via email, send a message with subject or body 'help' to
>> ? ? ? ?samm-request at lists.owasp.org
>>
>> You can reach the person managing the list at
>> ? ? ? ?samm-owner at lists.owasp.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of SAMM digest..."
>>
>>
>> Today's Topics:
>>
>> ? 1. Agile Software Development (James McGovern)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 1 Nov 2010 09:55:31 -0400
>> From: "James McGovern" <JMcGovern at virtusa.com>
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>> Message-ID:
>> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE08C at ws-mailsvr.Virtusa.com>
>> Content-Type: text/plain; charset="us-ascii"
>>
>> Many maturity models penalize Agile approaches to software development
>> since the focus isn't on creation of comprehensive documentation
>> upfront. Is there merit in providing "audit" guidance for those who are
>> leveraging Agile methods? How do we encourage folks to think about
>> maturity in an iterative way and not interpret SAMM as being more
>> waterfall-oriented?
>>
>>
>>
>> James McGovern
>> Insurance SBU
>>
>> Virtusa Corporation
>>
>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>
>> Phone: ?860 688 9900 Ext: ?1037 | Facsimile: ?860 688 2890
>>
>> ?<http://www.virtusa.com/> ? ?<http://www.virtusa.com/blog/>
>> <https://twitter.com/VirtusaCorp>
>> <http://www.linkedin.com/companies/virtusa>
>> <http://www.facebook.com/VirtusaCorp>
>>
>>
>>
>>
>> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>>
>> ---------------------------------------------------------------------------------------------
>
> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
> ---------------------------------------------------------------------------------------------
>
> This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.
>
> ---------------------------------------------------------------------------------------------
>

From JMcGovern at virtusa.com  Tue Nov  2 09:35:06 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Tue, 2 Nov 2010 09:35:06 -0400
Subject: [SAMM] Agile Software Development
In-Reply-To: <AANLkTik8g2x+AM4b0kV=5xOfoq--ejVFDXqofijFoe6m@mail.gmail.com>
References: <AANLkTik8g2x+AM4b0kV=5xOfoq--ejVFDXqofijFoe6m@mail.gmail.com>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE1D4@ws-mailsvr.Virtusa.com>

1. I think we should do something with Jon's comments and not just let them linger in the email archive. Is there merit in capturing the below thoughts and making it a SAMM appendix?

2. With the advent of "business architecture" I think we should figure out a way to also give credit to shops that capture "threats" in a business sense. For example, in the Hartford, former CEO articulated that he wouldn't want to see a listing of high net-worth annuitants leak. When strategies equally articulate both the optimistic and pessimistic perspectives, it is likely to be more mature. Ran across way to many "strategies" that were happy path and didn't provide a sense as to what they even needed to protect.

3. My thought regarding sprints (and maturity) is that if the team thinks of security as strictly authentication and authorization then it is a fail. Sometimes teams will articulate authentication as a feature such that they may have a requirement such as: I want a user to be able to use their Active Directory credentials to access an application, but won't think about other aspects such as what happens if someone is using their active directory credentials outside the network from a kiosk in Cuba at midnight. I think too many "auditors" will mark security is good by thinking of security as a "feature". Authentication tends to be visible where other forms of security (or insecurity) may not be.

4. I know of more than a few shops that have embraced "authentication as a service" and have deployed web access management products such as Siteminder. Likewise, if you look hard enough, you will also find that many of these same shops have deployed web access management products insecurely. The challenge is that if you deploy a web access management product on the "web server", your application may be reading a "cookie" which can afford the opportunity for tampering. We have to figure out whether the usage of security products results in more or less maturity. NOTE: The point-and-shoot web vulnerability scanners don't find this type of vulnerability that otherwise is easily discovered by humans.

5. Having a sprint with the goal of "squash all XSS bugs" is a non-starter in the world of Scrum, since the sprint is constrained by time and not outcome. Likewise, the ability to "demo" it tends to be a challenge for development teams even with those who are security literate. Maybe a measure of how many security concerns that are placed on the backlog is the next best option? NOTE: In waterfall shops, we may refer to this as "Day Two" activities and we know how often day two actually comes.

James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??


-----Original Message-----
From: jsteven at maladjustment.org [mailto:jsteven at maladjustment.org] On Behalf Of John Steven
Sent: Monday, November 01, 2010 5:28 PM
To: James McGovern; samm at lists.owasp.org
Subject: [SAMM] Agile Software Development

James,

Your reply poses two questions. First, "Are security-oriented sprints
advisable?" This question conjures the classic set of security
objections:

* You can't bolt security on later
* Security is an emergent property, it must be foremost in one's mind
during every release
* and so forth.

I don't disagree with those old saws. I've seen very productive
security (and other non-functional) sprints though. In particular,
I've seen security sprints provide the following benefits for
well-trained teams:

* Integrating with a security service, provided by shared services (such as URL-
  based authentication)
* Upgrading from a stub-implementation to a proper security control (such as
  encrypted channels or stores)
* Adding business logic rules for previous end-to-end proof-of-concepts (such
  as support for invaliding log-ins after an ID is deleted in SSO)

These feature-related sprint goals fit easily. I've also experienced
teams using sprints for exploration/prototyping, with goals such as:

* Identify all entities containing PII
* Conduct exploratory (security) testing to determine with XXX is exploitable
* Identify all components affected by YYY authorization check

On the other hand, I've not seen a single sprint "squash all XSS bugs"
or "implement access control, application-wide" or similar.

Note the slippery slope between 'integrating with a security service'
and 'implementing access control, application-wide'. James, I don't
expect that someone of your experience would make this mistake (in
fact, quite the contrary) but I did find that a key success factor was
the team's ability to break larger tasks up into sprint-sized chunks
in order to keep to standard sprint sizes. The last group of sprint
goals was designed to do exactly that. Each served as part of a larger
multi-sprint initiative. One team in particular was particularly good
at this kind of multi-sprint planning as they were used to dealing
with this in the realm of performance/scalability: they had gone from
Sql-lite to a fancy Oracle back-end. This was not their first
rodeo.What was neat, for me, was that they needed very little
"Security SME" to decompose their security tasks into sprint-sized
chunks once the misuse was documented... or the impact of the shared
service was understood... or... :D

-jOHN


On Mon, Nov 1, 2010 at 2:32 PM, James McGovern <JMcGovern at virtusa.com> wrote:
> How would/should we think about concepts such as Agile Protection Poker (http://collaboration.csc.ncsu.edu/laurie/Papers/essos09_submission_30.pdf) or having a security-oriented sprint as a component of a higher-level of software assurance?
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890
>
>
> -----Original Message-----
> From: jsteven at maladjustment.org [mailto:jsteven at maladjustment.org] On Behalf Of John Steven
> Sent: Monday, November 01, 2010 11:45 AM
> To: samm at lists.owasp.org
> Cc: James McGovern
> Subject: Re: SAMM Digest, Vol 20, Issue 2
>
> James,
>
> I agree that many maturity models can penalize agile methods. When it
> comes to security this need-not be true.
>
> I've helped a few organizations adopt security activities within an
> agile framework. Several activities were easy to introduce as
> evolutionary or incremental steps for existing activities--rather than
> revolutionary change.
>
> Simple improvements included :(*1):
>
> * Misuse/abuse case documentation (AM2.1)
> * Create security features guidance (SFD 1.1)
> * Identification of reuse opportunities (SFD 2.3) (*2)
> * Use of Findbugs/etc (CR3.1)
> * Peer (code) review
> * Create security tests (AM3.2)
>
> I arrived to find some of these activities in place, introduced some
> others, and others emerged from conversations with agile
> teams--without much arm-twisting.
>
> Other activities occurred as well, I've just provided a partial list
> here. While I specifically avoided listing infrastructural activities
> (like policy, etc.) notice that at least one agile team I worked with
> did set out and create some security features guidance internal to
> their dev team: a 'shadow' of their organization's security policy.
> They had someone sharp on their team interpret policy/stds. and cast
> it in usable terms for the tiger-team doing development to keep handy.
> This was clever.
>
> What's particularly interesting here is that activities related to
> design, another purportedly de-prioritized element of agile process,
> remains well represented. ?Perhaps this is my bias ;-)
>
> -jOHN
>
> (*1) - Coded ?with BSIMM identifiers despite fear that it will
> generate cries of sacrilege b/c organizations got credit for doing
> these activities when they were surveyed. This is proof beyond my
> email that not only did someone following Agile do security activities
> but that to maturity model folk--it mattered.
>
> (*2) - One case was OWASP ESAPI, one was an internal (LoB) toolkit,
> another was internal (provided by shared services)
>
>
>
> On Mon, Nov 1, 2010 at 12:00 PM, ?<samm-request at lists.owasp.org> wrote:
>> Send SAMM mailing list submissions to
>> ? ? ? ?samm at lists.owasp.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> ? ? ? ?https://lists.owasp.org/mailman/listinfo/samm
>> or, via email, send a message with subject or body 'help' to
>> ? ? ? ?samm-request at lists.owasp.org
>>
>> You can reach the person managing the list at
>> ? ? ? ?samm-owner at lists.owasp.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of SAMM digest..."
>>
>>
>> Today's Topics:
>>
>> ? 1. Agile Software Development (James McGovern)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 1 Nov 2010 09:55:31 -0400
>> From: "James McGovern" <JMcGovern at virtusa.com>
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>> Message-ID:
>> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE08C at ws-mailsvr.Virtusa.com>
>> Content-Type: text/plain; charset="us-ascii"
>>
>> Many maturity models penalize Agile approaches to software development
>> since the focus isn't on creation of comprehensive documentation
>> upfront. Is there merit in providing "audit" guidance for those who are
>> leveraging Agile methods? How do we encourage folks to think about
>> maturity in an iterative way and not interpret SAMM as being more
>> waterfall-oriented?
>>
>>
>>
>> James McGovern
>> Insurance SBU
>>
>> Virtusa Corporation
>>
>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>
>> Phone: ?860 688 9900 Ext: ?1037 | Facsimile: ?860 688 2890
>>
>> ?<http://www.virtusa.com/> ? ?<http://www.virtusa.com/blog/>
>> <https://twitter.com/VirtusaCorp>
>> <http://www.linkedin.com/companies/virtusa>
>> <http://www.facebook.com/VirtusaCorp>
>>
>>
>>
>>
>> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>>
>> ---------------------------------------------------------------------------------------------
>
> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
> ---------------------------------------------------------------------------------------------
>
> This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.
>
> ---------------------------------------------------------------------------------------------
>

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------

From jimbird at shaw.ca  Tue Nov  2 12:49:17 2010
From: jimbird at shaw.ca (JIM BIRD)
Date: Tue, 02 Nov 2010 10:49:17 -0600
Subject: [SAMM] Agile Software Development
In-Reply-To: <3D0018576183C3499481587FAE0BAAF808BDE08C@ws-mailsvr.Virtusa.com>
References: <fb99f8665640.4ccd5589@shaw.ca>
	<3D0018576183C3499481587FAE0BAAF808BDE08C@ws-mailsvr.Virtusa.com>
Message-ID: <fbaaf437446a.4ccfecad@shaw.ca>



The problem from a software development perspective is that
maturity models and process frameworks are part of what Agile teams are
reacting against: ?process for process sake?, high-ceremony,
documentation-heavy, more time needed upfront, more time needed downstream. A
good Agile or Lean software team is going to want to resist anything that doesn?t
directly contribute to delivering working code to a customer quickly. This is
taken to extremes with the latest fad of Continuous Deployment where developers run through their code through some automated tests and deploy straight to
production so that they can get immediate feedback. Suicide from a security (and
reliability) point of view of course, but it shows how extreme some teams are
taking these ideas.

I don?t know too many Agile teams, even more responsible
ones who don?t buy into Continuous Deployment, who are going to understand the
point of a maturity model, or try to use one, even one as relatively simple as
SAMM. And BSIMM is even more heavyweight, reasonably so since it is targeted to
enterprises ? but at over 100 measurement areas it is too much for an Agile
team to think about or try to work with. Take SAMM, which I am more familiar
with. There is a lot of emphasis on governance, and strategy and policies and
metrics and audits. This is not what an Agile organization is about. 

Even requirements and architecture are a hard sell ? as you
pointed out James, assessing is about looking at documents, these models
emphasize documents, and an Agile team is going to create only what
documentation is needed to get the job done. What matters to them is working
closely with the customer and delivering code that meets the customer's needs. With an Agile team, you need other ways than looking at
documentation to find evidence that the work is being done. So rather than
asking whether something is documented or formally reviewed, it might be better
to be able to ask the team questions that probe and verify their understanding of
problems. For example in SAMM it asks under Design Review ?Do project teams
document the attack perimeter of software designs?? Now, what is this question
really asking? It?s not about whether something got written down ? writing it
down doesn?t mean it gets dealt with. It?s asking whether the team understands
the attack surface of what they are building and where the risk areas are and
how they are going to handle them. So changing questions like this, questions that
are clearly documentation check-marks, to get to the point behind the document might
help. 

Adapting the maturity models to Agile is tough in other
cases because of the speed at which Agile teams move, the speed at which code
is delivered. Look at something simple like pen testing. In SAMM it asks if pen
testing is done prior to release. Well, if you are releasing every couple of
weeks (or every day or even x times a day for some teams), what does this mean?

It might make sense to come up with a compromise, in the
same way that Microsoft has tried to adapt the SDL to come up with SDL-Agile. To
identify the core practices that Agile teams should focus on, and recognize
that there needs to be / should be some foundational practices and some practices
that should be wrapped into sprints. In my experience managing small software
teams, it makes sense to start with coding ? it?s all about the code. So for
example:

-?????????
Education: people who write software like to get
training, as long as it is good training. So training on software security
awareness and defensive programming is an easy sell. The team needs to
understand software security first. Everybody. Including, and especially as Adrian
Lane pointed out at OWASP AppSec this year, the Product Manager/Product Owner.

-?????????
Code reviews and static analysis: a responsible
Agile team cares about the quality of the code. So making sure that security
checks are included in code reviews / pair programming makes sense (after
people have been trained so that they know what to look for). And any
responsible team is going to be following Continuous Integration. Adding static
analysis to CI is relatively straightforward if you do it from the start.
Harder of course if you already have a lot of code in place. But the tools will
help.

This is only a start of course: SDL-Agile is a good model to
reference, although a lot of teams, even teams that try hard, will fall short
in key areas like threat modeling because of the costs. 

But I?m afraid that at some point a maturity model doesn?t fit.
Helping Agile organizations to get to level 1, to basic good practices and
responsible awareness should be the goal. From there they should continue to
improve themselves through the inspect-and-adapt cycle, with help from security
experts as required. Asking Agile organizations to assess themselves against
some model and move further up some ladder is essentially meaningless. It?s
against how they work and the way that they think. It?s going back 20 years to
SEI CMM and CMMI maturity ladders that these people have already explicitly rejected.
They?ve already found a different way that works better for them. It?s up to
the security community to accept that and find ways to support it. 

Jim Bird

----- Original Message -----
From: James McGovern <JMcGovern at virtusa.com>
Date: Monday, November 1, 2010 7:55 am
Subject: [SAMM] Agile Software Development
To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>

> Many maturity models penalize Agile approaches to software development
> since the focus isn't on creation of comprehensive documentation
> upfront. Is there merit in providing "audit" guidance for those 
> who are
> leveraging Agile methods? How do we encourage folks to think about
> maturity in an iterative way and not interpret SAMM as being more
> waterfall-oriented?
> 
> ?
> 
> James McGovern
> Insurance SBU 
> 
> Virtusa Corporation
> 
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> 
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 
> 688 2890? 
> 
> ? <http://www.virtusa.com/>??? 
> <http://www.virtusa.com/blog/>?? 
> <https://twitter.com/VirtusaCorp>?? 
> <http://www.linkedin.com/companies/virtusa>?? 
> <http://www.facebook.com/VirtusaCorp> 
> 
> ?
> 
> 
> Virtusa was recently ranked and featured in 2010 Global Services 
> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte 
> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey 
> among others.
> 
> -----------------------------------------------------------------
> ----------------------------
> 
> This message, including any attachments, contains confidential 
> information intended for a specific individual and purpose, and 
> is intended for the addressee only. Any unauthorized disclosure, 
> use, dissemination, copying, or distribution of this message or 
> any of its attachments or the information contained in this e-
> mail, or the taking of any action based on it, is strictly 
> prohibited. If you are not the intended recipient, please notify 
> the sender immediately by return e-mail and delete this message.
> 
> -----------------------------------------------------------------
> ----------------------------
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101102/bde6c2bf/attachment-0001.html 

From John.Steven at owasp.org  Wed Nov  3 08:20:30 2010
From: John.Steven at owasp.org (John Steven)
Date: Wed, 3 Nov 2010 08:20:30 -0400
Subject: [SAMM] Agile Software Development
Message-ID: <AANLkTikd++QN2oTNG3NU3j_WJVu14qTgnSe9Bp2dmkd8@mail.gmail.com>

Jim,

Like James' email, it's hard to disagree with your points. Agile's
rows against process/governance are as predictable as in the reverse,
for good reason.

The net is this: Agile teams can be opposed towards docs/process but
rarely do they have the skills, irreplaceability, and executive
support to completely inoculate themselves against all
audit/governance.

That's why, with the experiences I shared, I tried to keep things in
the perspective of "Agile teams got credit for [activity XXX], which
they were already doing". In cases where they weren't already
conducting the activity (or were doing so without a specific eye
towards security), it was painless to add.

The object, in my opinion, should be to make small changes to behavior
that dramatically affect security outcomes, without having to change
development culture. Where Agile folk are doing good stuff, the push
should be to 'translate' this stuff into credit within the applied
maturity model.

Note that rather than requirements, I mentioned misuse cases (very
akin to user stories the teams already did).

Rather than architecture, security toolkit reuse occurred and threats
were identified (did I mention threats in my last email? That might
have been an omission)

I've found neat use of static analysis to provide assurance cases too.
Rather than documenting requirements compliant with a policy teams
have implemented custom rules that produce assurance that a security
toolkit was applied thoroughly across an application (in their Hudson
build). When auditors come around and said, "Hey, our policies say you
need requirements against XSS" the team was able to respond,

"We don't do that. But! we did identify a need to protect against that
and our nightly builds' results show our commitment to that hygiene."
Auditors needed to be trained to recognize that behavior as OK. This
seems to gel with your experience as well.

The second net is this: organizations in which Agile and
process/audit/MM's coexist need to recognize that:

* Securing agile dev won't require special activities outside their MM's canon
* Adjusting inputs/outputs/activities for agile teams may be more natural
  * Code review --> Peer review
* Giving teams credit for practiced MM-compliant activities will be
easier than mandating a single specific activity from each waterfall
process phase

Remember, SAMM doesn't prescribe particular activity. It presents a
menu from which organizations can chose a set providing desired
minimum coverage.  Likewise, BSIMM observed a variety of activities,
each of which may or may not be suited to a particular org/culture.

Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
that could be co-opted to be SAMM-agile.

-jOHN

> ----------------------------------------------------------------------
>
> Date: Tue, 02 Nov 2010 10:49:17 -0600
> From: JIM BIRD
>
> The problem from a software development perspective is that
> maturity models and process frameworks are part of what Agile teams are
> reacting against: ?process for process sake?, high-ceremony,
> documentation-heavy, more time needed upfront, more time needed downstream. A
> good Agile or Lean software team is going to want to resist anything that doesn?t
> directly contribute to delivering working code to a customer quickly. This is
> taken to extremes with the latest fad of Continuous Deployment where developers run through their code through some automated tests and deploy straight to
> production so that they can get immediate feedback. Suicide from a security (and
> reliability) point of view of course, but it shows how extreme some teams are
> taking these ideas.
>
> I don?t know too many Agile teams, even more responsible
> ones who don?t buy into Continuous Deployment, who are going to understand the
> point of a maturity model, or try to use one, even one as relatively simple as
> SAMM. And BSIMM is even more heavyweight, reasonably so since it is targeted to
> enterprises ? but at over 100 measurement areas it is too much for an Agile
> team to think about or try to work with. Take SAMM, which I am more familiar
> with. There is a lot of emphasis on governance, and strategy and policies and
> metrics and audits. This is not what an Agile organization is about.
>
> Even requirements and architecture are a hard sell ? as you
> pointed out James, assessing is about looking at documents, these models
> emphasize documents, and an Agile team is going to create only what
> documentation is needed to get the job done. What matters to them is working
> closely with the customer and delivering code that meets the customer's needs. With an Agile team, you need other ways than looking at
> documentation to find evidence that the work is being done. So rather than
> asking whether something is documented or formally reviewed, it might be better
> to be able to ask the team questions that probe and verify their understanding of
> problems. For example in SAMM it asks under Design Review ?Do project teams
> document the attack perimeter of software designs?? Now, what is this question
> really asking? It?s not about whether something got written down ? writing it
> down doesn?t mean it gets dealt with. It?s asking whether the team understands
> the attack surface of what they are building and where the risk areas are and
> how they are going to handle them. So changing questions like this, questions that
> are clearly documentation check-marks, to get to the point behind the document might
> help.
>
> Adapting the maturity models to Agile is tough in other
> cases because of the speed at which Agile teams move, the speed at which code
> is delivered. Look at something simple like pen testing. In SAMM it asks if pen
> testing is done prior to release. Well, if you are releasing every couple of
> weeks (or every day or even x times a day for some teams), what does this mean?
>
> It might make sense to come up with a compromise, in the
> same way that Microsoft has tried to adapt the SDL to come up with SDL-Agile. To
> identify the core practices that Agile teams should focus on, and recognize
> that there needs to be / should be some foundational practices and some practices
> that should be wrapped into sprints. In my experience managing small software
> teams, it makes sense to start with coding ? it?s all about the code. So for
> example:
>
> -?????????
> Education: people who write software like to get
> training, as long as it is good training. So training on software security
> awareness and defensive programming is an easy sell. The team needs to
> understand software security first. Everybody. Including, and especially as Adrian
> Lane pointed out at OWASP AppSec this year, the Product Manager/Product Owner.
>
> -?????????
> Code reviews and static analysis: a responsible
> Agile team cares about the quality of the code. So making sure that security
> checks are included in code reviews / pair programming makes sense (after
> people have been trained so that they know what to look for). And any
> responsible team is going to be following Continuous Integration. Adding static
> analysis to CI is relatively straightforward if you do it from the start.
> Harder of course if you already have a lot of code in place. But the tools will
> help.
>
> This is only a start of course: SDL-Agile is a good model to
> reference, although a lot of teams, even teams that try hard, will fall short
> in key areas like threat modeling because of the costs.
>
> But I?m afraid that at some point a maturity model doesn?t fit.
> Helping Agile organizations to get to level 1, to basic good practices and
> responsible awareness should be the goal. From there they should continue to
> improve themselves through the inspect-and-adapt cycle, with help from security
> experts as required. Asking Agile organizations to assess themselves against
> some model and move further up some ladder is essentially meaningless. It?s
> against how they work and the way that they think. It?s going back 20 years to
> SEI CMM and CMMI maturity ladders that these people have already explicitly rejected.
> They?ve already found a different way that works better for them. It?s up to
> the security community to accept that and find ways to support it.
>
> Jim Bird
>
> ----- Original Message -----
> From: James McGovern <JMcGovern at virtusa.com>
> Date: Monday, November 1, 2010 7:55 am
> Subject: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>
>> Many maturity models penalize Agile approaches to software development
>> since the focus isn't on creation of comprehensive documentation
>> upfront. Is there merit in providing "audit" guidance for those
>> who are
>> leveraging Agile methods? How do we encourage folks to think about
>> maturity in an iterative way and not interpret SAMM as being more
>> waterfall-oriented?
>>
>> ?
>>
>> James McGovern
>> Insurance SBU
>>
>> Virtusa Corporation
>>
>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>
>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>> 688 2890?
>>
>> ? <http://www.virtusa.com/>???
>> <http://www.virtusa.com/blog/>??
>> <https://twitter.com/VirtusaCorp>??
>> <http://www.linkedin.com/companies/virtusa>??
>> <http://www.facebook.com/VirtusaCorp>
>>
>> ?
>>
>>
>> Virtusa was recently ranked and featured in 2010 Global Services
>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>> among others.
>>
>> -----------------------------------------------------------------
>> ----------------------------

From JMcGovern at virtusa.com  Wed Nov  3 09:35:12 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Wed, 3 Nov 2010 09:35:12 -0400
Subject: [SAMM] Agile Software Development
In-Reply-To: <AANLkTikd++QN2oTNG3NU3j_WJVu14qTgnSe9Bp2dmkd8@mail.gmail.com>
References: <AANLkTikd++QN2oTNG3NU3j_WJVu14qTgnSe9Bp2dmkd8@mail.gmail.com>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE349@ws-mailsvr.Virtusa.com>

1. Code review not always the same as peer review. When looking at approaches such as XP where a team may be doing pair programming, there is no discrete "event" for an auditor to measure. Likewise, difficult for auditor to understand whether everyone is held to same standard (consistency)

2. Let's keep terminology clean when it comes to Agile and think about the notion of User Stories as a superset or control around enumerated requirements. User Stories can also have a security slant. User Stories are created by users/business customers while artifacts such as threat models tend to be created by IT types. If you look at how most shops operate, the user story is actually more important since it may actually cause the creation of requirements around it which in turn get tested by QA. Threat models while valuable rarely have the same effect or traceability characteristics.

3. Static analysis can only identify issues that are "findable" at coding time. Creating an artifact that late in the lifecycle is actually a suboptimal idea. Higher maturity is created if we can address security in an agile way at whatever feels like an architecture/design review. While this can't be automated, it can be done against a set of prescribed principles such as defense in depth, least privilege, etc.

4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can produce pretty dashboards articulating counts of highs, mediums, lows but doesn't provide the next step that would be truly valuable to an auditor which would be to align the findings with something like the OWASP Risk Rating method. I remember lots of painful conversations where there were 1000s of highs that resulted in low risk in one application where in another, there were 6 mediums and 1 low where it was possible to get your hands on a credit card and some PII data.  Since Pravir works for Fortify, I will let him noodle this statement to see if he believes there is a better way :-)

James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??

-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On Behalf Of John Steven
Sent: Wednesday, November 03, 2010 8:21 AM
To: samm at lists.owasp.org; jimbird at shaw.ca
Subject: Re: [SAMM] Agile Software Development

Jim,

Like James' email, it's hard to disagree with your points. Agile's
rows against process/governance are as predictable as in the reverse,
for good reason.

The net is this: Agile teams can be opposed towards docs/process but
rarely do they have the skills, irreplaceability, and executive
support to completely inoculate themselves against all
audit/governance.

That's why, with the experiences I shared, I tried to keep things in
the perspective of "Agile teams got credit for [activity XXX], which
they were already doing". In cases where they weren't already
conducting the activity (or were doing so without a specific eye
towards security), it was painless to add.

The object, in my opinion, should be to make small changes to behavior
that dramatically affect security outcomes, without having to change
development culture. Where Agile folk are doing good stuff, the push
should be to 'translate' this stuff into credit within the applied
maturity model.

Note that rather than requirements, I mentioned misuse cases (very
akin to user stories the teams already did).

Rather than architecture, security toolkit reuse occurred and threats
were identified (did I mention threats in my last email? That might
have been an omission)

I've found neat use of static analysis to provide assurance cases too.
Rather than documenting requirements compliant with a policy teams
have implemented custom rules that produce assurance that a security
toolkit was applied thoroughly across an application (in their Hudson
build). When auditors come around and said, "Hey, our policies say you
need requirements against XSS" the team was able to respond,

"We don't do that. But! we did identify a need to protect against that
and our nightly builds' results show our commitment to that hygiene."
Auditors needed to be trained to recognize that behavior as OK. This
seems to gel with your experience as well.

The second net is this: organizations in which Agile and
process/audit/MM's coexist need to recognize that:

* Securing agile dev won't require special activities outside their MM's canon
* Adjusting inputs/outputs/activities for agile teams may be more natural
  * Code review --> Peer review
* Giving teams credit for practiced MM-compliant activities will be
easier than mandating a single specific activity from each waterfall
process phase

Remember, SAMM doesn't prescribe particular activity. It presents a
menu from which organizations can chose a set providing desired
minimum coverage.  Likewise, BSIMM observed a variety of activities,
each of which may or may not be suited to a particular org/culture.

Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
that could be co-opted to be SAMM-agile.

-jOHN

> ----------------------------------------------------------------------
>
> Date: Tue, 02 Nov 2010 10:49:17 -0600
> From: JIM BIRD
>
> The problem from a software development perspective is that
> maturity models and process frameworks are part of what Agile teams are
> reacting against: ?process for process sake?, high-ceremony,
> documentation-heavy, more time needed upfront, more time needed downstream. A
> good Agile or Lean software team is going to want to resist anything that doesn?t
> directly contribute to delivering working code to a customer quickly. This is
> taken to extremes with the latest fad of Continuous Deployment where developers run through their code through some automated tests and deploy straight to
> production so that they can get immediate feedback. Suicide from a security (and
> reliability) point of view of course, but it shows how extreme some teams are
> taking these ideas.
>
> I don?t know too many Agile teams, even more responsible
> ones who don?t buy into Continuous Deployment, who are going to understand the
> point of a maturity model, or try to use one, even one as relatively simple as
> SAMM. And BSIMM is even more heavyweight, reasonably so since it is targeted to
> enterprises ? but at over 100 measurement areas it is too much for an Agile
> team to think about or try to work with. Take SAMM, which I am more familiar
> with. There is a lot of emphasis on governance, and strategy and policies and
> metrics and audits. This is not what an Agile organization is about.
>
> Even requirements and architecture are a hard sell ? as you
> pointed out James, assessing is about looking at documents, these models
> emphasize documents, and an Agile team is going to create only what
> documentation is needed to get the job done. What matters to them is working
> closely with the customer and delivering code that meets the customer's needs. With an Agile team, you need other ways than looking at
> documentation to find evidence that the work is being done. So rather than
> asking whether something is documented or formally reviewed, it might be better
> to be able to ask the team questions that probe and verify their understanding of
> problems. For example in SAMM it asks under Design Review ?Do project teams
> document the attack perimeter of software designs?? Now, what is this question
> really asking? It?s not about whether something got written down ? writing it
> down doesn?t mean it gets dealt with. It?s asking whether the team understands
> the attack surface of what they are building and where the risk areas are and
> how they are going to handle them. So changing questions like this, questions that
> are clearly documentation check-marks, to get to the point behind the document might
> help.
>
> Adapting the maturity models to Agile is tough in other
> cases because of the speed at which Agile teams move, the speed at which code
> is delivered. Look at something simple like pen testing. In SAMM it asks if pen
> testing is done prior to release. Well, if you are releasing every couple of
> weeks (or every day or even x times a day for some teams), what does this mean?
>
> It might make sense to come up with a compromise, in the
> same way that Microsoft has tried to adapt the SDL to come up with SDL-Agile. To
> identify the core practices that Agile teams should focus on, and recognize
> that there needs to be / should be some foundational practices and some practices
> that should be wrapped into sprints. In my experience managing small software
> teams, it makes sense to start with coding ? it?s all about the code. So for
> example:
>
> -?????????
> Education: people who write software like to get
> training, as long as it is good training. So training on software security
> awareness and defensive programming is an easy sell. The team needs to
> understand software security first. Everybody. Including, and especially as Adrian
> Lane pointed out at OWASP AppSec this year, the Product Manager/Product Owner.
>
> -?????????
> Code reviews and static analysis: a responsible
> Agile team cares about the quality of the code. So making sure that security
> checks are included in code reviews / pair programming makes sense (after
> people have been trained so that they know what to look for). And any
> responsible team is going to be following Continuous Integration. Adding static
> analysis to CI is relatively straightforward if you do it from the start.
> Harder of course if you already have a lot of code in place. But the tools will
> help.
>
> This is only a start of course: SDL-Agile is a good model to
> reference, although a lot of teams, even teams that try hard, will fall short
> in key areas like threat modeling because of the costs.
>
> But I?m afraid that at some point a maturity model doesn?t fit.
> Helping Agile organizations to get to level 1, to basic good practices and
> responsible awareness should be the goal. From there they should continue to
> improve themselves through the inspect-and-adapt cycle, with help from security
> experts as required. Asking Agile organizations to assess themselves against
> some model and move further up some ladder is essentially meaningless. It?s
> against how they work and the way that they think. It?s going back 20 years to
> SEI CMM and CMMI maturity ladders that these people have already explicitly rejected.
> They?ve already found a different way that works better for them. It?s up to
> the security community to accept that and find ways to support it.
>
> Jim Bird
>
> ----- Original Message -----
> From: James McGovern <JMcGovern at virtusa.com>
> Date: Monday, November 1, 2010 7:55 am
> Subject: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>
>> Many maturity models penalize Agile approaches to software development
>> since the focus isn't on creation of comprehensive documentation
>> upfront. Is there merit in providing "audit" guidance for those
>> who are
>> leveraging Agile methods? How do we encourage folks to think about
>> maturity in an iterative way and not interpret SAMM as being more
>> waterfall-oriented?
>>
>> ?
>>
>> James McGovern
>> Insurance SBU
>>
>> Virtusa Corporation
>>
>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>
>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>> 688 2890?
>>
>> ? <http://www.virtusa.com/>???
>> <http://www.virtusa.com/blog/>??
>> <https://twitter.com/VirtusaCorp>??
>> <http://www.linkedin.com/companies/virtusa>??
>> <http://www.facebook.com/VirtusaCorp>
>>
>> ?
>>
>>
>> Virtusa was recently ranked and featured in 2010 Global Services
>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>> among others.
>>
>> -----------------------------------------------------------------
>> ----------------------------
_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------

From John.Steven at owasp.org  Wed Nov  3 10:00:10 2010
From: John.Steven at owasp.org (John Steven)
Date: Wed, 3 Nov 2010 10:00:10 -0400
Subject: [SAMM] Agile Software Development
Message-ID: <AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6@mail.gmail.com>

James,

I agree with your points below. Again, my point is only that it
doesn't have to be combative/mutually exclusive when you can find
overlap and opportunity.

-jOHN

On Wed, Nov 3, 2010 at 10:34 AM,  <samm-request at lists.owasp.org> wrote:


> ------------------------------
>
> Date: Wed, 3 Nov 2010 09:35:12 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: Re: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; ? ? ? charset="iso-8859-1"
>
> 1. Code review not always the same as peer review. When looking at approaches such as XP where a team may be doing pair programming, there is no discrete "event" for an auditor to measure. Likewise, difficult for auditor to understand whether everyone is held to same standard (consistency)
>
> 2. Let's keep terminology clean when it comes to Agile and think about the notion of User Stories as a superset or control around enumerated requirements. User Stories can also have a security slant. User Stories are created by users/business customers while artifacts such as threat models tend to be created by IT types. If you look at how most shops operate, the user story is actually more important since it may actually cause the creation of requirements around it which in turn get tested by QA. Threat models while valuable rarely have the same effect or traceability characteristics.
>
> 3. Static analysis can only identify issues that are "findable" at coding time. Creating an artifact that late in the lifecycle is actually a suboptimal idea. Higher maturity is created if we can address security in an agile way at whatever feels like an architecture/design review. While this can't be automated, it can be done against a set of prescribed principles such as defense in depth, least privilege, etc.
>
> 4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can produce pretty dashboards articulating counts of highs, mediums, lows but doesn't provide the next step that would be truly valuable to an auditor which would be to align the findings with something like the OWASP Risk Rating method. I remember lots of painful conversations where there were 1000s of highs that resulted in low risk in one application where in another, there were 6 mediums and 1 low where it was possible to get your hands on a credit card and some PII data. ?Since Pravir works for Fortify, I will let him noodle this statement to see if he believes there is a better way :-)
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> ? ??
>
> -----Original Message-----
> From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On Behalf Of John Steven
> Sent: Wednesday, November 03, 2010 8:21 AM
> To: samm at lists.owasp.org; jimbird at shaw.ca
> Subject: Re: [SAMM] Agile Software Development
>
> Jim,
>
> Like James' email, it's hard to disagree with your points. Agile's
> rows against process/governance are as predictable as in the reverse,
> for good reason.
>
> The net is this: Agile teams can be opposed towards docs/process but
> rarely do they have the skills, irreplaceability, and executive
> support to completely inoculate themselves against all
> audit/governance.
>
> That's why, with the experiences I shared, I tried to keep things in
> the perspective of "Agile teams got credit for [activity XXX], which
> they were already doing". In cases where they weren't already
> conducting the activity (or were doing so without a specific eye
> towards security), it was painless to add.
>
> The object, in my opinion, should be to make small changes to behavior
> that dramatically affect security outcomes, without having to change
> development culture. Where Agile folk are doing good stuff, the push
> should be to 'translate' this stuff into credit within the applied
> maturity model.
>
> Note that rather than requirements, I mentioned misuse cases (very
> akin to user stories the teams already did).
>
> Rather than architecture, security toolkit reuse occurred and threats
> were identified (did I mention threats in my last email? That might
> have been an omission)
>
> I've found neat use of static analysis to provide assurance cases too.
> Rather than documenting requirements compliant with a policy teams
> have implemented custom rules that produce assurance that a security
> toolkit was applied thoroughly across an application (in their Hudson
> build). When auditors come around and said, "Hey, our policies say you
> need requirements against XSS" the team was able to respond,
>
> "We don't do that. But! we did identify a need to protect against that
> and our nightly builds' results show our commitment to that hygiene."
> Auditors needed to be trained to recognize that behavior as OK. This
> seems to gel with your experience as well.
>
> The second net is this: organizations in which Agile and
> process/audit/MM's coexist need to recognize that:
>
> * Securing agile dev won't require special activities outside their MM's canon
> * Adjusting inputs/outputs/activities for agile teams may be more natural
> ?* Code review --> Peer review
> * Giving teams credit for practiced MM-compliant activities will be
> easier than mandating a single specific activity from each waterfall
> process phase
>
> Remember, SAMM doesn't prescribe particular activity. It presents a
> menu from which organizations can chose a set providing desired
> minimum coverage. ?Likewise, BSIMM observed a variety of activities,
> each of which may or may not be suited to a particular org/culture.
>
> Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> that could be co-opted to be SAMM-agile.
>
> -jOHN
>
>> ----------------------------------------------------------------------
>>
>> Date: Tue, 02 Nov 2010 10:49:17 -0600
>> From: JIM BIRD
>>
>> The problem from a software development perspective is that
>> maturity models and process frameworks are part of what Agile teams are
>> reacting against: ?process for process sake?, high-ceremony,
>> documentation-heavy, more time needed upfront, more time needed downstream. A
>> good Agile or Lean software team is going to want to resist anything that doesn?t
>> directly contribute to delivering working code to a customer quickly. This is
>> taken to extremes with the latest fad of Continuous Deployment where developers run through their code through some automated tests and deploy straight to
>> production so that they can get immediate feedback. Suicide from a security (and
>> reliability) point of view of course, but it shows how extreme some teams are
>> taking these ideas.
>>
>> I don?t know too many Agile teams, even more responsible
>> ones who don?t buy into Continuous Deployment, who are going to understand the
>> point of a maturity model, or try to use one, even one as relatively simple as
>> SAMM. And BSIMM is even more heavyweight, reasonably so since it is targeted to
>> enterprises ? but at over 100 measurement areas it is too much for an Agile
>> team to think about or try to work with. Take SAMM, which I am more familiar
>> with. There is a lot of emphasis on governance, and strategy and policies and
>> metrics and audits. This is not what an Agile organization is about.
>>
>> Even requirements and architecture are a hard sell ? as you
>> pointed out James, assessing is about looking at documents, these models
>> emphasize documents, and an Agile team is going to create only what
>> documentation is needed to get the job done. What matters to them is working
>> closely with the customer and delivering code that meets the customer's needs. With an Agile team, you need other ways than looking at
>> documentation to find evidence that the work is being done. So rather than
>> asking whether something is documented or formally reviewed, it might be better
>> to be able to ask the team questions that probe and verify their understanding of
>> problems. For example in SAMM it asks under Design Review ?Do project teams
>> document the attack perimeter of software designs?? Now, what is this question
>> really asking? It?s not about whether something got written down ? writing it
>> down doesn?t mean it gets dealt with. It?s asking whether the team understands
>> the attack surface of what they are building and where the risk areas are and
>> how they are going to handle them. So changing questions like this, questions that
>> are clearly documentation check-marks, to get to the point behind the document might
>> help.
>>
>> Adapting the maturity models to Agile is tough in other
>> cases because of the speed at which Agile teams move, the speed at which code
>> is delivered. Look at something simple like pen testing. In SAMM it asks if pen
>> testing is done prior to release. Well, if you are releasing every couple of
>> weeks (or every day or even x times a day for some teams), what does this mean?
>>
>> It might make sense to come up with a compromise, in the
>> same way that Microsoft has tried to adapt the SDL to come up with SDL-Agile. To
>> identify the core practices that Agile teams should focus on, and recognize
>> that there needs to be / should be some foundational practices and some practices
>> that should be wrapped into sprints. In my experience managing small software
>> teams, it makes sense to start with coding ? it?s all about the code. So for
>> example:
>>
>> -?????????
>> Education: people who write software like to get
>> training, as long as it is good training. So training on software security
>> awareness and defensive programming is an easy sell. The team needs to
>> understand software security first. Everybody. Including, and especially as Adrian
>> Lane pointed out at OWASP AppSec this year, the Product Manager/Product Owner.
>>
>> -?????????
>> Code reviews and static analysis: a responsible
>> Agile team cares about the quality of the code. So making sure that security
>> checks are included in code reviews / pair programming makes sense (after
>> people have been trained so that they know what to look for). And any
>> responsible team is going to be following Continuous Integration. Adding static
>> analysis to CI is relatively straightforward if you do it from the start.
>> Harder of course if you already have a lot of code in place. But the tools will
>> help.
>>
>> This is only a start of course: SDL-Agile is a good model to
>> reference, although a lot of teams, even teams that try hard, will fall short
>> in key areas like threat modeling because of the costs.
>>
>> But I?m afraid that at some point a maturity model doesn?t fit.
>> Helping Agile organizations to get to level 1, to basic good practices and
>> responsible awareness should be the goal. From there they should continue to
>> improve themselves through the inspect-and-adapt cycle, with help from security
>> experts as required. Asking Agile organizations to assess themselves against
>> some model and move further up some ladder is essentially meaningless. It?s
>> against how they work and the way that they think. It?s going back 20 years to
>> SEI CMM and CMMI maturity ladders that these people have already explicitly rejected.
>> They?ve already found a different way that works better for them. It?s up to
>> the security community to accept that and find ways to support it.
>>
>> Jim Bird
>>
>> ----- Original Message -----
>> From: James McGovern <JMcGovern at virtusa.com>
>> Date: Monday, November 1, 2010 7:55 am
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>>
>>> Many maturity models penalize Agile approaches to software development
>>> since the focus isn't on creation of comprehensive documentation
>>> upfront. Is there merit in providing "audit" guidance for those
>>> who are
>>> leveraging Agile methods? How do we encourage folks to think about
>>> maturity in an iterative way and not interpret SAMM as being more
>>> waterfall-oriented?
>>>
>>> ?
>>>
>>> James McGovern
>>> Insurance SBU
>>>
>>> Virtusa Corporation
>>>
>>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>>
>>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>>> 688 2890?
>>>
>>> ? <http://www.virtusa.com/>???
>>> <http://www.virtusa.com/blog/>??
>>> <https://twitter.com/VirtusaCorp>??
>>> <http://www.linkedin.com/companies/virtusa>??
>>> <http://www.facebook.com/VirtusaCorp>
>>>
>>> ?
>>>
>>>
>>> Virtusa was recently ranked and featured in 2010 Global Services
>>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>>> among others.
>>>
>>> -----------------------------------------------------------------
>>> ----------------------------
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
>
> Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
> ---------------------------------------------------------------------------------------------
>
> This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

From rkfairchild at alumni.ou.edu  Wed Nov  3 11:18:33 2010
From: rkfairchild at alumni.ou.edu (Russ Fairchild)
Date: Wed, 03 Nov 2010 11:18:33 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 7
In-Reply-To: <mailman.7.1288800004.3513.samm@lists.owasp.org>
References: <mailman.7.1288800004.3513.samm@lists.owasp.org>
Message-ID: <000a01cb7b6a$6209a460$261ced20$@ou.edu>

The word that bothers me in this discussion is the word "auditor."

An auditor can never effectively look at code and determine if it is secure
or not.

An auditor can only look at controls and see if they are effective or not
based upon sampling.

My belief is there needs to be someone in the process that provides Software
Security Assurance (SSA).

They are the control.  And that control needs to be matured into the
organization.

It starts with code review and working with the developers, dynamic code
review and working with the developer, on and on.

Eventually the developer themselves will have infused with them the
knowledge that will help them write more secure code with no productivity
loss.

An auditor can't secure code because they won't understand the business
application.

Understanding the business application will require working with the
developers where both the SSA and learn from each other.

Russ Fairchild


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 12:00 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 7

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: Agile Software Development (John Steven)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 10:00:10 -0400
From: John Steven <John.Steven at owasp.org>
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>
Message-ID:
	<AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

James,

I agree with your points below. Again, my point is only that it
doesn't have to be combative/mutually exclusive when you can find
overlap and opportunity.

-jOHN

On Wed, Nov 3, 2010 at 10:34 AM,  <samm-request at lists.owasp.org> wrote:


> ------------------------------
>
> Date: Wed, 3 Nov 2010 09:35:12 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: Re: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; ? ? ? charset="iso-8859-1"
>
> 1. Code review not always the same as peer review. When looking at
approaches such as XP where a team may be doing pair programming, there is
no discrete "event" for an auditor to measure. Likewise, difficult for
auditor to understand whether everyone is held to same standard
(consistency)
>
> 2. Let's keep terminology clean when it comes to Agile and think about the
notion of User Stories as a superset or control around enumerated
requirements. User Stories can also have a security slant. User Stories are
created by users/business customers while artifacts such as threat models
tend to be created by IT types. If you look at how most shops operate, the
user story is actually more important since it may actually cause the
creation of requirements around it which in turn get tested by QA. Threat
models while valuable rarely have the same effect or traceability
characteristics.
>
> 3. Static analysis can only identify issues that are "findable" at coding
time. Creating an artifact that late in the lifecycle is actually a
suboptimal idea. Higher maturity is created if we can address security in an
agile way at whatever feels like an architecture/design review. While this
can't be automated, it can be done against a set of prescribed principles
such as defense in depth, least privilege, etc.
>
> 4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can
produce pretty dashboards articulating counts of highs, mediums, lows but
doesn't provide the next step that would be truly valuable to an auditor
which would be to align the findings with something like the OWASP Risk
Rating method. I remember lots of painful conversations where there were
1000s of highs that resulted in low risk in one application where in
another, there were 6 mediums and 1 low where it was possible to get your
hands on a credit card and some PII data. ?Since Pravir works for Fortify, I
will let him noodle this statement to see if he believes there is a better
way :-)
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> ? ??
>
> -----Original Message-----
> From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of John Steven
> Sent: Wednesday, November 03, 2010 8:21 AM
> To: samm at lists.owasp.org; jimbird at shaw.ca
> Subject: Re: [SAMM] Agile Software Development
>
> Jim,
>
> Like James' email, it's hard to disagree with your points. Agile's
> rows against process/governance are as predictable as in the reverse,
> for good reason.
>
> The net is this: Agile teams can be opposed towards docs/process but
> rarely do they have the skills, irreplaceability, and executive
> support to completely inoculate themselves against all
> audit/governance.
>
> That's why, with the experiences I shared, I tried to keep things in
> the perspective of "Agile teams got credit for [activity XXX], which
> they were already doing". In cases where they weren't already
> conducting the activity (or were doing so without a specific eye
> towards security), it was painless to add.
>
> The object, in my opinion, should be to make small changes to behavior
> that dramatically affect security outcomes, without having to change
> development culture. Where Agile folk are doing good stuff, the push
> should be to 'translate' this stuff into credit within the applied
> maturity model.
>
> Note that rather than requirements, I mentioned misuse cases (very
> akin to user stories the teams already did).
>
> Rather than architecture, security toolkit reuse occurred and threats
> were identified (did I mention threats in my last email? That might
> have been an omission)
>
> I've found neat use of static analysis to provide assurance cases too.
> Rather than documenting requirements compliant with a policy teams
> have implemented custom rules that produce assurance that a security
> toolkit was applied thoroughly across an application (in their Hudson
> build). When auditors come around and said, "Hey, our policies say you
> need requirements against XSS" the team was able to respond,
>
> "We don't do that. But! we did identify a need to protect against that
> and our nightly builds' results show our commitment to that hygiene."
> Auditors needed to be trained to recognize that behavior as OK. This
> seems to gel with your experience as well.
>
> The second net is this: organizations in which Agile and
> process/audit/MM's coexist need to recognize that:
>
> * Securing agile dev won't require special activities outside their MM's
canon
> * Adjusting inputs/outputs/activities for agile teams may be more natural
> ?* Code review --> Peer review
> * Giving teams credit for practiced MM-compliant activities will be
> easier than mandating a single specific activity from each waterfall
> process phase
>
> Remember, SAMM doesn't prescribe particular activity. It presents a
> menu from which organizations can chose a set providing desired
> minimum coverage. ?Likewise, BSIMM observed a variety of activities,
> each of which may or may not be suited to a particular org/culture.
>
> Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> that could be co-opted to be SAMM-agile.
>
> -jOHN
>
>> ----------------------------------------------------------------------
>>
>> Date: Tue, 02 Nov 2010 10:49:17 -0600
>> From: JIM BIRD
>>
>> The problem from a software development perspective is that
>> maturity models and process frameworks are part of what Agile teams are
>> reacting against: ?process for process sake?, high-ceremony,
>> documentation-heavy, more time needed upfront, more time needed
downstream. A
>> good Agile or Lean software team is going to want to resist anything that
doesn?t
>> directly contribute to delivering working code to a customer quickly.
This is
>> taken to extremes with the latest fad of Continuous Deployment where
developers run through their code through some automated tests and deploy
straight to
>> production so that they can get immediate feedback. Suicide from a
security (and
>> reliability) point of view of course, but it shows how extreme some teams
are
>> taking these ideas.
>>
>> I don?t know too many Agile teams, even more responsible
>> ones who don?t buy into Continuous Deployment, who are going to
understand the
>> point of a maturity model, or try to use one, even one as relatively
simple as
>> SAMM. And BSIMM is even more heavyweight, reasonably so since it is
targeted to
>> enterprises ? but at over 100 measurement areas it is too much for an
Agile
>> team to think about or try to work with. Take SAMM, which I am more
familiar
>> with. There is a lot of emphasis on governance, and strategy and policies
and
>> metrics and audits. This is not what an Agile organization is about.
>>
>> Even requirements and architecture are a hard sell ? as you
>> pointed out James, assessing is about looking at documents, these models
>> emphasize documents, and an Agile team is going to create only what
>> documentation is needed to get the job done. What matters to them is
working
>> closely with the customer and delivering code that meets the customer's
needs. With an Agile team, you need other ways than looking at
>> documentation to find evidence that the work is being done. So rather
than
>> asking whether something is documented or formally reviewed, it might be
better
>> to be able to ask the team questions that probe and verify their
understanding of
>> problems. For example in SAMM it asks under Design Review ?Do project
teams
>> document the attack perimeter of software designs?? Now, what is this
question
>> really asking? It?s not about whether something got written down ?
writing it
>> down doesn?t mean it gets dealt with. It?s asking whether the team
understands
>> the attack surface of what they are building and where the risk areas are
and
>> how they are going to handle them. So changing questions like this,
questions that
>> are clearly documentation check-marks, to get to the point behind the
document might
>> help.
>>
>> Adapting the maturity models to Agile is tough in other
>> cases because of the speed at which Agile teams move, the speed at which
code
>> is delivered. Look at something simple like pen testing. In SAMM it asks
if pen
>> testing is done prior to release. Well, if you are releasing every couple
of
>> weeks (or every day or even x times a day for some teams), what does this
mean?
>>
>> It might make sense to come up with a compromise, in the
>> same way that Microsoft has tried to adapt the SDL to come up with
SDL-Agile. To
>> identify the core practices that Agile teams should focus on, and
recognize
>> that there needs to be / should be some foundational practices and some
practices
>> that should be wrapped into sprints. In my experience managing small
software
>> teams, it makes sense to start with coding ? it?s all about the code. So
for
>> example:
>>
>> -?????????
>> Education: people who write software like to get
>> training, as long as it is good training. So training on software
security
>> awareness and defensive programming is an easy sell. The team needs to
>> understand software security first. Everybody. Including, and especially
as Adrian
>> Lane pointed out at OWASP AppSec this year, the Product Manager/Product
Owner.
>>
>> -?????????
>> Code reviews and static analysis: a responsible
>> Agile team cares about the quality of the code. So making sure that
security
>> checks are included in code reviews / pair programming makes sense (after
>> people have been trained so that they know what to look for). And any
>> responsible team is going to be following Continuous Integration. Adding
static
>> analysis to CI is relatively straightforward if you do it from the start.
>> Harder of course if you already have a lot of code in place. But the
tools will
>> help.
>>
>> This is only a start of course: SDL-Agile is a good model to
>> reference, although a lot of teams, even teams that try hard, will fall
short
>> in key areas like threat modeling because of the costs.
>>
>> But I?m afraid that at some point a maturity model doesn?t fit.
>> Helping Agile organizations to get to level 1, to basic good practices
and
>> responsible awareness should be the goal. From there they should continue
to
>> improve themselves through the inspect-and-adapt cycle, with help from
security
>> experts as required. Asking Agile organizations to assess themselves
against
>> some model and move further up some ladder is essentially meaningless.
It?s
>> against how they work and the way that they think. It?s going back 20
years to
>> SEI CMM and CMMI maturity ladders that these people have already
explicitly rejected.
>> They?ve already found a different way that works better for them. It?s up
to
>> the security community to accept that and find ways to support it.
>>
>> Jim Bird
>>
>> ----- Original Message -----
>> From: James McGovern <JMcGovern at virtusa.com>
>> Date: Monday, November 1, 2010 7:55 am
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>>
>>> Many maturity models penalize Agile approaches to software development
>>> since the focus isn't on creation of comprehensive documentation
>>> upfront. Is there merit in providing "audit" guidance for those
>>> who are
>>> leveraging Agile methods? How do we encourage folks to think about
>>> maturity in an iterative way and not interpret SAMM as being more
>>> waterfall-oriented?
>>>
>>> ?
>>>
>>> James McGovern
>>> Insurance SBU
>>>
>>> Virtusa Corporation
>>>
>>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>>
>>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>>> 688 2890?
>>>
>>> ? <http://www.virtusa.com/>???
>>> <http://www.virtusa.com/blog/>??
>>> <https://twitter.com/VirtusaCorp>??
>>> <http://www.linkedin.com/companies/virtusa>??
>>> <http://www.facebook.com/VirtusaCorp>
>>>
>>> ?
>>>
>>>
>>> Virtusa was recently ranked and featured in 2010 Global Services
>>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>>> among others.
>>>
>>> -----------------------------------------------------------------
>>> ----------------------------
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
>
> Virtusa was recently ranked and featured in 2010 Global Services 100,
IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast
500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
>
----------------------------------------------------------------------------
-----------------
>
> This message, including any attachments, contains confidential information
intended for a specific individual and purpose, and is intended for the
addressee only. Any unauthorized disclosure, use, dissemination, copying, or
distribution of this message or any of its attachments or the information
contained in this e-mail, or the taking of any action based on it, is
strictly prohibited. If you are not the intended recipient, please notify
the sender immediately by return e-mail and delete this message.


------------------------------

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm


End of SAMM Digest, Vol 20, Issue 7
***********************************


From jimbird at shaw.ca  Wed Nov  3 10:37:18 2010
From: jimbird at shaw.ca (JIM BIRD)
Date: Wed, 03 Nov 2010 08:37:18 -0600
Subject: [SAMM] Agile Software Development
In-Reply-To: <AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6@mail.gmail.com>
References: <AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6@mail.gmail.com>
Message-ID: <fba0258a6f1d.4cd11f3e@shaw.ca>

John,

Cool. I like your approach. As a manager of a software development organization that needs to be both secure and agile, I appreciate this kind of fair minded thinking and pragmatism. A couple of points:

1. We need more ways to help software teams build more secure software without having to use the compliance/audit/governance stick. There are lots of teams who are building software that needs to be more secure but aren't subject to the kind of governance or audit requirements. Those teams aren't going to understand a maturity model or use one, but they still need to be helped somehow.

2. For those teams who are under the thumb of governance and audit, the assessor's perspective will be critical here. For example, I thought your example of using static analysis for XSS compliance was cool, and it makes sense from an Agile perspective: if I can capture requirements in automated tests (or something equivalent), this is a good thing. James' comments show that not everybody will agree - and that's fair too. If we try to build too much room in the assessment model, then as a software developer I believe I have been responsible and I'm happily going doing what I think is good work. And then an assessor comes by and slams me. That would be sad. 

So maybe a SAMM lite / SAMM Agile is needed. What about BSIMM - will there be a BSIMM-lite?

----- Original Message -----
From: John Steven <John.Steven at owasp.org>
Date: Wednesday, November 3, 2010 8:00 am
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>

> James,
> 
> I agree with your points below. Again, my point is only that it
> doesn't have to be combative/mutually exclusive when you can find
> overlap and opportunity.
> 
> -jOHN
> 
> On Wed, Nov 3, 2010 at 10:34 AM,? <samm-
> request at lists.owasp.org> wrote:
> 
> 
> > ------------------------------
> >
> > Date: Wed, 3 Nov 2010 09:35:12 -0400
> > From: "James McGovern" <JMcGovern at virtusa.com>
> > Subject: Re: [SAMM] Agile Software Development
> > To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>> Message-ID:
> > ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-
> mailsvr.Virtusa.com>> Content-Type: text/plain; ? ? ? 
> charset="iso-8859-1"
> >
> > 1. Code review not always the same as peer review. When 
> looking at approaches such as XP where a team may be doing pair 
> programming, there is no discrete "event" for an auditor to 
> measure. Likewise, difficult for auditor to understand whether 
> everyone is held to same standard (consistency)
> >
> > 2. Let's keep terminology clean when it comes to Agile and 
> think about the notion of User Stories as a superset or control 
> around enumerated requirements. User Stories can also have a 
> security slant. User Stories are created by users/business 
> customers while artifacts such as threat models tend to be 
> created by IT types. If you look at how most shops operate, the 
> user story is actually more important since it may actually 
> cause the creation of requirements around it which in turn get 
> tested by QA. Threat models while valuable rarely have the same 
> effect or traceability characteristics.
> >
> > 3. Static analysis can only identify issues that are 
> "findable" at coding time. Creating an artifact that late in the 
> lifecycle is actually a suboptimal idea. Higher maturity is 
> created if we can address security in an agile way at whatever 
> feels like an architecture/design review. While this can't be 
> automated, it can be done against a set of prescribed principles 
> such as defense in depth, least privilege, etc.
> >
> > 4. Many of the static analysis tools such as Ounce Labs, 
> Fortify, etc can produce pretty dashboards articulating counts 
> of highs, mediums, lows but doesn't provide the next step that 
> would be truly valuable to an auditor which would be to align 
> the findings with something like the OWASP Risk Rating method. I 
> remember lots of painful conversations where there were 1000s of 
> highs that resulted in low risk in one application where in 
> another, there were 6 mediums and 1 low where it was possible to 
> get your hands on a credit card and some PII data. ?Since Pravir 
> works for Fortify, I will let him noodle this statement to see 
> if he believes there is a better way :-)
> >
> > James McGovern
> > Insurance SBU
> > Virtusa Corporation
> > 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> > Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> > ? ??
> >
> > -----Original Message-----
> > From: samm-bounces at lists.owasp.org [mailto:samm-
> bounces at lists.owasp.org] On Behalf Of John Steven
> > Sent: Wednesday, November 03, 2010 8:21 AM
> > To: samm at lists.owasp.org; jimbird at shaw.ca
> > Subject: Re: [SAMM] Agile Software Development
> >
> > Jim,
> >
> > Like James' email, it's hard to disagree with your points. Agile's
> > rows against process/governance are as predictable as in the 
> reverse,> for good reason.
> >
> > The net is this: Agile teams can be opposed towards 
> docs/process but
> > rarely do they have the skills, irreplaceability, and executive
> > support to completely inoculate themselves against all
> > audit/governance.
> >
> > That's why, with the experiences I shared, I tried to keep 
> things in
> > the perspective of "Agile teams got credit for [activity XXX], which
> > they were already doing". In cases where they weren't already
> > conducting the activity (or were doing so without a specific eye
> > towards security), it was painless to add.
> >
> > The object, in my opinion, should be to make small changes to 
> behavior> that dramatically affect security outcomes, without 
> having to change
> > development culture. Where Agile folk are doing good stuff, 
> the push
> > should be to 'translate' this stuff into credit within the applied
> > maturity model.
> >
> > Note that rather than requirements, I mentioned misuse cases (very
> > akin to user stories the teams already did).
> >
> > Rather than architecture, security toolkit reuse occurred and 
> threats> were identified (did I mention threats in my last 
> email? That might
> > have been an omission)
> >
> > I've found neat use of static analysis to provide assurance 
> cases too.
> > Rather than documenting requirements compliant with a policy teams
> > have implemented custom rules that produce assurance that a security
> > toolkit was applied thoroughly across an application (in their 
> Hudson> build). When auditors come around and said, "Hey, our 
> policies say you
> > need requirements against XSS" the team was able to respond,
> >
> > "We don't do that. But! we did identify a need to protect 
> against that
> > and our nightly builds' results show our commitment to that 
> hygiene."> Auditors needed to be trained to recognize that 
> behavior as OK. This
> > seems to gel with your experience as well.
> >
> > The second net is this: organizations in which Agile and
> > process/audit/MM's coexist need to recognize that:
> >
> > * Securing agile dev won't require special activities outside 
> their MM's canon
> > * Adjusting inputs/outputs/activities for agile teams may be 
> more natural
> > ?* Code review --> Peer review
> > * Giving teams credit for practiced MM-compliant activities 
> will be
> > easier than mandating a single specific activity from each waterfall
> > process phase
> >
> > Remember, SAMM doesn't prescribe particular activity. It 
> presents a
> > menu from which organizations can chose a set providing desired
> > minimum coverage. ?Likewise, BSIMM observed a variety of activities,
> > each of which may or may not be suited to a particular org/culture.
> >
> > Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> > that could be co-opted to be SAMM-agile.
> >
> > -jOHN
> >
> >> --------------------------------------------------------------
> --------
> >>
> >> Date: Tue, 02 Nov 2010 10:49:17 -0600
> >> From: JIM BIRD
> >>
> >> The problem from a software development perspective is that
> >> maturity models and process frameworks are part of what Agile 
> teams are
> >> reacting against: ?process for process sake?, high-ceremony,
> >> documentation-heavy, more time needed upfront, more time 
> needed downstream. A
> >> good Agile or Lean software team is going to want to resist 
> anything that doesn?t
> >> directly contribute to delivering working code to a customer 
> quickly. This is
> >> taken to extremes with the latest fad of Continuous 
> Deployment where developers run through their code through some 
> automated tests and deploy straight to
> >> production so that they can get immediate feedback. Suicide 
> from a security (and
> >> reliability) point of view of course, but it shows how 
> extreme some teams are
> >> taking these ideas.
> >>
> >> I don?t know too many Agile teams, even more responsible
> >> ones who don?t buy into Continuous Deployment, who are going 
> to understand the
> >> point of a maturity model, or try to use one, even one as 
> relatively simple as
> >> SAMM. And BSIMM is even more heavyweight, reasonably so since 
> it is targeted to
> >> enterprises ? but at over 100 measurement areas it is too 
> much for an Agile
> >> team to think about or try to work with. Take SAMM, which I 
> am more familiar
> >> with. There is a lot of emphasis on governance, and strategy 
> and policies and
> >> metrics and audits. This is not what an Agile organization is 
> about.>>
> >> Even requirements and architecture are a hard sell ? as you
> >> pointed out James, assessing is about looking at documents, 
> these models
> >> emphasize documents, and an Agile team is going to create 
> only what
> >> documentation is needed to get the job done. What matters to 
> them is working
> >> closely with the customer and delivering code that meets the 
> customer's needs. With an Agile team, you need other ways than 
> looking at
> >> documentation to find evidence that the work is being done. 
> So rather than
> >> asking whether something is documented or formally reviewed, 
> it might be better
> >> to be able to ask the team questions that probe and verify 
> their understanding of
> >> problems. For example in SAMM it asks under Design Review ?Do 
> project teams
> >> document the attack perimeter of software designs?? Now, what 
> is this question
> >> really asking? It?s not about whether something got written 
> down ? writing it
> >> down doesn?t mean it gets dealt with. It?s asking whether the 
> team understands
> >> the attack surface of what they are building and where the 
> risk areas are and
> >> how they are going to handle them. So changing questions like 
> this, questions that
> >> are clearly documentation check-marks, to get to the point 
> behind the document might
> >> help.
> >>
> >> Adapting the maturity models to Agile is tough in other
> >> cases because of the speed at which Agile teams move, the 
> speed at which code
> >> is delivered. Look at something simple like pen testing. In 
> SAMM it asks if pen
> >> testing is done prior to release. Well, if you are releasing 
> every couple of
> >> weeks (or every day or even x times a day for some teams), 
> what does this mean?
> >>
> >> It might make sense to come up with a compromise, in the
> >> same way that Microsoft has tried to adapt the SDL to come up 
> with SDL-Agile. To
> >> identify the core practices that Agile teams should focus on, 
> and recognize
> >> that there needs to be / should be some foundational 
> practices and some practices
> >> that should be wrapped into sprints. In my experience 
> managing small software
> >> teams, it makes sense to start with coding ? it?s all about 
> the code. So for
> >> example:
> >>
> >> -?????????
> >> Education: people who write software like to get
> >> training, as long as it is good training. So training on 
> software security
> >> awareness and defensive programming is an easy sell. The team 
> needs to
> >> understand software security first. Everybody. Including, and 
> especially as Adrian
> >> Lane pointed out at OWASP AppSec this year, the Product 
> Manager/Product Owner.
> >>
> >> -?????????
> >> Code reviews and static analysis: a responsible
> >> Agile team cares about the quality of the code. So making 
> sure that security
> >> checks are included in code reviews / pair programming makes 
> sense (after
> >> people have been trained so that they know what to look for). 
> And any
> >> responsible team is going to be following Continuous 
> Integration. Adding static
> >> analysis to CI is relatively straightforward if you do it 
> from the start.
> >> Harder of course if you already have a lot of code in place. 
> But the tools will
> >> help.
> >>
> >> This is only a start of course: SDL-Agile is a good model to
> >> reference, although a lot of teams, even teams that try hard, 
> will fall short
> >> in key areas like threat modeling because of the costs.
> >>
> >> But I?m afraid that at some point a maturity model doesn?t fit.
> >> Helping Agile organizations to get to level 1, to basic good 
> practices and
> >> responsible awareness should be the goal. From there they 
> should continue to
> >> improve themselves through the inspect-and-adapt cycle, with 
> help from security
> >> experts as required. Asking Agile organizations to assess 
> themselves against
> >> some model and move further up some ladder is essentially 
> meaningless. It?s
> >> against how they work and the way that they think. It?s going 
> back 20 years to
> >> SEI CMM and CMMI maturity ladders that these people have 
> already explicitly rejected.
> >> They?ve already found a different way that works better for 
> them. It?s up to
> >> the security community to accept that and find ways to 
> support it.
> >>
> >> Jim Bird
> >>
> >> ----- Original Message -----
> >> From: James McGovern <JMcGovern at virtusa.com>
> >> Date: Monday, November 1, 2010 7:55 am
> >> Subject: [SAMM] Agile Software Development
> >> To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>>>
> >>> Many maturity models penalize Agile approaches to software 
> development>>> since the focus isn't on creation of 
> comprehensive documentation
> >>> upfront. Is there merit in providing "audit" guidance for those
> >>> who are
> >>> leveraging Agile methods? How do we encourage folks to think about
> >>> maturity in an iterative way and not interpret SAMM as being more
> >>> waterfall-oriented?
> >>>
> >>> ?
> >>>
> >>> James McGovern
> >>> Insurance SBU
> >>>
> >>> Virtusa Corporation
> >>>
> >>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> >>>
> >>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
> >>> 688 2890?
> >>>
> >>> ? <http://www.virtusa.com/>???
> >>> <http://www.virtusa.com/blog/>??
> >>> <https://twitter.com/VirtusaCorp>??
> >>> <http://www.linkedin.com/companies/virtusa>??
> >>> <http://www.facebook.com/VirtusaCorp>
> >>>
> >>> ?
> >>>
> >>>
> >>> Virtusa was recently ranked and featured in 2010 Global Services
> >>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
> >>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
> >>> among others.
> >>>
> >>> -------------------------------------------------------------
> ----
> >>> ----------------------------
> > _______________________________________________
> > SAMM mailing list
> > SAMM at lists.owasp.org
> > https://lists.owasp.org/mailman/listinfo/samm
> >
> > Virtusa was recently ranked and featured in 2010 Global 
> Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 
> Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best 
> Employers Survey among others.
> >
> > ---------------------------------------------------------------
> ------------------------------
> >
> > This message, including any attachments, contains confidential 
> information intended for a specific individual and purpose, and 
> is intended for the addressee only. Any unauthorized disclosure, 
> use, dissemination, copying, or distribution of this message or 
> any of its attachments or the information contained in this e-
> mail, or the taking of any action based on it, is strictly 
> prohibited. If you are not the intended recipient, please notify 
> the sender immediately by return e-mail and delete this message.
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101103/5647b4d9/attachment-0001.html 

From JMcGovern at virtusa.com  Wed Nov  3 14:14:23 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Wed, 3 Nov 2010 14:14:23 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 7
In-Reply-To: <000a01cb7b6a$6209a460$261ced20$@ou.edu>
References: <mailman.7.1288800004.3513.samm@lists.owasp.org>
	<000a01cb7b6a$6209a460$261ced20$@ou.edu>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE3B3@ws-mailsvr.Virtusa.com>

1. If we believe that the someone in the process that provides Software Security Assurance, do we also believe this individual should be separate from the development team? PCI seems to think so. Do you know that I tell my son's to review all of my code before they get to go to Chuck e. Cheeses? Care to guess how quickly my code gets reviewed? NOTE: The nine year old has already found uses for WebScarab in changing parms for the games he plays.

2. We shouldn't assume that the developers even understand business context. Think about the throw it over the wall model better known as outsourcing. They are given "instructions" such as put widget X on page Y without any additional context or participation from above (us US-based enterprisey types)

James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On Behalf Of Russ Fairchild
Sent: Wednesday, November 03, 2010 11:19 AM
To: samm at lists.owasp.org
Subject: Re: [SAMM] SAMM Digest, Vol 20, Issue 7

The word that bothers me in this discussion is the word "auditor."

An auditor can never effectively look at code and determine if it is secure
or not.

An auditor can only look at controls and see if they are effective or not
based upon sampling.

My belief is there needs to be someone in the process that provides Software
Security Assurance (SSA).

They are the control.  And that control needs to be matured into the
organization.

It starts with code review and working with the developers, dynamic code
review and working with the developer, on and on.

Eventually the developer themselves will have infused with them the
knowledge that will help them write more secure code with no productivity
loss.

An auditor can't secure code because they won't understand the business
application.

Understanding the business application will require working with the
developers where both the SSA and learn from each other.

Russ Fairchild


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 12:00 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 7

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: Agile Software Development (John Steven)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 10:00:10 -0400
From: John Steven <John.Steven at owasp.org>
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>
Message-ID:
	<AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

James,

I agree with your points below. Again, my point is only that it
doesn't have to be combative/mutually exclusive when you can find
overlap and opportunity.

-jOHN

On Wed, Nov 3, 2010 at 10:34 AM,  <samm-request at lists.owasp.org> wrote:


> ------------------------------
>
> Date: Wed, 3 Nov 2010 09:35:12 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: Re: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; ? ? ? charset="iso-8859-1"
>
> 1. Code review not always the same as peer review. When looking at
approaches such as XP where a team may be doing pair programming, there is
no discrete "event" for an auditor to measure. Likewise, difficult for
auditor to understand whether everyone is held to same standard
(consistency)
>
> 2. Let's keep terminology clean when it comes to Agile and think about the
notion of User Stories as a superset or control around enumerated
requirements. User Stories can also have a security slant. User Stories are
created by users/business customers while artifacts such as threat models
tend to be created by IT types. If you look at how most shops operate, the
user story is actually more important since it may actually cause the
creation of requirements around it which in turn get tested by QA. Threat
models while valuable rarely have the same effect or traceability
characteristics.
>
> 3. Static analysis can only identify issues that are "findable" at coding
time. Creating an artifact that late in the lifecycle is actually a
suboptimal idea. Higher maturity is created if we can address security in an
agile way at whatever feels like an architecture/design review. While this
can't be automated, it can be done against a set of prescribed principles
such as defense in depth, least privilege, etc.
>
> 4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can
produce pretty dashboards articulating counts of highs, mediums, lows but
doesn't provide the next step that would be truly valuable to an auditor
which would be to align the findings with something like the OWASP Risk
Rating method. I remember lots of painful conversations where there were
1000s of highs that resulted in low risk in one application where in
another, there were 6 mediums and 1 low where it was possible to get your
hands on a credit card and some PII data. ?Since Pravir works for Fortify, I
will let him noodle this statement to see if he believes there is a better
way :-)
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> ? ??
>
> -----Original Message-----
> From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of John Steven
> Sent: Wednesday, November 03, 2010 8:21 AM
> To: samm at lists.owasp.org; jimbird at shaw.ca
> Subject: Re: [SAMM] Agile Software Development
>
> Jim,
>
> Like James' email, it's hard to disagree with your points. Agile's
> rows against process/governance are as predictable as in the reverse,
> for good reason.
>
> The net is this: Agile teams can be opposed towards docs/process but
> rarely do they have the skills, irreplaceability, and executive
> support to completely inoculate themselves against all
> audit/governance.
>
> That's why, with the experiences I shared, I tried to keep things in
> the perspective of "Agile teams got credit for [activity XXX], which
> they were already doing". In cases where they weren't already
> conducting the activity (or were doing so without a specific eye
> towards security), it was painless to add.
>
> The object, in my opinion, should be to make small changes to behavior
> that dramatically affect security outcomes, without having to change
> development culture. Where Agile folk are doing good stuff, the push
> should be to 'translate' this stuff into credit within the applied
> maturity model.
>
> Note that rather than requirements, I mentioned misuse cases (very
> akin to user stories the teams already did).
>
> Rather than architecture, security toolkit reuse occurred and threats
> were identified (did I mention threats in my last email? That might
> have been an omission)
>
> I've found neat use of static analysis to provide assurance cases too.
> Rather than documenting requirements compliant with a policy teams
> have implemented custom rules that produce assurance that a security
> toolkit was applied thoroughly across an application (in their Hudson
> build). When auditors come around and said, "Hey, our policies say you
> need requirements against XSS" the team was able to respond,
>
> "We don't do that. But! we did identify a need to protect against that
> and our nightly builds' results show our commitment to that hygiene."
> Auditors needed to be trained to recognize that behavior as OK. This
> seems to gel with your experience as well.
>
> The second net is this: organizations in which Agile and
> process/audit/MM's coexist need to recognize that:
>
> * Securing agile dev won't require special activities outside their MM's
canon
> * Adjusting inputs/outputs/activities for agile teams may be more natural
> ?* Code review --> Peer review
> * Giving teams credit for practiced MM-compliant activities will be
> easier than mandating a single specific activity from each waterfall
> process phase
>
> Remember, SAMM doesn't prescribe particular activity. It presents a
> menu from which organizations can chose a set providing desired
> minimum coverage. ?Likewise, BSIMM observed a variety of activities,
> each of which may or may not be suited to a particular org/culture.
>
> Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> that could be co-opted to be SAMM-agile.
>
> -jOHN
>
>> ----------------------------------------------------------------------
>>
>> Date: Tue, 02 Nov 2010 10:49:17 -0600
>> From: JIM BIRD
>>
>> The problem from a software development perspective is that
>> maturity models and process frameworks are part of what Agile teams are
>> reacting against: ?process for process sake?, high-ceremony,
>> documentation-heavy, more time needed upfront, more time needed
downstream. A
>> good Agile or Lean software team is going to want to resist anything that
doesn?t
>> directly contribute to delivering working code to a customer quickly.
This is
>> taken to extremes with the latest fad of Continuous Deployment where
developers run through their code through some automated tests and deploy
straight to
>> production so that they can get immediate feedback. Suicide from a
security (and
>> reliability) point of view of course, but it shows how extreme some teams
are
>> taking these ideas.
>>
>> I don?t know too many Agile teams, even more responsible
>> ones who don?t buy into Continuous Deployment, who are going to
understand the
>> point of a maturity model, or try to use one, even one as relatively
simple as
>> SAMM. And BSIMM is even more heavyweight, reasonably so since it is
targeted to
>> enterprises ? but at over 100 measurement areas it is too much for an
Agile
>> team to think about or try to work with. Take SAMM, which I am more
familiar
>> with. There is a lot of emphasis on governance, and strategy and policies
and
>> metrics and audits. This is not what an Agile organization is about.
>>
>> Even requirements and architecture are a hard sell ? as you
>> pointed out James, assessing is about looking at documents, these models
>> emphasize documents, and an Agile team is going to create only what
>> documentation is needed to get the job done. What matters to them is
working
>> closely with the customer and delivering code that meets the customer's
needs. With an Agile team, you need other ways than looking at
>> documentation to find evidence that the work is being done. So rather
than
>> asking whether something is documented or formally reviewed, it might be
better
>> to be able to ask the team questions that probe and verify their
understanding of
>> problems. For example in SAMM it asks under Design Review ?Do project
teams
>> document the attack perimeter of software designs?? Now, what is this
question
>> really asking? It?s not about whether something got written down ?
writing it
>> down doesn?t mean it gets dealt with. It?s asking whether the team
understands
>> the attack surface of what they are building and where the risk areas are
and
>> how they are going to handle them. So changing questions like this,
questions that
>> are clearly documentation check-marks, to get to the point behind the
document might
>> help.
>>
>> Adapting the maturity models to Agile is tough in other
>> cases because of the speed at which Agile teams move, the speed at which
code
>> is delivered. Look at something simple like pen testing. In SAMM it asks
if pen
>> testing is done prior to release. Well, if you are releasing every couple
of
>> weeks (or every day or even x times a day for some teams), what does this
mean?
>>
>> It might make sense to come up with a compromise, in the
>> same way that Microsoft has tried to adapt the SDL to come up with
SDL-Agile. To
>> identify the core practices that Agile teams should focus on, and
recognize
>> that there needs to be / should be some foundational practices and some
practices
>> that should be wrapped into sprints. In my experience managing small
software
>> teams, it makes sense to start with coding ? it?s all about the code. So
for
>> example:
>>
>> -?????????
>> Education: people who write software like to get
>> training, as long as it is good training. So training on software
security
>> awareness and defensive programming is an easy sell. The team needs to
>> understand software security first. Everybody. Including, and especially
as Adrian
>> Lane pointed out at OWASP AppSec this year, the Product Manager/Product
Owner.
>>
>> -?????????
>> Code reviews and static analysis: a responsible
>> Agile team cares about the quality of the code. So making sure that
security
>> checks are included in code reviews / pair programming makes sense (after
>> people have been trained so that they know what to look for). And any
>> responsible team is going to be following Continuous Integration. Adding
static
>> analysis to CI is relatively straightforward if you do it from the start.
>> Harder of course if you already have a lot of code in place. But the
tools will
>> help.
>>
>> This is only a start of course: SDL-Agile is a good model to
>> reference, although a lot of teams, even teams that try hard, will fall
short
>> in key areas like threat modeling because of the costs.
>>
>> But I?m afraid that at some point a maturity model doesn?t fit.
>> Helping Agile organizations to get to level 1, to basic good practices
and
>> responsible awareness should be the goal. From there they should continue
to
>> improve themselves through the inspect-and-adapt cycle, with help from
security
>> experts as required. Asking Agile organizations to assess themselves
against
>> some model and move further up some ladder is essentially meaningless.
It?s
>> against how they work and the way that they think. It?s going back 20
years to
>> SEI CMM and CMMI maturity ladders that these people have already
explicitly rejected.
>> They?ve already found a different way that works better for them. It?s up
to
>> the security community to accept that and find ways to support it.
>>
>> Jim Bird
>>
>> ----- Original Message -----
>> From: James McGovern <JMcGovern at virtusa.com>
>> Date: Monday, November 1, 2010 7:55 am
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>>
>>> Many maturity models penalize Agile approaches to software development
>>> since the focus isn't on creation of comprehensive documentation
>>> upfront. Is there merit in providing "audit" guidance for those
>>> who are
>>> leveraging Agile methods? How do we encourage folks to think about
>>> maturity in an iterative way and not interpret SAMM as being more
>>> waterfall-oriented?
>>>
>>> ?
>>>
>>> James McGovern
>>> Insurance SBU
>>>
>>> Virtusa Corporation
>>>
>>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>>
>>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>>> 688 2890?
>>>
>>> ? <http://www.virtusa.com/>???
>>> <http://www.virtusa.com/blog/>??
>>> <https://twitter.com/VirtusaCorp>??
>>> <http://www.linkedin.com/companies/virtusa>??
>>> <http://www.facebook.com/VirtusaCorp>
>>>
>>> ?
>>>
>>>
>>> Virtusa was recently ranked and featured in 2010 Global Services
>>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>>> among others.
>>>
>>> -----------------------------------------------------------------
>>> ----------------------------
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
>
> Virtusa was recently ranked and featured in 2010 Global Services 100,
IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast
500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
>
----------------------------------------------------------------------------
-----------------
>
> This message, including any attachments, contains confidential information
intended for a specific individual and purpose, and is intended for the
addressee only. Any unauthorized disclosure, use, dissemination, copying, or
distribution of this message or any of its attachments or the information
contained in this e-mail, or the taking of any action based on it, is
strictly prohibited. If you are not the intended recipient, please notify
the sender immediately by return e-mail and delete this message.


------------------------------

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm


End of SAMM Digest, Vol 20, Issue 7
***********************************

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------

From JMcGovern at virtusa.com  Wed Nov  3 14:21:39 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Wed, 3 Nov 2010 14:21:39 -0400
Subject: [SAMM] Agile Software Development
In-Reply-To: <fba0258a6f1d.4cd11f3e@shaw.ca>
References: <AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6@mail.gmail.com>
	<fba0258a6f1d.4cd11f3e@shaw.ca>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE3B5@ws-mailsvr.Virtusa.com>

I like the notion of Agile Protection Poker as a substitute/replacement
for other artifacts and feel that it would be good of us to figure out
how to incorporate. Other recommendations include:

 

-          Misuse Stories

-          Helping auditors to understand that their notion of a risk
register may align with the agile concept of technical debt. Maybe
auditors can somehow slightly morph the notion of burndown to fit their
needs

-          Helping developers get credit for building test harnesses.
Even though defects remain, if you are attacked, having this in place is
actually a positive.

 

I wouldn't be a fan of having a SAMM-lite since the challenge described
is less about the ability for Agile teams to step up and more about the
ability for auditors to understand Agile approaches in this context.
Lighter audit criteria with all the levels of maturity could be both
good and bad.

 

James McGovern
Insurance SBU 

Virtusa Corporation

100 Northfield Drive, Suite 305 | Windsor, CT | 06095

Phone:  860 688 9900 Ext:  1037 | Facsimile:  860 688 2890  

  <http://www.virtusa.com/>    <http://www.virtusa.com/blog/>   
<https://twitter.com/VirtusaCorp>   
<http://www.linkedin.com/companies/virtusa>   
<http://www.facebook.com/VirtusaCorp> 

 

From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of JIM BIRD
Sent: Wednesday, November 03, 2010 10:37 AM
To: Software Assurance Maturity Model (SAMM)
Subject: Re: [SAMM] Agile Software Development

 

John,

Cool. I like your approach. As a manager of a software development
organization that needs to be both secure and agile, I appreciate this
kind of fair minded thinking and pragmatism. A couple of points:

1. We need more ways to help software teams build more secure software
without having to use the compliance/audit/governance stick. There are
lots of teams who are building software that needs to be more secure but
aren't subject to the kind of governance or audit requirements. Those
teams aren't going to understand a maturity model or use one, but they
still need to be helped somehow.

2. For those teams who are under the thumb of governance and audit, the
assessor's perspective will be critical here. For example, I thought
your example of using static analysis for XSS compliance was cool, and
it makes sense from an Agile perspective: if I can capture requirements
in automated tests (or something equivalent), this is a good thing.
James' comments show that not everybody will agree - and that's fair
too. If we try to build too much room in the assessment model, then as a
software developer I believe I have been responsible and I'm happily
going doing what I think is good work. And then an assessor comes by and
slams me. That would be sad. 

So maybe a SAMM lite / SAMM Agile is needed. What about BSIMM - will
there be a BSIMM-lite?

----- Original Message -----
From: John Steven <John.Steven at owasp.org>
Date: Wednesday, November 3, 2010 8:00 am
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>

> James,
> 
> I agree with your points below. Again, my point is only that it
> doesn't have to be combative/mutually exclusive when you can find
> overlap and opportunity.
> 
> -jOHN
> 
> On Wed, Nov 3, 2010 at 10:34 AM,  <samm-
> request at lists.owasp.org> wrote:
> 
> 
> > ------------------------------
> >
> > Date: Wed, 3 Nov 2010 09:35:12 -0400
> > From: "James McGovern" <JMcGovern at virtusa.com>
> > Subject: Re: [SAMM] Agile Software Development
> > To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>> Message-ID:
> >        <3D0018576183C3499481587FAE0BAAF808BDE349 at ws-
> mailsvr.Virtusa.com>> Content-Type: text/plain;       
> charset="iso-8859-1"
> >
> > 1. Code review not always the same as peer review. When 
> looking at approaches such as XP where a team may be doing pair 
> programming, there is no discrete "event" for an auditor to 
> measure. Likewise, difficult for auditor to understand whether 
> everyone is held to same standard (consistency)
> >
> > 2. Let's keep terminology clean when it comes to Agile and 
> think about the notion of User Stories as a superset or control 
> around enumerated requirements. User Stories can also have a 
> security slant. User Stories are created by users/business 
> customers while artifacts such as threat models tend to be 
> created by IT types. If you look at how most shops operate, the 
> user story is actually more important since it may actually 
> cause the creation of requirements around it which in turn get 
> tested by QA. Threat models while valuable rarely have the same 
> effect or traceability characteristics.
> >
> > 3. Static analysis can only identify issues that are 
> "findable" at coding time. Creating an artifact that late in the 
> lifecycle is actually a suboptimal idea. Higher maturity is 
> created if we can address security in an agile way at whatever 
> feels like an architecture/design review. While this can't be 
> automated, it can be done against a set of prescribed principles 
> such as defense in depth, least privilege, etc.
> >
> > 4. Many of the static analysis tools such as Ounce Labs, 
> Fortify, etc can produce pretty dashboards articulating counts 
> of highs, mediums, lows but doesn't provide the next step that 
> would be truly valuable to an auditor which would be to align 
> the findings with something like the OWASP Risk Rating method. I 
> remember lots of painful conversations where there were 1000s of 
> highs that resulted in low risk in one application where in 
> another, there were 6 mediums and 1 low where it was possible to 
> get your hands on a credit card and some PII data.  Since Pravir 
> works for Fortify, I will let him noodle this statement to see 
> if he believes there is a better way :-)
> >
> > James McGovern
> > Insurance SBU
> > Virtusa Corporation
> > 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> > Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> > ? ??
> >
> > -----Original Message-----
> > From: samm-bounces at lists.owasp.org [mailto:samm-
> bounces at lists.owasp.org] On Behalf Of John Steven
> > Sent: Wednesday, November 03, 2010 8:21 AM
> > To: samm at lists.owasp.org; jimbird at shaw.ca
> > Subject: Re: [SAMM] Agile Software Development
> >
> > Jim,
> >
> > Like James' email, it's hard to disagree with your points. Agile's
> > rows against process/governance are as predictable as in the 
> reverse,> for good reason.
> >
> > The net is this: Agile teams can be opposed towards 
> docs/process but
> > rarely do they have the skills, irreplaceability, and executive
> > support to completely inoculate themselves against all
> > audit/governance.
> >
> > That's why, with the experiences I shared, I tried to keep 
> things in
> > the perspective of "Agile teams got credit for [activity XXX], which
> > they were already doing". In cases where they weren't already
> > conducting the activity (or were doing so without a specific eye
> > towards security), it was painless to add.
> >
> > The object, in my opinion, should be to make small changes to 
> behavior> that dramatically affect security outcomes, without 
> having to change
> > development culture. Where Agile folk are doing good stuff, 
> the push
> > should be to 'translate' this stuff into credit within the applied
> > maturity model.
> >
> > Note that rather than requirements, I mentioned misuse cases (very
> > akin to user stories the teams already did).
> >
> > Rather than architecture, security toolkit reuse occurred and 
> threats> were identified (did I mention threats in my last 
> email? That might
> > have been an omission)
> >
> > I've found neat use of static analysis to provide assurance 
> cases too.
> > Rather than documenting requirements compliant with a policy teams
> > have implemented custom rules that produce assurance that a security
> > toolkit was applied thoroughly across an application (in their 
> Hudson> build). When auditors come around and said, "Hey, our 
> policies say you
> > need requirements against XSS" the team was able to respond,
> >
> > "We don't do that. But! we did identify a need to protect 
> against that
> > and our nightly builds' results show our commitment to that 
> hygiene."> Auditors needed to be trained to recognize that 
> behavior as OK. This
> > seems to gel with your experience as well.
> >
> > The second net is this: organizations in which Agile and
> > process/audit/MM's coexist need to recognize that:
> >
> > * Securing agile dev won't require special activities outside 
> their MM's canon
> > * Adjusting inputs/outputs/activities for agile teams may be 
> more natural
> >  * Code review --> Peer review
> > * Giving teams credit for practiced MM-compliant activities 
> will be
> > easier than mandating a single specific activity from each waterfall
> > process phase
> >
> > Remember, SAMM doesn't prescribe particular activity. It 
> presents a
> > menu from which organizations can chose a set providing desired
> > minimum coverage.  Likewise, BSIMM observed a variety of activities,
> > each of which may or may not be suited to a particular org/culture.
> >
> > Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> > that could be co-opted to be SAMM-agile.
> >
> > -jOHN
> >
> >> --------------------------------------------------------------
> --------
> >>
> >> Date: Tue, 02 Nov 2010 10:49:17 -0600
> >> From: JIM BIRD
> >>
> >> The problem from a software development perspective is that
> >> maturity models and process frameworks are part of what Agile 
> teams are
> >> reacting against: ?process for process sake?, high-ceremony,
> >> documentation-heavy, more time needed upfront, more time 
> needed downstream. A
> >> good Agile or Lean software team is going to want to resist 
> anything that doesn?t
> >> directly contribute to delivering working code to a customer 
> quickly. This is
> >> taken to extremes with the latest fad of Continuous 
> Deployment where developers run through their code through some 
> automated tests and deploy straight to
> >> production so that they can get immediate feedback. Suicide 
> from a security (and
> >> reliability) point of view of course, but it shows how 
> extreme some teams are
> >> taking these ideas.
> >>
> >> I don?t know too many Agile teams, even more responsible
> >> ones who don?t buy into Continuous Deployment, who are going 
> to understand the
> >> point of a maturity model, or try to use one, even one as 
> relatively simple as
> >> SAMM. And BSIMM is even more heavyweight, reasonably so since 
> it is targeted to
> >> enterprises ? but at over 100 measurement areas it is too 
> much for an Agile
> >> team to think about or try to work with. Take SAMM, which I 
> am more familiar
> >> with. There is a lot of emphasis on governance, and strategy 
> and policies and
> >> metrics and audits. This is not what an Agile organization is 
> about.>>
> >> Even requirements and architecture are a hard sell ? as you
> >> pointed out James, assessing is about looking at documents, 
> these models
> >> emphasize documents, and an Agile team is going to create 
> only what
> >> documentation is needed to get the job done. What matters to 
> them is working
> >> closely with the customer and delivering code that meets the 
> customer's needs. With an Agile team, you need other ways than 
> looking at
> >> documentation to find evidence that the work is being done. 
> So rather than
> >> asking whether something is documented or formally reviewed, 
> it might be better
> >> to be able to ask the team questions that probe and verify 
> their understanding of
> >> problems. For example in SAMM it asks under Design Review ?Do 
> project teams
> >> document the attack perimeter of software designs?? Now, what 
> is this question
> >> really asking? It?s not about whether something got written 
> down ? writing it
> >> down doesn?t mean it gets dealt with. It?s asking whether the 
> team understands
> >> the attack surface of what they are building and where the 
> risk areas are and
> >> how they are going to handle them. So changing questions like 
> this, questions that
> >> are clearly documentation check-marks, to get to the point 
> behind the document might
> >> help.
> >>
> >> Adapting the maturity models to Agile is tough in other
> >> cases because of the speed at which Agile teams move, the 
> speed at which code
> >> is delivered. Look at something simple like pen testing. In 
> SAMM it asks if pen
> >> testing is done prior to release. Well, if you are releasing 
> every couple of
> >> weeks (or every day or even x times a day for some teams), 
> what does this mean?
> >>
> >> It might make sense to come up with a compromise, in the
> >> same way that Microsoft has tried to adapt the SDL to come up 
> with SDL-Agile. To
> >> identify the core practices that Agile teams should focus on, 
> and recognize
> >> that there needs to be / should be some foundational 
> practices and some practices
> >> that should be wrapped into sprints. In my experience 
> managing small software
> >> teams, it makes sense to start with coding ? it?s all about 
> the code. So for
> >> example:
> >>
> >> -?????????
> >> Education: people who write software like to get
> >> training, as long as it is good training. So training on 
> software security
> >> awareness and defensive programming is an easy sell. The team 
> needs to
> >> understand software security first. Everybody. Including, and 
> especially as Adrian
> >> Lane pointed out at OWASP AppSec this year, the Product 
> Manager/Product Owner.
> >>
> >> -?????????
> >> Code reviews and static analysis: a responsible
> >> Agile team cares about the quality of the code. So making 
> sure that security
> >> checks are included in code reviews / pair programming makes 
> sense (after
> >> people have been trained so that they know what to look for). 
> And any
> >> responsible team is going to be following Continuous 
> Integration. Adding static
> >> analysis to CI is relatively straightforward if you do it 
> from the start.
> >> Harder of course if you already have a lot of code in place. 
> But the tools will
> >> help.
> >>
> >> This is only a start of course: SDL-Agile is a good model to
> >> reference, although a lot of teams, even teams that try hard, 
> will fall short
> >> in key areas like threat modeling because of the costs.
> >>
> >> But I?m afraid that at some point a maturity model doesn?t fit.
> >> Helping Agile organizations to get to level 1, to basic good 
> practices and
> >> responsible awareness should be the goal. From there they 
> should continue to
> >> improve themselves through the inspect-and-adapt cycle, with 
> help from security
> >> experts as required. Asking Agile organizations to assess 
> themselves against
> >> some model and move further up some ladder is essentially 
> meaningless. It?s
> >> against how they work and the way that they think. It?s going 
> back 20 years to
> >> SEI CMM and CMMI maturity ladders that these people have 
> already explicitly rejected.
> >> They?ve already found a different way that works better for 
> them. It?s up to
> >> the security community to accept that and find ways to 
> support it.
> >>
> >> Jim Bird
> >>
> >> ----- Original Message -----
> >> From: James McGovern <JMcGovern at virtusa.com>
> >> Date: Monday, November 1, 2010 7:55 am
> >> Subject: [SAMM] Agile Software Development
> >> To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>>>
> >>> Many maturity models penalize Agile approaches to software 
> development>>> since the focus isn't on creation of 
> comprehensive documentation
> >>> upfront. Is there merit in providing "audit" guidance for those
> >>> who are
> >>> leveraging Agile methods? How do we encourage folks to think about
> >>> maturity in an iterative way and not interpret SAMM as being more
> >>> waterfall-oriented?
> >>>
> >>> ?
> >>>
> >>> James McGovern
> >>> Insurance SBU
> >>>
> >>> Virtusa Corporation
> >>>
> >>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> >>>
> >>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
> >>> 688 2890?
> >>>
> >>> ? <http://www.virtusa.com/>???
> >>> <http://www.virtusa.com/blog/>??
> >>> <https://twitter.com/VirtusaCorp>??
> >>> <http://www.linkedin.com/companies/virtusa>??
> >>> <http://www.facebook.com/VirtusaCorp>
> >>>
> >>> ?
> >>>
> >>>
> >>> Virtusa was recently ranked and featured in 2010 Global Services
> >>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
> >>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
> >>> among others.
> >>>
> >>> -------------------------------------------------------------
> ----
> >>> ----------------------------
> > _______________________________________________
> > SAMM mailing list
> > SAMM at lists.owasp.org
> > https://lists.owasp.org/mailman/listinfo/samm
> >
> > Virtusa was recently ranked and featured in 2010 Global 
> Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 
> Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best 
> Employers Survey among others.
> >
> > ---------------------------------------------------------------
> ------------------------------
> >
> > This message, including any attachments, contains confidential 
> information intended for a specific individual and purpose, and 
> is intended for the addressee only. Any unauthorized disclosure, 
> use, dissemination, copying, or distribution of this message or 
> any of its attachments or the information contained in this e-
> mail, or the taking of any action based on it, is strictly 
> prohibited. If you are not the intended recipient, please notify 
> the sender immediately by return e-mail and delete this message.
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
> 


Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0001.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 1397 bytes
Desc: image001.jpg
Url : https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0001.jpe 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 744 bytes
Desc: image002.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0004.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 1211 bytes
Desc: image003.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0005.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 789 bytes
Desc: image004.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0006.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 763 bytes
Desc: image005.gif
Url : https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachment-0007.gif 

From rkfairchild at alumni.ou.edu  Wed Nov  3 15:22:02 2010
From: rkfairchild at alumni.ou.edu (Russ Fairchild)
Date: Wed, 03 Nov 2010 15:22:02 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 9
References: <mailman.14397.1288814534.2290.samm@lists.owasp.org>
Message-ID: <002a01cb7b8c$6582f430$3088dc90$@ou.edu>

Hi James,

Replies in-line

-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 4:02 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 9

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: SAMM Digest, Vol 20, Issue 7 (James McGovern)
   2. Re: Agile Software Development (James McGovern)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 14:14:23 -0400
From: "James McGovern" <JMcGovern at virtusa.com>
Subject: Re: [SAMM] SAMM Digest, Vol 20, Issue 7
To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
Message-ID:
	<3D0018576183C3499481587FAE0BAAF808BDE3B3 at ws-mailsvr.Virtusa.com>
Content-Type: text/plain;	charset="iso-8859-1"

1. If we believe that the someone in the process that provides Software
Security Assurance, do we also believe this individual should be separate
from the development team? PCI seems to think so. Do you know that I tell my
son's to review all of my code before they get to go to Chuck e. Cheeses?
Care to guess how quickly my code gets reviewed? NOTE: The nine year old has
already found uses for WebScarab in changing parms for the games he plays.

RKF :  To your first question, the answer is yes, but the spectrum can be
from informal to very formal depending on where you are in the maturity
model and what your business is.  There are many models for defining each
level, but it usually ends up that the highest level is national security.
Most businesses are several levels below that.

RKF:  As far as the rest of the text, not sure what point you are trying to
make.  But I think the point that should be made is kids are smart and
absorb things like sponges so we should make sure they understand the issue
of security:  not that horrible things can happen (which you and I know can)
but undesirable things may happen so you should protect yourself.

2. We shouldn't assume that the developers even understand business context.
Think about the throw it over the wall model better known as outsourcing.
They are given "instructions" such as put widget X on page Y without any
additional context or participation from above (us US-based enterprisey
types)

RKF:  I think this is an issue set apart from security.  Most organizations
I have worked with, the developers do understand the business context.  To
your point, if it is outsourced to a commodity shop, then yes, business
context is the first order of business before you can begin to address
security.


James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of Russ Fairchild
Sent: Wednesday, November 03, 2010 11:19 AM
To: samm at lists.owasp.org
Subject: Re: [SAMM] SAMM Digest, Vol 20, Issue 7

The word that bothers me in this discussion is the word "auditor."

An auditor can never effectively look at code and determine if it is secure
or not.

An auditor can only look at controls and see if they are effective or not
based upon sampling.

My belief is there needs to be someone in the process that provides Software
Security Assurance (SSA).

They are the control.  And that control needs to be matured into the
organization.

It starts with code review and working with the developers, dynamic code
review and working with the developer, on and on.

Eventually the developer themselves will have infused with them the
knowledge that will help them write more secure code with no productivity
loss.

An auditor can't secure code because they won't understand the business
application.

Understanding the business application will require working with the
developers where both the SSA and learn from each other.

Russ Fairchild


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 12:00 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 7

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: Agile Software Development (John Steven)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 10:00:10 -0400
From: John Steven <John.Steven at owasp.org>
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>
Message-ID:
	<AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

James,

I agree with your points below. Again, my point is only that it
doesn't have to be combative/mutually exclusive when you can find
overlap and opportunity.

-jOHN

On Wed, Nov 3, 2010 at 10:34 AM,  <samm-request at lists.owasp.org> wrote:


> ------------------------------
>
> Date: Wed, 3 Nov 2010 09:35:12 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: Re: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; ? ? ? charset="iso-8859-1"
>
> 1. Code review not always the same as peer review. When looking at
approaches such as XP where a team may be doing pair programming, there is
no discrete "event" for an auditor to measure. Likewise, difficult for
auditor to understand whether everyone is held to same standard
(consistency)
>
> 2. Let's keep terminology clean when it comes to Agile and think about the
notion of User Stories as a superset or control around enumerated
requirements. User Stories can also have a security slant. User Stories are
created by users/business customers while artifacts such as threat models
tend to be created by IT types. If you look at how most shops operate, the
user story is actually more important since it may actually cause the
creation of requirements around it which in turn get tested by QA. Threat
models while valuable rarely have the same effect or traceability
characteristics.
>
> 3. Static analysis can only identify issues that are "findable" at coding
time. Creating an artifact that late in the lifecycle is actually a
suboptimal idea. Higher maturity is created if we can address security in an
agile way at whatever feels like an architecture/design review. While this
can't be automated, it can be done against a set of prescribed principles
such as defense in depth, least privilege, etc.
>
> 4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can
produce pretty dashboards articulating counts of highs, mediums, lows but
doesn't provide the next step that would be truly valuable to an auditor
which would be to align the findings with something like the OWASP Risk
Rating method. I remember lots of painful conversations where there were
1000s of highs that resulted in low risk in one application where in
another, there were 6 mediums and 1 low where it was possible to get your
hands on a credit card and some PII data. ?Since Pravir works for Fortify, I
will let him noodle this statement to see if he believes there is a better
way :-)
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> ? ??
>
******************


From rkfairchild at alumni.ou.edu  Wed Nov  3 15:17:07 2010
From: rkfairchild at alumni.ou.edu (Russ Fairchild)
Date: Wed, 03 Nov 2010 15:17:07 -0400
Subject: [SAMM] SAMM Digest, Vol 20, Issue 9
In-Reply-To: <mailman.14397.1288814534.2290.samm@lists.owasp.org>
References: <mailman.14397.1288814534.2290.samm@lists.owasp.org>
Message-ID: <002201cb7b8b$b5e7a980$21b6fc80$@ou.edu>

Hi James,

Replies in-line

-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 4:02 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 9

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: SAMM Digest, Vol 20, Issue 7 (James McGovern)
   2. Re: Agile Software Development (James McGovern)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 14:14:23 -0400
From: "James McGovern" <JMcGovern at virtusa.com>
Subject: Re: [SAMM] SAMM Digest, Vol 20, Issue 7
To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
Message-ID:
	<3D0018576183C3499481587FAE0BAAF808BDE3B3 at ws-mailsvr.Virtusa.com>
Content-Type: text/plain;	charset="iso-8859-1"

1. If we believe that the someone in the process that provides Software
Security Assurance, do we also believe this individual should be separate
from the development team? PCI seems to think so. Do you know that I tell my
son's to review all of my code before they get to go to Chuck e. Cheeses?
Care to guess how quickly my code gets reviewed? NOTE: The nine year old has
already found uses for WebScarab in changing parms for the games he plays.

RKF :  To your first question, the answer is yes, but the spectrum can be
from informal to very formal depending on where you are in the maturity
model and what your business is.  There are many models for defining each
level, but it usually ends up that the highest level is national security.
Most businesses are several levels below that.

RKF:  As far as the rest of the text, not sure what point you are trying to
make.  But I think the point that should be made is kids are smart and
absorb things like sponges so we should make sure they understand the issue
of security:  not that horrible things can happen (which you and I know can)
but undesirable things may happen so you should protect yourself.

2. We shouldn't assume that the developers even understand business context.
Think about the throw it over the wall model better known as outsourcing.
They are given "instructions" such as put widget X on page Y without any
additional context or participation from above (us US-based enterprisey
types)

RKF:  I think this is an issue set apart from security.  Most organizations
I have worked with, the developers do understand the business context.  To
your point, if it is outsourced to a commodity shop, then yes, business
context is the first order of business before you can begin to address
security.


James McGovern
Insurance SBU 
Virtusa Corporation
100 Northfield Drive, Suite 305 | Windsor, CT | 06095
Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
? ??


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of Russ Fairchild
Sent: Wednesday, November 03, 2010 11:19 AM
To: samm at lists.owasp.org
Subject: Re: [SAMM] SAMM Digest, Vol 20, Issue 7

The word that bothers me in this discussion is the word "auditor."

An auditor can never effectively look at code and determine if it is secure
or not.

An auditor can only look at controls and see if they are effective or not
based upon sampling.

My belief is there needs to be someone in the process that provides Software
Security Assurance (SSA).

They are the control.  And that control needs to be matured into the
organization.

It starts with code review and working with the developers, dynamic code
review and working with the developer, on and on.

Eventually the developer themselves will have infused with them the
knowledge that will help them write more secure code with no productivity
loss.

An auditor can't secure code because they won't understand the business
application.

Understanding the business application will require working with the
developers where both the SSA and learn from each other.

Russ Fairchild


-----Original Message-----
From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org] On
Behalf Of samm-request at lists.owasp.org
Sent: Wednesday, November 03, 2010 12:00 PM
To: samm at lists.owasp.org
Subject: SAMM Digest, Vol 20, Issue 7

Send SAMM mailing list submissions to
	samm at lists.owasp.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://lists.owasp.org/mailman/listinfo/samm
or, via email, send a message with subject or body 'help' to
	samm-request at lists.owasp.org

You can reach the person managing the list at
	samm-owner at lists.owasp.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of SAMM digest..."


Today's Topics:

   1. Re: Agile Software Development (John Steven)


----------------------------------------------------------------------

Message: 1
Date: Wed, 3 Nov 2010 10:00:10 -0400
From: John Steven <John.Steven at owasp.org>
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>
Message-ID:
	<AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

James,

I agree with your points below. Again, my point is only that it
doesn't have to be combative/mutually exclusive when you can find
overlap and opportunity.

-jOHN

On Wed, Nov 3, 2010 at 10:34 AM,  <samm-request at lists.owasp.org> wrote:


> ------------------------------
>
> Date: Wed, 3 Nov 2010 09:35:12 -0400
> From: "James McGovern" <JMcGovern at virtusa.com>
> Subject: Re: [SAMM] Agile Software Development
> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
> Message-ID:
> ? ? ? ?<3D0018576183C3499481587FAE0BAAF808BDE349 at ws-mailsvr.Virtusa.com>
> Content-Type: text/plain; ? ? ? charset="iso-8859-1"
>
> 1. Code review not always the same as peer review. When looking at
approaches such as XP where a team may be doing pair programming, there is
no discrete "event" for an auditor to measure. Likewise, difficult for
auditor to understand whether everyone is held to same standard
(consistency)
>
> 2. Let's keep terminology clean when it comes to Agile and think about the
notion of User Stories as a superset or control around enumerated
requirements. User Stories can also have a security slant. User Stories are
created by users/business customers while artifacts such as threat models
tend to be created by IT types. If you look at how most shops operate, the
user story is actually more important since it may actually cause the
creation of requirements around it which in turn get tested by QA. Threat
models while valuable rarely have the same effect or traceability
characteristics.
>
> 3. Static analysis can only identify issues that are "findable" at coding
time. Creating an artifact that late in the lifecycle is actually a
suboptimal idea. Higher maturity is created if we can address security in an
agile way at whatever feels like an architecture/design review. While this
can't be automated, it can be done against a set of prescribed principles
such as defense in depth, least privilege, etc.
>
> 4. Many of the static analysis tools such as Ounce Labs, Fortify, etc can
produce pretty dashboards articulating counts of highs, mediums, lows but
doesn't provide the next step that would be truly valuable to an auditor
which would be to align the findings with something like the OWASP Risk
Rating method. I remember lots of painful conversations where there were
1000s of highs that resulted in low risk in one application where in
another, there were 6 mediums and 1 low where it was possible to get your
hands on a credit card and some PII data. ?Since Pravir works for Fortify, I
will let him noodle this statement to see if he believes there is a better
way :-)
>
> James McGovern
> Insurance SBU
> Virtusa Corporation
> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> ? ??
>
> -----Original Message-----
> From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of John Steven
> Sent: Wednesday, November 03, 2010 8:21 AM
> To: samm at lists.owasp.org; jimbird at shaw.ca
> Subject: Re: [SAMM] Agile Software Development
>
> Jim,
>
> Like James' email, it's hard to disagree with your points. Agile's
> rows against process/governance are as predictable as in the reverse,
> for good reason.
>
> The net is this: Agile teams can be opposed towards docs/process but
> rarely do they have the skills, irreplaceability, and executive
> support to completely inoculate themselves against all
> audit/governance.
>
> That's why, with the experiences I shared, I tried to keep things in
> the perspective of "Agile teams got credit for [activity XXX], which
> they were already doing". In cases where they weren't already
> conducting the activity (or were doing so without a specific eye
> towards security), it was painless to add.
>
> The object, in my opinion, should be to make small changes to behavior
> that dramatically affect security outcomes, without having to change
> development culture. Where Agile folk are doing good stuff, the push
> should be to 'translate' this stuff into credit within the applied
> maturity model.
>
> Note that rather than requirements, I mentioned misuse cases (very
> akin to user stories the teams already did).
>
> Rather than architecture, security toolkit reuse occurred and threats
> were identified (did I mention threats in my last email? That might
> have been an omission)
>
> I've found neat use of static analysis to provide assurance cases too.
> Rather than documenting requirements compliant with a policy teams
> have implemented custom rules that produce assurance that a security
> toolkit was applied thoroughly across an application (in their Hudson
> build). When auditors come around and said, "Hey, our policies say you
> need requirements against XSS" the team was able to respond,
>
> "We don't do that. But! we did identify a need to protect against that
> and our nightly builds' results show our commitment to that hygiene."
> Auditors needed to be trained to recognize that behavior as OK. This
> seems to gel with your experience as well.
>
> The second net is this: organizations in which Agile and
> process/audit/MM's coexist need to recognize that:
>
> * Securing agile dev won't require special activities outside their MM's
canon
> * Adjusting inputs/outputs/activities for agile teams may be more natural
> ?* Code review --> Peer review
> * Giving teams credit for practiced MM-compliant activities will be
> easier than mandating a single specific activity from each waterfall
> process phase
>
> Remember, SAMM doesn't prescribe particular activity. It presents a
> menu from which organizations can chose a set providing desired
> minimum coverage. ?Likewise, BSIMM observed a variety of activities,
> each of which may or may not be suited to a particular org/culture.
>
> Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> that could be co-opted to be SAMM-agile.
>
> -jOHN
>
>> ----------------------------------------------------------------------
>>
>> Date: Tue, 02 Nov 2010 10:49:17 -0600
>> From: JIM BIRD
>>
>> The problem from a software development perspective is that
>> maturity models and process frameworks are part of what Agile teams are
>> reacting against: ?process for process sake?, high-ceremony,
>> documentation-heavy, more time needed upfront, more time needed
downstream. A
>> good Agile or Lean software team is going to want to resist anything that
doesn?t
>> directly contribute to delivering working code to a customer quickly.
This is
>> taken to extremes with the latest fad of Continuous Deployment where
developers run through their code through some automated tests and deploy
straight to
>> production so that they can get immediate feedback. Suicide from a
security (and
>> reliability) point of view of course, but it shows how extreme some teams
are
>> taking these ideas.
>>
>> I don?t know too many Agile teams, even more responsible
>> ones who don?t buy into Continuous Deployment, who are going to
understand the
>> point of a maturity model, or try to use one, even one as relatively
simple as
>> SAMM. And BSIMM is even more heavyweight, reasonably so since it is
targeted to
>> enterprises ? but at over 100 measurement areas it is too much for an
Agile
>> team to think about or try to work with. Take SAMM, which I am more
familiar
>> with. There is a lot of emphasis on governance, and strategy and policies
and
>> metrics and audits. This is not what an Agile organization is about.
>>
>> Even requirements and architecture are a hard sell ? as you
>> pointed out James, assessing is about looking at documents, these models
>> emphasize documents, and an Agile team is going to create only what
>> documentation is needed to get the job done. What matters to them is
working
>> closely with the customer and delivering code that meets the customer's
needs. With an Agile team, you need other ways than looking at
>> documentation to find evidence that the work is being done. So rather
than
>> asking whether something is documented or formally reviewed, it might be
better
>> to be able to ask the team questions that probe and verify their
understanding of
>> problems. For example in SAMM it asks under Design Review ?Do project
teams
>> document the attack perimeter of software designs?? Now, what is this
question
>> really asking? It?s not about whether something got written down ?
writing it
>> down doesn?t mean it gets dealt with. It?s asking whether the team
understands
>> the attack surface of what they are building and where the risk areas are
and
>> how they are going to handle them. So changing questions like this,
questions that
>> are clearly documentation check-marks, to get to the point behind the
document might
>> help.
>>
>> Adapting the maturity models to Agile is tough in other
>> cases because of the speed at which Agile teams move, the speed at which
code
>> is delivered. Look at something simple like pen testing. In SAMM it asks
if pen
>> testing is done prior to release. Well, if you are releasing every couple
of
>> weeks (or every day or even x times a day for some teams), what does this
mean?
>>
>> It might make sense to come up with a compromise, in the
>> same way that Microsoft has tried to adapt the SDL to come up with
SDL-Agile. To
>> identify the core practices that Agile teams should focus on, and
recognize
>> that there needs to be / should be some foundational practices and some
practices
>> that should be wrapped into sprints. In my experience managing small
software
>> teams, it makes sense to start with coding ? it?s all about the code. So
for
>> example:
>>
>> -?????????
>> Education: people who write software like to get
>> training, as long as it is good training. So training on software
security
>> awareness and defensive programming is an easy sell. The team needs to
>> understand software security first. Everybody. Including, and especially
as Adrian
>> Lane pointed out at OWASP AppSec this year, the Product Manager/Product
Owner.
>>
>> -?????????
>> Code reviews and static analysis: a responsible
>> Agile team cares about the quality of the code. So making sure that
security
>> checks are included in code reviews / pair programming makes sense (after
>> people have been trained so that they know what to look for). And any
>> responsible team is going to be following Continuous Integration. Adding
static
>> analysis to CI is relatively straightforward if you do it from the start.
>> Harder of course if you already have a lot of code in place. But the
tools will
>> help.
>>
>> This is only a start of course: SDL-Agile is a good model to
>> reference, although a lot of teams, even teams that try hard, will fall
short
>> in key areas like threat modeling because of the costs.
>>
>> But I?m afraid that at some point a maturity model doesn?t fit.
>> Helping Agile organizations to get to level 1, to basic good practices
and
>> responsible awareness should be the goal. From there they should continue
to
>> improve themselves through the inspect-and-adapt cycle, with help from
security
>> experts as required. Asking Agile organizations to assess themselves
against
>> some model and move further up some ladder is essentially meaningless.
It?s
>> against how they work and the way that they think. It?s going back 20
years to
>> SEI CMM and CMMI maturity ladders that these people have already
explicitly rejected.
>> They?ve already found a different way that works better for them. It?s up
to
>> the security community to accept that and find ways to support it.
>>
>> Jim Bird
>>
>> ----- Original Message -----
>> From: James McGovern <JMcGovern at virtusa.com>
>> Date: Monday, November 1, 2010 7:55 am
>> Subject: [SAMM] Agile Software Development
>> To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
>>
>>> Many maturity models penalize Agile approaches to software development
>>> since the focus isn't on creation of comprehensive documentation
>>> upfront. Is there merit in providing "audit" guidance for those
>>> who are
>>> leveraging Agile methods? How do we encourage folks to think about
>>> maturity in an iterative way and not interpret SAMM as being more
>>> waterfall-oriented?
>>>
>>> ?
>>>
>>> James McGovern
>>> Insurance SBU
>>>
>>> Virtusa Corporation
>>>
>>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
>>>
>>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
>>> 688 2890?
>>>
>>> ? <http://www.virtusa.com/>???
>>> <http://www.virtusa.com/blog/>??
>>> <https://twitter.com/VirtusaCorp>??
>>> <http://www.linkedin.com/companies/virtusa>??
>>> <http://www.facebook.com/VirtusaCorp>
>>>
>>> ?
>>>
>>>
>>> Virtusa was recently ranked and featured in 2010 Global Services
>>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
>>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
>>> among others.
>>>
>>> -----------------------------------------------------------------
>>> ----------------------------
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
>
> Virtusa was recently ranked and featured in 2010 Global Services 100,
IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast
500 and 2009 Dataquest-IDC Best Employers Survey among others.
>
>
----------------------------------------------------------------------------
-----------------
>
> This message, including any attachments, contains confidential information
intended for a specific individual and purpose, and is intended for the
addressee only. Any unauthorized disclosure, use, dissemination, copying, or
distribution of this message or any of its attachments or the information
contained in this e-mail, or the taking of any action based on it, is
strictly prohibited. If you are not the intended recipient, please notify
the sender immediately by return e-mail and delete this message.


------------------------------

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm


End of SAMM Digest, Vol 20, Issue 7
***********************************

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's
2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and
2009 Dataquest-IDC Best Employers Survey among others.

----------------------------------------------------------------------------
-----------------

This message, including any attachments, contains confidential information
intended for a specific individual and purpose, and is intended for the
addressee only. Any unauthorized disclosure, use, dissemination, copying, or
distribution of this message or any of its attachments or the information
contained in this e-mail, or the taking of any action based on it, is
strictly prohibited. If you are not the intended recipient, please notify
the sender immediately by return e-mail and delete this message.

----------------------------------------------------------------------------
-----------------


------------------------------

Message: 2
Date: Wed, 3 Nov 2010 14:21:39 -0400
From: "James McGovern" <JMcGovern at virtusa.com>
Subject: Re: [SAMM] Agile Software Development
To: "Software Assurance Maturity Model (SAMM)" <samm at lists.owasp.org>
Message-ID:
	<3D0018576183C3499481587FAE0BAAF808BDE3B5 at ws-mailsvr.Virtusa.com>
Content-Type: text/plain; charset="us-ascii"

I like the notion of Agile Protection Poker as a substitute/replacement
for other artifacts and feel that it would be good of us to figure out
how to incorporate. Other recommendations include:

 

-          Misuse Stories

-          Helping auditors to understand that their notion of a risk
register may align with the agile concept of technical debt. Maybe
auditors can somehow slightly morph the notion of burndown to fit their
needs

-          Helping developers get credit for building test harnesses.
Even though defects remain, if you are attacked, having this in place is
actually a positive.

 

I wouldn't be a fan of having a SAMM-lite since the challenge described
is less about the ability for Agile teams to step up and more about the
ability for auditors to understand Agile approaches in this context.
Lighter audit criteria with all the levels of maturity could be both
good and bad.

 

James McGovern
Insurance SBU 

Virtusa Corporation

100 Northfield Drive, Suite 305 | Windsor, CT | 06095

Phone:  860 688 9900 Ext:  1037 | Facsimile:  860 688 2890  

  <http://www.virtusa.com/>    <http://www.virtusa.com/blog/>   
<https://twitter.com/VirtusaCorp>   
<http://www.linkedin.com/companies/virtusa>   
<http://www.facebook.com/VirtusaCorp> 

 

From: samm-bounces at lists.owasp.org [mailto:samm-bounces at lists.owasp.org]
On Behalf Of JIM BIRD
Sent: Wednesday, November 03, 2010 10:37 AM
To: Software Assurance Maturity Model (SAMM)
Subject: Re: [SAMM] Agile Software Development

 

John,

Cool. I like your approach. As a manager of a software development
organization that needs to be both secure and agile, I appreciate this
kind of fair minded thinking and pragmatism. A couple of points:

1. We need more ways to help software teams build more secure software
without having to use the compliance/audit/governance stick. There are
lots of teams who are building software that needs to be more secure but
aren't subject to the kind of governance or audit requirements. Those
teams aren't going to understand a maturity model or use one, but they
still need to be helped somehow.

2. For those teams who are under the thumb of governance and audit, the
assessor's perspective will be critical here. For example, I thought
your example of using static analysis for XSS compliance was cool, and
it makes sense from an Agile perspective: if I can capture requirements
in automated tests (or something equivalent), this is a good thing.
James' comments show that not everybody will agree - and that's fair
too. If we try to build too much room in the assessment model, then as a
software developer I believe I have been responsible and I'm happily
going doing what I think is good work. And then an assessor comes by and
slams me. That would be sad. 

So maybe a SAMM lite / SAMM Agile is needed. What about BSIMM - will
there be a BSIMM-lite?

----- Original Message -----
From: John Steven <John.Steven at owasp.org>
Date: Wednesday, November 3, 2010 8:00 am
Subject: Re: [SAMM] Agile Software Development
To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>

> James,
> 
> I agree with your points below. Again, my point is only that it
> doesn't have to be combative/mutually exclusive when you can find
> overlap and opportunity.
> 
> -jOHN
> 
> On Wed, Nov 3, 2010 at 10:34 AM,  <samm-
> request at lists.owasp.org> wrote:
> 
> 
> > ------------------------------
> >
> > Date: Wed, 3 Nov 2010 09:35:12 -0400
> > From: "James McGovern" <JMcGovern at virtusa.com>
> > Subject: Re: [SAMM] Agile Software Development
> > To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>> Message-ID:
> >        <3D0018576183C3499481587FAE0BAAF808BDE349 at ws-
> mailsvr.Virtusa.com>> Content-Type: text/plain;       
> charset="iso-8859-1"
> >
> > 1. Code review not always the same as peer review. When 
> looking at approaches such as XP where a team may be doing pair 
> programming, there is no discrete "event" for an auditor to 
> measure. Likewise, difficult for auditor to understand whether 
> everyone is held to same standard (consistency)
> >
> > 2. Let's keep terminology clean when it comes to Agile and 
> think about the notion of User Stories as a superset or control 
> around enumerated requirements. User Stories can also have a 
> security slant. User Stories are created by users/business 
> customers while artifacts such as threat models tend to be 
> created by IT types. If you look at how most shops operate, the 
> user story is actually more important since it may actually 
> cause the creation of requirements around it which in turn get 
> tested by QA. Threat models while valuable rarely have the same 
> effect or traceability characteristics.
> >
> > 3. Static analysis can only identify issues that are 
> "findable" at coding time. Creating an artifact that late in the 
> lifecycle is actually a suboptimal idea. Higher maturity is 
> created if we can address security in an agile way at whatever 
> feels like an architecture/design review. While this can't be 
> automated, it can be done against a set of prescribed principles 
> such as defense in depth, least privilege, etc.
> >
> > 4. Many of the static analysis tools such as Ounce Labs, 
> Fortify, etc can produce pretty dashboards articulating counts 
> of highs, mediums, lows but doesn't provide the next step that 
> would be truly valuable to an auditor which would be to align 
> the findings with something like the OWASP Risk Rating method. I 
> remember lots of painful conversations where there were 1000s of 
> highs that resulted in low risk in one application where in 
> another, there were 6 mediums and 1 low where it was possible to 
> get your hands on a credit card and some PII data.  Since Pravir 
> works for Fortify, I will let him noodle this statement to see 
> if he believes there is a better way :-)
> >
> > James McGovern
> > Insurance SBU
> > Virtusa Corporation
> > 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> > Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> > ? ??
> >
> > -----Original Message-----
> > From: samm-bounces at lists.owasp.org [mailto:samm-
> bounces at lists.owasp.org] On Behalf Of John Steven
> > Sent: Wednesday, November 03, 2010 8:21 AM
> > To: samm at lists.owasp.org; jimbird at shaw.ca
> > Subject: Re: [SAMM] Agile Software Development
> >
> > Jim,
> >
> > Like James' email, it's hard to disagree with your points. Agile's
> > rows against process/governance are as predictable as in the 
> reverse,> for good reason.
> >
> > The net is this: Agile teams can be opposed towards 
> docs/process but
> > rarely do they have the skills, irreplaceability, and executive
> > support to completely inoculate themselves against all
> > audit/governance.
> >
> > That's why, with the experiences I shared, I tried to keep 
> things in
> > the perspective of "Agile teams got credit for [activity XXX], which
> > they were already doing". In cases where they weren't already
> > conducting the activity (or were doing so without a specific eye
> > towards security), it was painless to add.
> >
> > The object, in my opinion, should be to make small changes to 
> behavior> that dramatically affect security outcomes, without 
> having to change
> > development culture. Where Agile folk are doing good stuff, 
> the push
> > should be to 'translate' this stuff into credit within the applied
> > maturity model.
> >
> > Note that rather than requirements, I mentioned misuse cases (very
> > akin to user stories the teams already did).
> >
> > Rather than architecture, security toolkit reuse occurred and 
> threats> were identified (did I mention threats in my last 
> email? That might
> > have been an omission)
> >
> > I've found neat use of static analysis to provide assurance 
> cases too.
> > Rather than documenting requirements compliant with a policy teams
> > have implemented custom rules that produce assurance that a security
> > toolkit was applied thoroughly across an application (in their 
> Hudson> build). When auditors come around and said, "Hey, our 
> policies say you
> > need requirements against XSS" the team was able to respond,
> >
> > "We don't do that. But! we did identify a need to protect 
> against that
> > and our nightly builds' results show our commitment to that 
> hygiene."> Auditors needed to be trained to recognize that 
> behavior as OK. This
> > seems to gel with your experience as well.
> >
> > The second net is this: organizations in which Agile and
> > process/audit/MM's coexist need to recognize that:
> >
> > * Securing agile dev won't require special activities outside 
> their MM's canon
> > * Adjusting inputs/outputs/activities for agile teams may be 
> more natural
> >  * Code review --> Peer review
> > * Giving teams credit for practiced MM-compliant activities 
> will be
> > easier than mandating a single specific activity from each waterfall
> > process phase
> >
> > Remember, SAMM doesn't prescribe particular activity. It 
> presents a
> > menu from which organizations can chose a set providing desired
> > minimum coverage.  Likewise, BSIMM observed a variety of activities,
> > each of which may or may not be suited to a particular org/culture.
> >
> > Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> > that could be co-opted to be SAMM-agile.
> >
> > -jOHN
> >
> >> --------------------------------------------------------------
> --------
> >>
> >> Date: Tue, 02 Nov 2010 10:49:17 -0600
> >> From: JIM BIRD
> >>
> >> The problem from a software development perspective is that
> >> maturity models and process frameworks are part of what Agile 
> teams are
> >> reacting against: ?process for process sake?, high-ceremony,
> >> documentation-heavy, more time needed upfront, more time 
> needed downstream. A
> >> good Agile or Lean software team is going to want to resist 
> anything that doesn?t
> >> directly contribute to delivering working code to a customer 
> quickly. This is
> >> taken to extremes with the latest fad of Continuous 
> Deployment where developers run through their code through some 
> automated tests and deploy straight to
> >> production so that they can get immediate feedback. Suicide 
> from a security (and
> >> reliability) point of view of course, but it shows how 
> extreme some teams are
> >> taking these ideas.
> >>
> >> I don?t know too many Agile teams, even more responsible
> >> ones who don?t buy into Continuous Deployment, who are going 
> to understand the
> >> point of a maturity model, or try to use one, even one as 
> relatively simple as
> >> SAMM. And BSIMM is even more heavyweight, reasonably so since 
> it is targeted to
> >> enterprises ? but at over 100 measurement areas it is too 
> much for an Agile
> >> team to think about or try to work with. Take SAMM, which I 
> am more familiar
> >> with. There is a lot of emphasis on governance, and strategy 
> and policies and
> >> metrics and audits. This is not what an Agile organization is 
> about.>>
> >> Even requirements and architecture are a hard sell ? as you
> >> pointed out James, assessing is about looking at documents, 
> these models
> >> emphasize documents, and an Agile team is going to create 
> only what
> >> documentation is needed to get the job done. What matters to 
> them is working
> >> closely with the customer and delivering code that meets the 
> customer's needs. With an Agile team, you need other ways than 
> looking at
> >> documentation to find evidence that the work is being done. 
> So rather than
> >> asking whether something is documented or formally reviewed, 
> it might be better
> >> to be able to ask the team questions that probe and verify 
> their understanding of
> >> problems. For example in SAMM it asks under Design Review ?Do 
> project teams
> >> document the attack perimeter of software designs?? Now, what 
> is this question
> >> really asking? It?s not about whether something got written 
> down ? writing it
> >> down doesn?t mean it gets dealt with. It?s asking whether the 
> team understands
> >> the attack surface of what they are building and where the 
> risk areas are and
> >> how they are going to handle them. So changing questions like 
> this, questions that
> >> are clearly documentation check-marks, to get to the point 
> behind the document might
> >> help.
> >>
> >> Adapting the maturity models to Agile is tough in other
> >> cases because of the speed at which Agile teams move, the 
> speed at which code
> >> is delivered. Look at something simple like pen testing. In 
> SAMM it asks if pen
> >> testing is done prior to release. Well, if you are releasing 
> every couple of
> >> weeks (or every day or even x times a day for some teams), 
> what does this mean?
> >>
> >> It might make sense to come up with a compromise, in the
> >> same way that Microsoft has tried to adapt the SDL to come up 
> with SDL-Agile. To
> >> identify the core practices that Agile teams should focus on, 
> and recognize
> >> that there needs to be / should be some foundational 
> practices and some practices
> >> that should be wrapped into sprints. In my experience 
> managing small software
> >> teams, it makes sense to start with coding ? it?s all about 
> the code. So for
> >> example:
> >>
> >> -?????????
> >> Education: people who write software like to get
> >> training, as long as it is good training. So training on 
> software security
> >> awareness and defensive programming is an easy sell. The team 
> needs to
> >> understand software security first. Everybody. Including, and 
> especially as Adrian
> >> Lane pointed out at OWASP AppSec this year, the Product 
> Manager/Product Owner.
> >>
> >> -?????????
> >> Code reviews and static analysis: a responsible
> >> Agile team cares about the quality of the code. So making 
> sure that security
> >> checks are included in code reviews / pair programming makes 
> sense (after
> >> people have been trained so that they know what to look for). 
> And any
> >> responsible team is going to be following Continuous 
> Integration. Adding static
> >> analysis to CI is relatively straightforward if you do it 
> from the start.
> >> Harder of course if you already have a lot of code in place. 
> But the tools will
> >> help.
> >>
> >> This is only a start of course: SDL-Agile is a good model to
> >> reference, although a lot of teams, even teams that try hard, 
> will fall short
> >> in key areas like threat modeling because of the costs.
> >>
> >> But I?m afraid that at some point a maturity model doesn?t fit.
> >> Helping Agile organizations to get to level 1, to basic good 
> practices and
> >> responsible awareness should be the goal. From there they 
> should continue to
> >> improve themselves through the inspect-and-adapt cycle, with 
> help from security
> >> experts as required. Asking Agile organizations to assess 
> themselves against
> >> some model and move further up some ladder is essentially 
> meaningless. It?s
> >> against how they work and the way that they think. It?s going 
> back 20 years to
> >> SEI CMM and CMMI maturity ladders that these people have 
> already explicitly rejected.
> >> They?ve already found a different way that works better for 
> them. It?s up to
> >> the security community to accept that and find ways to 
> support it.
> >>
> >> Jim Bird
> >>
> >> ----- Original Message -----
> >> From: James McGovern <JMcGovern at virtusa.com>
> >> Date: Monday, November 1, 2010 7:55 am
> >> Subject: [SAMM] Agile Software Development
> >> To: "Software Assurance Maturity Model (SAMM)" 
> <samm at lists.owasp.org>>>
> >>> Many maturity models penalize Agile approaches to software 
> development>>> since the focus isn't on creation of 
> comprehensive documentation
> >>> upfront. Is there merit in providing "audit" guidance for those
> >>> who are
> >>> leveraging Agile methods? How do we encourage folks to think about
> >>> maturity in an iterative way and not interpret SAMM as being more
> >>> waterfall-oriented?
> >>>
> >>> ?
> >>>
> >>> James McGovern
> >>> Insurance SBU
> >>>
> >>> Virtusa Corporation
> >>>
> >>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> >>>
> >>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
> >>> 688 2890?
> >>>
> >>> ? <http://www.virtusa.com/>???
> >>> <http://www.virtusa.com/blog/>??
> >>> <https://twitter.com/VirtusaCorp>??
> >>> <http://www.linkedin.com/companies/virtusa>??
> >>> <http://www.facebook.com/VirtusaCorp>
> >>>
> >>> ?
> >>>
> >>>
> >>> Virtusa was recently ranked and featured in 2010 Global Services
> >>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
> >>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
> >>> among others.
> >>>
> >>> -------------------------------------------------------------
> ----
> >>> ----------------------------
> > _______________________________________________
> > SAMM mailing list
> > SAMM at lists.owasp.org
> > https://lists.owasp.org/mailman/listinfo/samm
> >
> > Virtusa was recently ranked and featured in 2010 Global 
> Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 
> Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best 
> Employers Survey among others.
> >
> > ---------------------------------------------------------------
> ------------------------------
> >
> > This message, including any attachments, contains confidential 
> information intended for a specific individual and purpose, and 
> is intended for the addressee only. Any unauthorized disclosure, 
> use, dissemination, copying, or distribution of this message or 
> any of its attachments or the information contained in this e-
> mail, or the taking of any action based on it, is strictly 
> prohibited. If you are not the intended recipient, please notify 
> the sender immediately by return e-mail and delete this message.
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm
> 


Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's
2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and
2009 Dataquest-IDC Best Employers Survey among others.

----------------------------------------------------------------------------
-----------------

This message, including any attachments, contains confidential information
intended for a specific individual and purpose, and is intended for the
addressee only. Any unauthorized disclosure, use, dissemination, copying, or
distribution of this message or any of its attachments or the information
contained in this e-mail, or the taking of any action based on it, is
strictly prohibited. If you are not the intended recipient, please notify
the sender immediately by return e-mail and delete this message.

----------------------------------------------------------------------------
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL:
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent.html 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 1397 bytes
Desc: image001.jpg
Url :
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent.jpe 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 744 bytes
Desc: image002.gif
Url :
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 1211 bytes
Desc: image003.gif
Url :
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent-0001.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 789 bytes
Desc: image004.gif
Url :
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent-0002.gif 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 763 bytes
Desc: image005.gif
Url :
https://lists.owasp.org/pipermail/samm/attachments/20101103/db551d26/attachm
ent-0003.gif 

------------------------------

_______________________________________________
SAMM mailing list
SAMM at lists.owasp.org
https://lists.owasp.org/mailman/listinfo/samm


End of SAMM Digest, Vol 20, Issue 9
***********************************


From JMcGovern at virtusa.com  Wed Nov  3 16:31:04 2010
From: JMcGovern at virtusa.com (James McGovern)
Date: Wed, 3 Nov 2010 16:31:04 -0400
Subject: [SAMM] Agile Software Development
In-Reply-To: <002201cb7b8b$b5e7a980$21b6fc80$@ou.edu>
References: <mailman.14397.1288814534.2290.samm@lists.owasp.org>
	<002201cb7b8b$b5e7a980$21b6fc80$@ou.edu>
Message-ID: <3D0018576183C3499481587FAE0BAAF808BDE3DE@ws-mailsvr.Virtusa.com>

I think the point I was intending to make was to say that an auditor can
observe the event, but still has no ability to understand quality/depth
of review and am asking whether the reviewer should be held to some
standard before the auditor can check the box?

My example of outsourcing can too be applied to Agile environments.
Business context is usually gained during Agile Project Management
approaches such as Scrum, Kanban, Crystal, etc. However, you can do
Agile Software Development without Agile Project Management. For
example, I can do Extreme Programming where we build test cases first
without using any Project Management Lifecycle. Generally speaking,
auditors tend to understand more on how to audit Project Management
oriented processes and not how to audit software development oriented
practices. SDLC is too overloaded a term and may need a little bit of
decomposition in order to help SAMM align with other models.

Now for a more general question, should we figure out a way to refine
the phrase "static analysis"? In the context most OWASP members would
interpret can differ from static analysis as used for quality assurance
purposes. Sometimes security and quality are the same, sometimes they
are different. Providing some form of lens to see the Venn diagram
between these two may be useful?

-----------------
1. If we believe that the someone in the process that provides Software
Security Assurance, do we also believe this individual should be
separate
from the development team? PCI seems to think so. Do you know that I
tell my
son's to review all of my code before they get to go to Chuck e.
Cheeses?
Care to guess how quickly my code gets reviewed? NOTE: The nine year old
has
already found uses for WebScarab in changing parms for the games he
plays.

RKF :  To your first question, the answer is yes, but the spectrum can
be
from informal to very formal depending on where you are in the maturity
model and what your business is.  There are many models for defining
each
level, but it usually ends up that the highest level is national
security.
Most businesses are several levels below that.

RKF:  As far as the rest of the text, not sure what point you are trying
to
make.  But I think the point that should be made is kids are smart and
absorb things like sponges so we should make sure they understand the
issue
of security:  not that horrible things can happen (which you and I know
can)
but undesirable things may happen so you should protect yourself.

2. We shouldn't assume that the developers even understand business
context.
Think about the throw it over the wall model better known as
outsourcing.
They are given "instructions" such as put widget X on page Y without any
additional context or participation from above (us US-based enterprisey
types)

RKF:  I think this is an issue set apart from security.  Most
organizations
I have worked with, the developers do understand the business context.
To
your point, if it is outsourced to a commodity shop, then yes, business
context is the first order of business before you can begin to address
security.

Virtusa was recently ranked and featured in 2010 Global Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey among others.

---------------------------------------------------------------------------------------------

This message, including any attachments, contains confidential information intended for a specific individual and purpose, and is intended for the addressee only. Any unauthorized disclosure, use, dissemination, copying, or distribution of this message or any of its attachments or the information contained in this e-mail, or the taking of any action based on it, is strictly prohibited. If you are not the intended recipient, please notify the sender immediately by return e-mail and delete this message.

---------------------------------------------------------------------------------------------

From jim.manico at owasp.org  Thu Nov  4 03:34:31 2010
From: jim.manico at owasp.org (Jim Manico)
Date: Thu, 04 Nov 2010 13:04:31 +0530
Subject: [SAMM] Agile Software Development
In-Reply-To: <fba0258a6f1d.4cd11f3e@shaw.ca>
References: <AANLkTinYJF9jY4E6DRXf=RyTbWVsdKaE=1LnddCGYVt6@mail.gmail.com>
	<fba0258a6f1d.4cd11f3e@shaw.ca>
Message-ID: <4CD26207.3010501@owasp.org>

 > 2. For those teams who are under the thumb of governance and audit, 
the assessor's perspective will be critical here. For example, I thought 
your example of using static analysis for XSS compliance was cool, and 
it makes sense from an Agile perspective: if I can capture requirements 
in automated tests (or something equivalent), this is a good thing.

If you want to use static analysis and automation to prove that you are 
safe from XSS, that's great from a compliance perspective, but will only 
get you so far if you want to build a secure system. I have several 
clients who have zero tolerance for XSS. We do manual/peer code review 
(and /custom /SAST rules) to ensure that all output are encoded in the 
right context. Especially when you deal with AJAX based systems and want 
to stop DOM-based XSS, DAST/SAST and I dare say even unit testing is 
minimally helpful.

Again, if compliance is what you are chasing, automate away. If a deeply 
secure system is what you are after, you need control-based assessment 
methodologies in addition to automation.

Even better, keep a close on of the trio of emerging XSS defense methods 
(JavaScript sandboxing, Auto-escaping templates, and Content Security 
Policy). I have hope that they will make the world a much safer place.

- Jim



> John,
>
> Cool. I like your approach. As a manager of a software development 
> organization that needs to be both secure and agile, I appreciate this 
> kind of fair minded thinking and pragmatism. A couple of points:
>
> 1. We need more ways to help software teams build more secure software 
> without having to use the compliance/audit/governance stick. There are 
> lots of teams who are building software that needs to be more secure 
> but aren't subject to the kind of governance or audit requirements. 
> Those teams aren't going to understand a maturity model or use one, 
> but they still need to be helped somehow.
>
> 2. For those teams who are under the thumb of governance and audit, 
> the assessor's perspective will be critical here. For example, I 
> thought your example of using static analysis for XSS compliance was 
> cool, and it makes sense from an Agile perspective: if I can capture 
> requirements in automated tests (or something equivalent), this is a 
> good thing. James' comments show that not everybody will agree - and 
> that's fair too. If we try to build too much room in the assessment 
> model, then as a software developer I believe I have been responsible 
> and I'm happily going doing what I think is good work. And then an 
> assessor comes by and slams me. That would be sad.
>
> So maybe a SAMM lite / SAMM Agile is needed. What about BSIMM - will 
> there be a BSIMM-lite?
>
> ----- Original Message -----
> From: John Steven <John.Steven at owasp.org>
> Date: Wednesday, November 3, 2010 8:00 am
> Subject: Re: [SAMM] Agile Software Development
> To: samm at lists.owasp.org, James McGovern <JMcGovern at virtusa.com>
>
> > James,
> >
> > I agree with your points below. Again, my point is only that it
> > doesn't have to be combative/mutually exclusive when you can find
> > overlap and opportunity.
> >
> > -jOHN
> >
> > On Wed, Nov 3, 2010 at 10:34 AM, <samm-
> > request at lists.owasp.org> wrote:
> >
> >
> > > ------------------------------
> > >
> > > Date: Wed, 3 Nov 2010 09:35:12 -0400
> > > From: "James McGovern" <JMcGovern at virtusa.com>
> > > Subject: Re: [SAMM] Agile Software Development
> > > To: "Software Assurance Maturity Model (SAMM)"
> > <samm at lists.owasp.org>> Message-ID:
> > > <3D0018576183C3499481587FAE0BAAF808BDE349 at ws-
> > mailsvr.Virtusa.com>> Content-Type: text/plain;
> > charset="iso-8859-1"
> > >
> > > 1. Code review not always the same as peer review. When
> > looking at approaches such as XP where a team may be doing pair
> > programming, there is no discrete "event" for an auditor to
> > measure. Likewise, difficult for auditor to understand whether
> > everyone is held to same standard (consistency)
> > >
> > > 2. Let's keep terminology clean when it comes to Agile and
> > think about the notion of User Stories as a superset or control
> > around enumerated requirements. User Stories can also have a
> > security slant. User Stories are created by users/business
> > customers while artifacts such as threat models tend to be
> > created by IT types. If you look at how most shops operate, the
> > user story is actually more important since it may actually
> > cause the creation of requirements around it which in turn get
> > tested by QA. Threat models while valuable rarely have the same
> > effect or traceability characteristics.
> > >
> > > 3. Static analysis can only identify issues that are
> > "findable" at coding time. Creating an artifact that late in the
> > lifecycle is actually a suboptimal idea. Higher maturity is
> > created if we can address security in an agile way at whatever
> > feels like an architecture/design review. While this can't be
> > automated, it can be done against a set of prescribed principles
> > such as defense in depth, least privilege, etc.
> > >
> > > 4. Many of the static analysis tools such as Ounce Labs,
> > Fortify, etc can produce pretty dashboards articulating counts
> > of highs, mediums, lows but doesn't provide the next step that
> > would be truly valuable to an auditor which would be to align
> > the findings with something like the OWASP Risk Rating method. I
> > remember lots of painful conversations where there were 1000s of
> > highs that resulted in low risk in one application where in
> > another, there were 6 mediums and 1 low where it was possible to
> > get your hands on a credit card and some PII data.  Since Pravir
> > works for Fortify, I will let him noodle this statement to see
> > if he believes there is a better way :-)
> > >
> > > James McGovern
> > > Insurance SBU
> > > Virtusa Corporation
> > > 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> > > Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860 688 2890 ?
> > > ? ??
> > >
> > > -----Original Message-----
> > > From: samm-bounces at lists.owasp.org [mailto:samm-
> > bounces at lists.owasp.org] On Behalf Of John Steven
> > > Sent: Wednesday, November 03, 2010 8:21 AM
> > > To: samm at lists.owasp.org; jimbird at shaw.ca
> > > Subject: Re: [SAMM] Agile Software Development
> > >
> > > Jim,
> > >
> > > Like James' email, it's hard to disagree with your points. Agile's
> > > rows against process/governance are as predictable as in the
> > reverse,> for good reason.
> > >
> > > The net is this: Agile teams can be opposed towards
> > docs/process but
> > > rarely do they have the skills, irreplaceability, and executive
> > > support to completely inoculate themselves against all
> > > audit/governance.
> > >
> > > That's why, with the experiences I shared, I tried to keep
> > things in
> > > the perspective of "Agile teams got credit for [activity XXX], which
> > > they were already doing". In cases where they weren't already
> > > conducting the activity (or were doing so without a specific eye
> > > towards security), it was painless to add.
> > >
> > > The object, in my opinion, should be to make small changes to
> > behavior> that dramatically affect security outcomes, without
> > having to change
> > > development culture. Where Agile folk are doing good stuff,
> > the push
> > > should be to 'translate' this stuff into credit within the applied
> > > maturity model.
> > >
> > > Note that rather than requirements, I mentioned misuse cases (very
> > > akin to user stories the teams already did).
> > >
> > > Rather than architecture, security toolkit reuse occurred and
> > threats> were identified (did I mention threats in my last
> > email? That might
> > > have been an omission)
> > >
> > > I've found neat use of static analysis to provide assurance
> > cases too.
> > > Rather than documenting requirements compliant with a policy teams
> > > have implemented custom rules that produce assurance that a security
> > > toolkit was applied thoroughly across an application (in their
> > Hudson> build). When auditors come around and said, "Hey, our
> > policies say you
> > > need requirements against XSS" the team was able to respond,
> > >
> > > "We don't do that. But! we did identify a need to protect
> > against that
> > > and our nightly builds' results show our commitment to that
> > hygiene."> Auditors needed to be trained to recognize that
> > behavior as OK. This
> > > seems to gel with your experience as well.
> > >
> > > The second net is this: organizations in which Agile and
> > > process/audit/MM's coexist need to recognize that:
> > >
> > > * Securing agile dev won't require special activities outside
> > their MM's canon
> > > * Adjusting inputs/outputs/activities for agile teams may be
> > more natural
> > >  * Code review --> Peer review
> > > * Giving teams credit for practiced MM-compliant activities
> > will be
> > > easier than mandating a single specific activity from each waterfall
> > > process phase
> > >
> > > Remember, SAMM doesn't prescribe particular activity. It
> > presents a
> > > menu from which organizations can chose a set providing desired
> > > minimum coverage.  Likewise, BSIMM observed a variety of activities,
> > > each of which may or may not be suited to a particular org/culture.
> > >
> > > Jim, wasn't there are push to do a SAMM-lite at some point? Perhaps
> > > that could be co-opted to be SAMM-agile.
> > >
> > > -jOHN
> > >
> > >> --------------------------------------------------------------
> > --------
> > >>
> > >> Date: Tue, 02 Nov 2010 10:49:17 -0600
> > >> From: JIM BIRD
> > >>
> > >> The problem from a software development perspective is that
> > >> maturity models and process frameworks are part of what Agile
> > teams are
> > >> reacting against: ?process for process sake?, high-ceremony,
> > >> documentation-heavy, more time needed upfront, more time
> > needed downstream. A
> > >> good Agile or Lean software team is going to want to resist
> > anything that doesn?t
> > >> directly contribute to delivering working code to a customer
> > quickly. This is
> > >> taken to extremes with the latest fad of Continuous
> > Deployment where developers run through their code through some
> > automated tests and deploy straight to
> > >> production so that they can get immediate feedback. Suicide
> > from a security (and
> > >> reliability) point of view of course, but it shows how
> > extreme some teams are
> > >> taking these ideas.
> > >>
> > >> I don?t know too many Agile teams, even more responsible
> > >> ones who don?t buy into Continuous Deployment, who are going
> > to understand the
> > >> point of a maturity model, or try to use one, even one as
> > relatively simple as
> > >> SAMM. And BSIMM is even more heavyweight, reasonably so since
> > it is targeted to
> > >> enterprises ? but at over 100 measurement areas it is too
> > much for an Agile
> > >> team to think about or try to work with. Take SAMM, which I
> > am more familiar
> > >> with. There is a lot of emphasis on governance, and strategy
> > and policies and
> > >> metrics and audits. This is not what an Agile organization is
> > about.>>
> > >> Even requirements and architecture are a hard sell ? as you
> > >> pointed out James, assessing is about looking at documents,
> > these models
> > >> emphasize documents, and an Agile team is going to create
> > only what
> > >> documentation is needed to get the job done. What matters to
> > them is working
> > >> closely with the customer and delivering code that meets the
> > customer's needs. With an Agile team, you need other ways than
> > looking at
> > >> documentation to find evidence that the work is being done.
> > So rather than
> > >> asking whether something is documented or formally reviewed,
> > it might be better
> > >> to be able to ask the team questions that probe and verify
> > their understanding of
> > >> problems. For example in SAMM it asks under Design Review ?Do
> > project teams
> > >> document the attack perimeter of software designs?? Now, what
> > is this question
> > >> really asking? It?s not about whether something got written
> > down ? writing it
> > >> down doesn?t mean it gets dealt with. It?s asking whether the
> > team understands
> > >> the attack surface of what they are building and where the
> > risk areas are and
> > >> how they are going to handle them. So changing questions like
> > this, questions that
> > >> are clearly documentation check-marks, to get to the point
> > behind the document might
> > >> help.
> > >>
> > >> Adapting the maturity models to Agile is tough in other
> > >> cases because of the speed at which Agile teams move, the
> > speed at which code
> > >> is delivered. Look at something simple like pen testing. In
> > SAMM it asks if pen
> > >> testing is done prior to release. Well, if you are releasing
> > every couple of
> > >> weeks (or every day or even x times a day for some teams),
> > what does this mean?
> > >>
> > >> It might make sense to come up with a compromise, in the
> > >> same way that Microsoft has tried to adapt the SDL to come up
> > with SDL-Agile. To
> > >> identify the core practices that Agile teams should focus on,
> > and recognize
> > >> that there needs to be / should be some foundational
> > practices and some practices
> > >> that should be wrapped into sprints. In my experience
> > managing small software
> > >> teams, it makes sense to start with coding ? it?s all about
> > the code. So for
> > >> example:
> > >>
> > >> -?????????
> > >> Education: people who write software like to get
> > >> training, as long as it is good training. So training on
> > software security
> > >> awareness and defensive programming is an easy sell. The team
> > needs to
> > >> understand software security first. Everybody. Including, and
> > especially as Adrian
> > >> Lane pointed out at OWASP AppSec this year, the Product
> > Manager/Product Owner.
> > >>
> > >> -?????????
> > >> Code reviews and static analysis: a responsible
> > >> Agile team cares about the quality of the code. So making
> > sure that security
> > >> checks are included in code reviews / pair programming makes
> > sense (after
> > >> people have been trained so that they know what to look for).
> > And any
> > >> responsible team is going to be following Continuous
> > Integration. Adding static
> > >> analysis to CI is relatively straightforward if you do it
> > from the start.
> > >> Harder of course if you already have a lot of code in place.
> > But the tools will
> > >> help.
> > >>
> > >> This is only a start of course: SDL-Agile is a good model to
> > >> reference, although a lot of teams, even teams that try hard,
> > will fall short
> > >> in key areas like threat modeling because of the costs.
> > >>
> > >> But I?m afraid that at some point a maturity model doesn?t fit.
> > >> Helping Agile organizations to get to level 1, to basic good
> > practices and
> > >> responsible awareness should be the goal. From there they
> > should continue to
> > >> improve themselves through the inspect-and-adapt cycle, with
> > help from security
> > >> experts as required. Asking Agile organizations to assess
> > themselves against
> > >> some model and move further up some ladder is essentially
> > meaningless. It?s
> > >> against how they work and the way that they think. It?s going
> > back 20 years to
> > >> SEI CMM and CMMI maturity ladders that these people have
> > already explicitly rejected.
> > >> They?ve already found a different way that works better for
> > them. It?s up to
> > >> the security community to accept that and find ways to
> > support it.
> > >>
> > >> Jim Bird
> > >>
> > >> ----- Original Message -----
> > >> From: James McGovern <JMcGovern at virtusa.com>
> > >> Date: Monday, November 1, 2010 7:55 am
> > >> Subject: [SAMM] Agile Software Development
> > >> To: "Software Assurance Maturity Model (SAMM)"
> > <samm at lists.owasp.org>>>
> > >>> Many maturity models penalize Agile approaches to software
> > development>>> since the focus isn't on creation of
> > comprehensive documentation
> > >>> upfront. Is there merit in providing "audit" guidance for those
> > >>> who are
> > >>> leveraging Agile methods? How do we encourage folks to think about
> > >>> maturity in an iterative way and not interpret SAMM as being more
> > >>> waterfall-oriented?
> > >>>
> > >>> ?
> > >>>
> > >>> James McGovern
> > >>> Insurance SBU
> > >>>
> > >>> Virtusa Corporation
> > >>>
> > >>> 100 Northfield Drive, Suite 305 | Windsor, CT | 06095
> > >>>
> > >>> Phone:? 860 688 9900 Ext:? 1037 | Facsimile:? 860
> > >>> 688 2890?
> > >>>
> > >>> ? <http://www.virtusa.com/>???
> > >>> <http://www.virtusa.com/blog/>??
> > >>> <https://twitter.com/VirtusaCorp>??
> > >>> <http://www.linkedin.com/companies/virtusa>??
> > >>> <http://www.facebook.com/VirtusaCorp>
> > >>>
> > >>> ?
> > >>>
> > >>>
> > >>> Virtusa was recently ranked and featured in 2010 Global Services
> > >>> 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009 Deloitte
> > >>> Technology Fast 500 and 2009 Dataquest-IDC Best Employers Survey
> > >>> among others.
> > >>>
> > >>> -------------------------------------------------------------
> > ----
> > >>> ----------------------------
> > > _______________________________________________
> > > SAMM mailing list
> > > SAMM at lists.owasp.org
> > > https://lists.owasp.org/mailman/listinfo/samm
> > >
> > > Virtusa was recently ranked and featured in 2010 Global
> > Services 100, IAOP's 2010 Global Outsourcing 100 sub-list, 2009
> > Deloitte Technology Fast 500 and 2009 Dataquest-IDC Best
> > Employers Survey among others.
> > >
> > > ---------------------------------------------------------------
> > ------------------------------
> > >
> > > This message, including any attachments, contains confidential
> > information intended for a specific individual and purpose, and
> > is intended for the addressee only. Any unauthorized disclosure,
> > use, dissemination, copying, or distribution of this message or
> > any of its attachments or the information contained in this e-
> > mail, or the taking of any action based on it, is strictly
> > prohibited. If you are not the intended recipient, please notify
> > the sender immediately by return e-mail and delete this message.
> > _______________________________________________
> > SAMM mailing list
> > SAMM at lists.owasp.org
> > https://lists.owasp.org/mailman/listinfo/samm
> >
>
>
> _______________________________________________
> SAMM mailing list
> SAMM at lists.owasp.org
> https://lists.owasp.org/mailman/listinfo/samm

-------------- next part --------------
An HTML attachment was scrubbed...
URL: https://lists.owasp.org/pipermail/samm/attachments/20101104/e40fd818/attachment-0001.html 

From christian.heinrich at cmlh.id.au  Sat Nov  6 20:29:26 2010
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Sun, 7 Nov 2010 11:29:26 +1100
Subject: [SAMM] EG1.A - "Top 10" Reference
Message-ID: <AANLkTi=hfQJ6KiPpY_joRm95b=SOr4QNauOLUa2zxhe1@mail.gmail.com>

Pravir,

On p43 of p96 it might be worth expanding this as "OWASP Top Ten"
rather then "Top 10" and including the URL for the OWASP Top Ten 10
(or any other Top X List) as a footnote?

Also, as a development culture matures then this scope (i.e. Top Ten)
I presume that this would expand to include other bodies of work, such
as ASVS, OWASP Testing Guide, etc?


-- 
Regards,
Christian Heinrich

http://www.linkedin.com/in/ChristianHeinrich

Mobile: +61 433 510 532 (AEST +10 GMT/UTC)
SkypeID: cmlh.id.au

From christian.heinrich at cmlh.id.au  Sat Nov  6 21:04:10 2010
From: christian.heinrich at cmlh.id.au (Christian Heinrich)
Date: Sun, 7 Nov 2010 12:04:10 +1100
Subject: [SAMM] Draft Correlation to BSIMM2 of the "Education and Guidance"
 and "Policy and Compliance" Security Practices
Message-ID: <AANLkTim5L_WSNvzXUi=o3ecv5mOGiCuTh+aP4_LUb4p-@mail.gmail.com>

To continue on from
https://lists.owasp.org/pipermail/samm/2010-October/000237.html

>From my reading of the "Training" and "Policy and Compliance"
Practices specified by BSIMM2 I have concluded
that the following correlation may (i.e. this could be incorrect)
exist with OpenSAMM v1.0 which I have published at

1. http://cmlh.id.au/post/1495680459/bsamm-gov-pc i.e. "Policy and Compliance"
2. http://cmlh.id.au/post/1501070970/bsamm-gov-training i.e.
"Education and Guidance"

I welcome any constructive feedback from the community on these drafts.


-- 
Regards,
Christian Heinrich

http://www.linkedin.com/in/ChristianHeinrich

Mobile: +61 433 510 532 (AEST +10 GMT/UTC)
SkypeID: cmlh.id.au

From rajiv.x.sharma at ORACLE.COM  Sun Nov  7 01:17:00 2010
From: rajiv.x.sharma at ORACLE.COM (rajiv.x.sharma at ORACLE.COM)
Date: Sat, 6 Nov 2010 22:17:00 -0700 (PDT)
Subject: [SAMM] Auto Reply: Draft Correlation to BSIMM2 of the "Education
 and Guidance" and "Policy and Compliance" Security Practices
Message-ID: <3d9d887c-79e8-4f3f-8c62-f9c85c42d465@default>

I'm out of office on Friday, Nov 5th. In case of any urgent issue, I can be reached at my mobile number in Aria.

Regards,
Rajiv


From rajiv.x.sharma at oracle.com  Sun Nov  7 01:18:33 2010
From: rajiv.x.sharma at oracle.com (rajiv.x.sharma at oracle.com)
Date: Sat, 6 Nov 2010 22:18:33 -0700 (PDT)
Subject: [SAMM] Auto Reply: Auto Reply: Draft Correlation to BSIMM2 of the
 "Education and Guidance" and "Policy and Compliance" Security Practices
Message-ID: <79128cb2-70b4-4034-97e3-349c5b50e8a6@default>

I'm out of office on Friday, Nov 5th. In case of any urgent issue, I can be reached at my mobile number in Aria.

Regards,
Rajiv


From colin.watson at owasp.org  Wed Nov 10 21:26:29 2010
From: colin.watson at owasp.org (Colin Watson)
Date: Thu, 11 Nov 2010 02:26:29 +0000
Subject: [SAMM] Correlation - BSIMM - SSF - Domains and Practices
In-Reply-To: <AANLkTi=pO+ht3yReOmfoe+5ina0ti48L4phXFj=CuT-a@mail.gmail.com>
References: <AANLkTineVTzY2niHnq=3mDGLbOCpRAw8=Y4HC5Mi64DG@mail.gmail.com>
	<F7F8EA16-DB6F-487F-8B1B-B74A3940CDDF@owasp.org>
	<70D4247CD05BD8439BDE923BA3215B712EB03B28@S27GE2.office.ascure.com>
	<AANLkTi=pO+ht3yReOmfoe+5ina0ti48L4phXFj=CuT-a@mail.gmail.com>
Message-ID: <AANLkTimS-Pt7HCSAQzSc7AV=v67cdkNHv61kRjFTJ8F9@mail.gmail.com>

At AppSec DC today, on behalf of Department of Homeland Security
National Cyber Security Division?s Software Assurance program, Edmund
Wotring presented an aggregated cross-reference of:

- BSIMM
- SAMM
- CMMI for Acquisition (CMMI-ACQ
- Process Reference Model For Assurance
- CERT Resilience Management Model

focusing on the overlaps, rather than the differences.  He
demonstrated an Excel tool which lets users create a status overview
against 5 domains:

- Governance
- Knowledge
- Verification
- Deployment
- Supplier management

each with 3 categories and 3 practices.

   http://www.owasp.org/index.php/Ensuring_Software_Assurance_Process_Maturity
   https://buildsecurityin.us-cert.gov/swa/proself_assm.html

The tool will be published shortly at https://buildsecurityin.us-cert.gov

Colin

