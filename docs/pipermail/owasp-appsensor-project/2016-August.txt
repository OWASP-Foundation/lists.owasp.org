From timothy22000 at gmail.com  Tue Aug 16 19:03:32 2016
From: timothy22000 at gmail.com (Timothy Sum Hon Mun)
Date: Tue, 16 Aug 2016 20:03:32 +0100
Subject: [Owasp-appsensor-project] AppSensor GSoC ML Weekly Summary
In-Reply-To: <CAPQUyzz+N_JvQ0Yne1CrEpJ2VaMoqtSTeuriwx8716EqCXW1RQ@mail.gmail.com>
References: <CAPQUyzw2Em0BPm3PFw0x6gP3GMJyzCEM-ww6BKAAgqbp_E0qzQ@mail.gmail.com>
	<CAPQUyzwoAdCYd43mp1oPQu2nQ6mwKBaJRvWfXbs7yRMUY3du5w@mail.gmail.com>
	<CAPQUyzwa9reGNJg8P8RKrQ-bEPzt+OVncS+sadTgBrpaJd9xrA@mail.gmail.com>
	<CAPQUyzwR-dTq9WFftf-_BYRS11=ULJBWydeyfrCynzjncxNE0Q@mail.gmail.com>
	<CAPQUyzzvZkVnt+Gh1XCRYxojZB8SCsBfr9d3bRBbF4cTsCHzVw@mail.gmail.com>
	<CAPQUyzz+N_JvQ0Yne1CrEpJ2VaMoqtSTeuriwx8716EqCXW1RQ@mail.gmail.com>
Message-ID: <CAPQUyzzde2HRBzQqtJc46S84-MJiKYt0LFjTOA3Zj0-8H2ad4A@mail.gmail.com>

Hi All,


My weekly updates for the project. There will be two weeks for this update
and there will be one more week left till the end. :(


If anyone has ideas or suggestions, please feel free to chip in.

-------------------


Report 2/08/2016

Date: 2nd August 2016

Accomplishments in the past week: Restructured code - configuration passed
to files - preparing it for rule suggestion and defining threshold, did
clustering and clustering then classification for one feature with the
artificial dataset with the results, working on the rule suggestion for the
results from the one feature one atm

Goals for the upcoming week: Complete rule suggestion work and see how it
is, create and improve script for artificial dataset.

Blockers (things preventing forward progress):

Adjustments to project plan, if any:

Other: (use this space to document anything you learned, what worked well,
what didn't work well, etc.)

-------------------

Report 9/08/2016

Date: 9th August 2016

Accomplishments in the past week: Completed rule suggestion work with one
and multiple features (not using geocoded lat/long yet) - mostly focus on
the output

Goals for the upcoming week: Integrate lat/long into rule suggestion
output, test accuracy of the output and tweak artificial dataset for some
good examples, visualizing the what has been produced, documenting future
work that can be done

Blockers (things preventing forward progress):

Adjustments to project plan, if any:

Other: (use this space to document anything you learned, what worked well,
what didn't work well, etc.)

If you encounter task not serializable exception when running you Spark
job, this can happen if the class of the object you are creating is not
serializable. This problem occurs because the class has to be serializable
so that it can be sent to the different worker nodes. If this class was
created by yourself, you can just implement Serializable to fix this
exception. If it is a third party library or class, there are several ways
to fix it in the links - one of the ways being making the object as static
so it is created once per machine which is what worked for me. You can look
at the links for alternative solutions if it doesn?t work for you. (
https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/troubleshooting/javaionotserializableexception.html,
http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou
)

-------------------

Kind Regards,
Tim

On Tue, Jul 26, 2016 at 7:42 AM, Timothy Sum Hon Mun <timothy22000 at gmail.com
> wrote:

> Hi All,
>
> My weekly project update as per usual. :)
>
> If anyone has ideas or suggestions, please feel free to chip in.
>
> --------------------------------------
>
>
> Report 19/7/2016
>
> Date:  19 July 2016
>
> Accomplishments in the past week: Geocoded API - caching - convert to
> column, Found out that Streaming KMeans is not suitable for my use-case
> (reasoning below), Did clustering with one feature for rule suggestion
> (HTTP Verb - added it in weird verb and clustered - there is a separate
> cluster that signify anomalous)
>
> Goals for the upcoming week: Clustering for more features for rule
> suggestion, Experiment with rule suggestion with only clustering and
> clustering then classification for more than one feature, Create script for
> generating artificial dataset
>
> Blockers (things preventing forward progress):
>
> Adjustments to project plan, if any: - Working on a university project
> deadline this week - slower progress
>
> Other: (use this space to document anything you learned, what worked well,
> what didn't work well, etc.):
>
>    -
>
>    Index stability with VectorIndexer and StringIndexer - Index for
>    categorical to numerical changes every time for both indexers
>    (VectorIndexer: https://spark.apache.org/docs/
>    1.6.0/api/java/org/apache/spark/ml/feature/VectorIndexer.html
>    <https://spark.apache.org/docs/1.6.0/api/java/org/apache/spark/ml/feature/VectorIndexer.html>
>    and StringIndexer: https://spark.apache.org/docs/
>    1.6.0/api/java/org/apache/spark/ml/feature/StringIndexer.html
>    <https://spark.apache.org/docs/1.6.0/api/java/org/apache/spark/ml/feature/StringIndexer.html>
>    - most frequent label get index 0). Therefore, if I index streaming data as
>    they come in, I cannot ensure that the index for a feature being taken in
>    by an algorithm can be consistent as new data comes in. The alternative
>    would be to keep a table and update/re-index it as new data points comes in
>    and only feed in the new data points to the streaming kmeans - the index
>    may change as well if new data points come in. So current approach where I
>    re-train the kmeans model on the whole dataset or table is fine for now to
>    ensure index stability.
>
>
> --------------------------------------
>
> Kind Regards,
> Tim
>
>
> On Tue, Jul 19, 2016 at 3:46 PM, Timothy Sum Hon Mun <
> timothy22000 at gmail.com> wrote:
>
>> Hi All,
>>
>> My update for my progress last week failed to send out and I didn't
>> realize it soon enough so here it is instead.
>>
>> If anyone has ideas or suggestions, please feel free to chip in.
>> --------------------------------------
>>
>> Report 12/7/2016
>>
>> Date:  12 July 2016
>>
>> Accomplishments in the past week: Got Streaming KMeans working, Geocoded
>> location data with google geocoding API and integrated it with logistic
>> regression, Fix the noOfBins problem with decision trees for complex
>> analysis
>>
>> Goals for the upcoming week: Integrate lat/long with other classification
>> algorithm, cache or save geocoded lat/long to a persistent storage or just
>> on local file system due to request limits, cluster on one feature for rule
>> suggestion, create artificial anomalies into dataset (simple for now)
>>
>> Blockers (things preventing forward progress):
>>
>> Adjustments to project plan, if any:
>>
>> Other: (use this space to document anything you learned, what worked
>> well, what didn't work well, etc.):
>>
>>    -
>>
>>    maxBins in MLib Decision Tree will default to lower value if it is
>>    greater than the largest number of possible values for categorical values
>>    -
>>
>>    Google Geocoding API - limits requests to 2500 a day. Problem for
>>    large datasets - Should be alright for our prototype case - otherwise
>>    consider using cache or database
>>
>>
>> --------------------------------------
>>
>> Kind Regards,
>> Tim
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.owasp.org/pipermail/owasp-appsensor-project/attachments/20160816/50172198/attachment-0001.html>

